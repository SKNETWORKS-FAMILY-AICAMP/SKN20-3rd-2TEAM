{
  "context": "Patch collapse, a phenomenon where observing certain image patches reduces uncertainty in others, improves masked image modeling and promotes vision efficiency through selective patch exposure. Observing certain patches in an image reduces the uncertainty of others. Their realization lowers the distribution entropy of each remaining patch feature, analogous to collapsing a particle's wave function in quantum mechanics. This phenomenon can intuitively be calledpatch collapse. To identify which patches are most relied on during a target region's collapse, we learn anautoencoderthat softly selects a subset of patches to reconstruct each target patch. Graphing these learned dependencies for each patch'sPageRank scorereveals the optimal patch order to realize an image. We show that respecting this order benefits variousmasked image modelingmethods. First,autoregressive image generationcan be boosted by retraining the state-of-the-art modelMAR. Next, we introduce a new setup forimage classificationby exposingVision Transformersonly to high-rank patches in the collapse order. Seeing 22\\% of such patches is sufficient to achieve high accuracy. With these experiments, we proposepatch collapseas a novel image modeling perspective that promotes vision efficiency. Our project is available at https://github.com/wguo-ai/CoP . Observing certain patches in an image reduces the uncertainty of others. Their realization lowers the distribution entropy of each remaining patch feature, analogous to collapsing a particle's wave function in quantum mechanics. This phenomenon can intuitively be called patch collapse. To identify which patches are most relied on during a target region's collapse, we learn an autoencoder that softly selects a subset of patches to reconstruct each target patch. Graphing these learned dependencies for each patch's PageRank score reveals the optimal patch order to realize an image. We show that respecting this order benefits various masked image modeling methods. First, autoregressive image generation can be boosted by retraining the state-of-the-art model MAR. Next, we introduce a new setup for image classification by exposing Vision Transformers only to high-rank patches in the collapse order. Seeing 22% of such patches is sufficient to achieve high accuracy. With these experiments, we propose patch collapse as a novel image modeling perspective that promotes vision efficiency.  This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "paper_name": "The Collapse of Patches",
    "github_url": "https://github.com/wguo-ai/CoP",
    "huggingface_url": "https://huggingface.co/papers/2511.22281",
    "upvote": 5,
    "tags": [
      "image",
      "patch",
      "patches"
    ]
  }
}
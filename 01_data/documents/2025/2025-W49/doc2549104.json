{
  "context": "BlockVid addresses challenges in block diffusion video generation by employing semantic-aware sparse KV caching, Block Forcing training, and noise scheduling to produce high-quality, coherent minute-long videos. Generating minute-long videos is a critical step toward developing world models, providing a foundation for realistic extended scenes and advanced AI simulators. The emergingsemi-autoregressive(block diffusion) paradigm integrates the strengths of diffusion andautoregressive models, enabling arbitrary-length video generation and improving inference efficiency throughKV cachingandparallel sampling. However, it yet faces two enduring challenges: (i)KV-cache-induced long-horizon error accumulation, and (ii) the lack of fine-grained long-video benchmarks and coherence-aware metrics. To overcome these limitations, we proposeBlockVid, a novelblock diffusionframework equipped withsemantic-aware sparse KV cache, an effective training strategy calledBlock Forcing, and dedicatedchunk-wise noise schedulingand shuffling to reduce error propagation and enhancetemporal consistency. We further introduceLV-Bench, a fine-grained benchmark for minute-long videos, complete with new metrics evaluatinglong-range coherence. Extensive experiments onVBenchandLV-Benchdemonstrate thatBlockVidconsistently outperforms existing methods in generating high-quality, coherent minute-long videos. In particular, it achieves a 22.2% improvement onVDE Subjectand a 19.4% improvement onVDE ClarityinLV-Benchover the state of the art approaches. Project website: https://ziplab.co/BlockVid. Inferix (Code): https://github.com/alibaba-damo-academy/Inferix. Generating minute-long videos is a critical step toward developing world models, providing a foundation for realistic extended scenes and advanced AI simulators. The emerging semi-autoregressive (block diffusion) paradigm integrates the strengths of diffusion and autoregressive models, enabling arbitrary-length video generation and improving inference efficiency through KV caching and parallel sampling. However, it yet faces two enduring challenges: (i) KV-cache-induced long-horizon error accumulation, and (ii) the lack of fine-grained long-video benchmarks and coherence-aware metrics. To overcome these limitations, we propose BlockVid, a novel block diffusion framework equipped with semantic-aware sparse KV cache, an effective training strategy called Block Forcing, and dedicated chunk-wise noise scheduling and shuffling to reduce error propagation and enhance temporal consistency. We further introduce LV-Bench, a fine-grained benchmark for minute-long videos, complete with new metrics evaluating long-range coherence. Extensive experiments on VBench and LV-Bench demonstrate that BlockVid consistently outperforms existing methods in generating high-quality, coherent minute-long videos. In particular, it achieves a 22.2% improvement on VDE Subject and a 19.4% improvement on VDE Clarity in LV-Bench over the state of the art approaches. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "paper_name": "BlockVid: Block Diffusion for High-Quality and Consistent Minute-Long Video Generation",
    "github_url": "https://github.com/alibaba-damo-academy/Inferix/",
    "huggingface_url": "https://huggingface.co/papers/2511.22973",
    "upvote": 2,
    "tags": [
      "long video",
      "keyword2",
      "keyword3"
    ]
  }
}
{
  "context": "ORION models enhance reasoning efficiency and cost-effectiveness by compressing reasoning steps into ultra-compressed structured tokens, reducing latency and training costs while maintaining high accuracy. Large Reasoning Models(LRMs) achieve strong performance in mathematics, code generation, and task planning, but their reliance on long chains of verbose \"thinking\" tokens leads to high latency, redundancy, and incoherent reasoning paths. Inspired by theLanguage of Thought Hypothesis, which posits that human reasoning operates over a symbolic, compositional mental language calledMentalese, we introduce a framework that trains models to reason in a similarly compact style.Mentaleseencodes abstract reasoning as ultra-compressed, structured tokens, enabling models to solve complex problems with far fewer steps. To improve both efficiency and accuracy, we proposeSHORTER LENGTH PREFERENCE OPTIMIZATION(SLPO), areinforcement learningmethod that rewards concise solutions that stay correct, while still allowing longer reasoning when needed. Applied toMentalese-aligned models, SLPO yields significantly higher compression rates by enabling concise reasoning that preserves the benefits of detailed thinking without the computational overhead. Across benchmarks includingAIME2024 and 2025,MinervaMath,OlympiadBench,Math500, andAMC, ourORION modelsproduce reasoning traces with 4-16x fewer tokens, achieve up to 5x lower inference latency, and reduce training costs by 7-9x relative to the DeepSeek R1 Distilled model, while maintaining 90-98% of its accuracy. ORION also surpassesClaudeandChatGPT-4oby up to 5% in accuracy while maintaining 2x compression. These results show thatMentalese-style compressed reasoning offers a step toward human-like cognitive efficiency, enabling real-time, cost-effective reasoning without sacrificing accuracy. We introduceORION, a framework designed to teach language models to reason efficiently using a compact, symboliclanguage-of-thoughtrepresentation. Instead of generating long, often redundant chain-of-thought explanations, we train models to express reasoning through concise, structured symbolic steps. Our approach combines supervised learning with a novel reinforcement learning objective to optimize both correctness and efficiency. Reasoning in large language models has evolved from prompt-based chain-of-thought, to supervised step-by-step reasoning, to reinforcement-learning-driven verifiable reasoning. We position ORION as the next step:efficient symbolic reasoning, moving toward future systems capable of scalable, faithful, and cost-effective problem solving with minimal redundancy. We formalize a Mentalese-style representation that encodes reasoning using atomic operations. This removes natural-language verbosity and keeps every operation semantically necessary. We benchmark ORION on high-difficulty math reasoning tasks such as AIME, AMC, and MATH-500, measuring trace length, accuracy, inference cost, and faithfulness. Our RL objective adaptively balances correctness and compactness, enabling models to keep reasoning steps minimal while preserving validity. We implement a full pipeline optimized for deployment: shorter traces yield4–16× fewer tokens,5× lower latency, and7–9× lower compute cost. Structured symbolic traces allow transparent inspection of each reasoning step, improving debuggability and model reliability. ORION provides aclear technical pathway for efficient reasoningin LLMs. By combining symbolic thinking with reinforcement learning, we demonstrate that models can achieve strong accuracy with far fewer reasoning tokens. This work serves as both a conceptual shift away from verbose chain-of-thought and a practical system enablingfaster, cheaper, and more interpretable reasoning, suitable for both academic research and real-world applications. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "paper_name": "ORION: Teaching Language Models to Reason Efficiently in the Language of Thought",
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.22891",
    "upvote": 5,
    "tag1": "reasoning",
    "tag2": "step",
    "tag3": "accuracy"
  }
}
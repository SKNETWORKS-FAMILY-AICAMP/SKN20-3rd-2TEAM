{
  "context": "MG-Nav, a dual-scale framework for zero-shot visual navigation, combines global memory-guided planning with local geometry-enhanced control using a Sparse Spatial Memory Graph and a VGGT-adapter for robust navigation in unseen environments. We present MG-Nav (Memory-Guided Navigation), a dual-scale framework for zero-shot visual navigation that unifies global memory-guided planning with local geometry-enhanced control. At its core is theSparse Spatial Memory Graph(SMG), a compact, region-centric memory where each node aggregates multi-viewkeyframeandobject semantics, capturing both appearance and spatial structure while preserving viewpoint diversity. At the global level, the agent is localized onSMGand a goal-conditioned node path is planned via animage-to-instance hybrid retrieval, producing a sequence of reachablewaypoints for long-horizon guidance. At the local level, a navigation foundation policy executes thesewaypoints inpoint-goal modewithobstacle-aware control, and switches toimage-goal modewhen navigating from the final node towards the visual target. To further enhance viewpoint alignment and goal recognition, we introduceVGGT-adapter, a lightweight geometric module built on the pre-trained VGGT model, which aligns observation and goal features in a shared3D-aware space. MG-Nav operates global planning and local control at different frequencies, using periodic re-localization to correct errors. Experiments onHM3DInstance-Image-Goal andMP3DImage-Goal benchmarks demonstrate that MG-Nav achieves state-of-the-artzero-shot performanceand remains robust underdynamic rearrangementsand unseen scene conditions.  Â·Sign uporlog into comment",
  "metadata": {
    "paper_name": "MG-Nav: Dual-Scale Visual Navigation via Sparse Spatial Memory",
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.22609",
    "upvote": 33,
    "tags": [
      "goal",
      "memory",
      "navigation"
    ]
  }
}
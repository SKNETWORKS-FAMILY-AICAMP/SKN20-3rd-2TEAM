doc_id,paper_name,doc_file,github_url,huggingface_url,upvote,tags
doc2549001,From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence,doc2549001.json,,https://huggingface.co/papers/2511.18538,191,"[""code"", ""research"", ""llms""]"
doc2549002,"LongVT: Incentivizing ""Thinking with Long Videos"" via Native Tool Calling",doc2549002.json,https://github.com/EvolvingLMMs-Lab/LongVT,https://huggingface.co/papers/2511.20785,144,"[""https"", ""longvt"", ""video""]"
doc2549003,Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer,doc2549003.json,https://github.com/Tongyi-MAI/Z-Image,https://huggingface.co/papers/2511.22699,109,"[""image"", ""model"", ""https""]"
doc2549004,Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights,doc2549004.json,https://github.com/opendatalab-raiser/Envision,https://huggingface.co/papers/2512.01816,83,"[""models"", ""world"", ""image""]"
doc2549005,Stabilizing Reinforcement Learning with LLMs: Formulation and Practices,doc2549005.json,,https://huggingface.co/papers/2512.01374,59,"[""training"", ""level"", ""paper""]"
doc2549006,DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models,doc2549006.json,,https://huggingface.co/papers/2512.02556,54,"[""deepseek"", ""v3"", ""deepseek v3""]"
doc2549007,DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning,doc2549007.json,,https://huggingface.co/papers/2511.22570,48,"[""reasoning"", ""self"", ""step""]"
doc2549008,How Far Are We from Genuinely Useful Deep Research Agents?,doc2549008.json,https://github.com/OPPO-PersonalAI/FINDER_DEFT,https://huggingface.co/papers/2512.01948,45,"[""research"", ""dras"", ""reports""]"
doc2549009,REASONEDIT: Towards Reasoning-Enhanced Image Editing Models,doc2549009.json,https://github.com/stepfun-ai/Step1X-Edit?tab=readme-ov-file#step1x-edit-v1p2-v12,https://huggingface.co/papers/2511.22625,44,"[""editing"", ""image"", ""edit""]"
doc2549010,What about gravity in video generation? Post-Training Newton's Laws with Verifiable Rewards,doc2549010.json,https://github.com/cvlab-stonybrook/NewtonRewards,https://huggingface.co/papers/2512.00425,41,"[""physics"", ""physical"", ""training""]"
doc2549011,Infinity-RoPE: Action-Controllable Infinite Video Generation Emerges From Autoregressive Self-Rollout,doc2549011.json,,https://huggingface.co/papers/2511.20649,40,"[""rope"", ""video"", ""temporal""]"
doc2549012,Vision Bridge Transformer at Scale,doc2549012.json,https://github.com/Yuanshi9815/ViBT,https://huggingface.co/papers/2511.23199,39,"[""bridge"", ""models"", ""data""]"
doc2549013,TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models,doc2549013.json,,https://huggingface.co/papers/2512.02014,37,"[""unified"", ""generation"", ""paper""]"
doc2549014,AnyTalker: Scaling Multi-Person Talking Video Generation with Interactivity Refinement,doc2549014.json,https://github.com/HKUST-C4G/AnyTalker,https://huggingface.co/papers/2511.23475,37,"[""person"", ""multi"", ""multi person""]"
doc2549015,The Consistency Critic: Correcting Inconsistencies in Generated Images via Reference-Guided Attentive Alignment,doc2549015.json,https://github.com/HVision-NKU/ImageCritic,https://huggingface.co/papers/2511.20614,36,"[""imagecritic"", ""paper"", ""reference""]"
doc2549016,Geometrically-Constrained Agent for Spatial Reasoning,doc2549016.json,https://github.com/gca-spatial-reasoning/gca,https://huggingface.co/papers/2511.22659,35,"[""reasoning"", ""gca"", ""semantic""]"
doc2549017,MG-Nav: Dual-Scale Visual Navigation via Sparse Spatial Memory,doc2549017.json,,https://huggingface.co/papers/2511.22609,33,"[""goal"", ""memory"", ""navigation""]"
doc2549018,LFM2 Technical Report,doc2549018.json,,https://huggingface.co/papers/2511.23404,31,"[""lfm2"", ""models"", ""strong""]"
doc2549019,SimScale: Learning to Drive via Real-World Simulation at Scale,doc2549019.json,https://github.com/OpenDriveLab/SimScale,https://huggingface.co/papers/2511.23369,29,"[""world"", ""real"", ""real world""]"
doc2549020,MultiShotMaster: A Controllable Multi-Shot Video Generation Framework,doc2549020.json,,https://huggingface.co/papers/2512.03041,27,"[""shot"", ""multi"", ""multi shot""]"
doc2549021,"Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models",doc2549021.json,https://github.com/screemix/Wikontic,https://huggingface.co/papers/2512.00590,27,"[""wikontic"", ""kgs"", ""quality""]"
doc2549022,Architecture Decoupling Is Not All You Need For Unified Multimodal Model,doc2549022.json,https://github.com/zhengdian1/AIA,https://huggingface.co/papers/2511.22663,27,"[""decoupling"", ""generation"", ""attention""]"
doc2549023,CaptionQA: Is Your Caption as Useful as the Image Itself?,doc2549023.json,https://github.com/bronyayang/CaptionQA,https://huggingface.co/papers/2511.21025,23,"[""utility"", ""captions"", ""image""]"
doc2549024,Guided Self-Evolving LLMs with Minimal Human Supervision,doc2549024.json,,https://huggingface.co/papers/2512.02472,22,"[""human"", ""self"", ""training""]"
doc2549025,Flash-DMD: Towards High-Fidelity Few-Step Image Generation with Efficient Distillation and Joint Reinforcement Learning,doc2549025.json,,https://huggingface.co/papers/2511.20549,22,"[""training"", ""models"", ""distillation""]"
doc2549026,DiP: Taming Diffusion Models in Pixel Space,doc2549026.json,,https://huggingface.co/papers/2511.18822,22,"[""dip"", ""diffusion"", ""generation""]"
doc2549027,Rectifying LLM Thought from Lens of Optimization,doc2549027.json,https://github.com/open-compass/RePro,https://huggingface.co/papers/2512.01925,21,"[""reasoning"", ""process"", ""cot""]"
doc2549028,VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference,doc2549028.json,https://github.com/mit-han-lab/vlash,https://huggingface.co/papers/2512.01031,20,"[""vlash"", ""vlas"", ""execution""]"
doc2549029,DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action,doc2549029.json,,https://huggingface.co/papers/2511.22134,20,"[""action"", ""data"", ""vla""]"
doc2549030,Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models,doc2549030.json,,https://huggingface.co/papers/2511.23319,19,"[""context"", ""long"", ""attention""]"
doc2549031,Adversarial Flow Models,doc2549031.json,,https://huggingface.co/papers/2511.22475,19,"[""models"", ""flow"", ""af""]"
doc2549032,ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation,doc2549032.json,https://github.com/kszpxxzmc/ViSAudio,https://huggingface.co/papers/2512.03036,18,"[""audio"", ""visaudio"", ""spatial""]"
doc2549033,WorldMM: Dynamic Multimodal Memory Agent for Long Video Reasoning,doc2549033.json,https://github.com/wgcyeo/WorldMM,https://huggingface.co/papers/2512.02425,18,"[""memory"", ""video"", ""multiple""]"
doc2549034,GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation,doc2549034.json,,https://huggingface.co/papers/2512.01801,18,"[""rl"", ""gr rl"", ""gr""]"
doc2549035,Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models,doc2549035.json,,https://huggingface.co/papers/2511.18890,16,"[""latency"", ""real"", ""accuracy""]"
doc2549036,InternVideo-Next: Towards General Video Foundation Models without Video-Text Supervision,doc2549036.json,,https://huggingface.co/papers/2512.01342,14,"[""level"", ""stage"", ""pixel""]"
doc2549037,"Decoupled DMD: CFG Augmentation as the Spear, Distribution Matching as the Shield",doc2549037.json,https://github.com/Tongyi-MAI/Z-Image/tree/main,https://huggingface.co/papers/2511.22677,14,"[""distillation"", ""matching"", ""step""]"
doc2549038,SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs,doc2549038.json,,https://huggingface.co/papers/2512.00722,13,"[""specontext"", ""model"", ""paper""]"
doc2549039,Flow Straighter and Faster: Efficient One-Step Generative Modeling via MeanFlow on Rectified Trajectories,doc2549039.json,https://github.com/Xinxi-Zhang/Re-MeanFlow,https://huggingface.co/papers/2511.23342,13,"[""rectified"", ""meanflow"", ""step""]"
doc2549040,Where Culture Fades: Revealing the Cultural Gap in Text-to-Image Generation,doc2549040.json,,https://huggingface.co/papers/2511.17282,13,"[""cultural"", ""models"", ""paper""]"
doc2549041,MultiBanana: A Challenging Benchmark for Multi-Reference Text-to-Image Generation,doc2549041.json,https://github.com/matsuolab/multibanana,https://huggingface.co/papers/2511.22989,12,"[""reference"", ""multi reference"", ""multi""]"
doc2549042,RefineBench: Evaluating Refinement Capability of Language Models via Checklists,doc2549042.json,https://github.com/RefineBench/refinebench-eval,https://huggingface.co/papers/2511.22173,12,"[""refinement"", ""lms"", ""self""]"
doc2549043,Mixture of Horizons in Action Chunking,doc2549043.json,https://github.com/Timsty1/MixtureOfHorizons/tree/main,https://huggingface.co/papers/2511.19433,13,"[""moh"", ""term"", ""performance""]"
doc2549044,Accelerating Streaming Video Large Language Models via Hierarchical Token Compression,doc2549044.json,https://github.com/lern-to-write/STC,https://huggingface.co/papers/2512.00891,11,"[""stc"", ""textbf"", ""llm""]"
doc2549045,Does Hearing Help Seeing? Investigating Audio-Video Joint Denoising for Video Generation,doc2549045.json,https://github.com/jianzongwu/Does-Hearing-Help-Seeing,https://huggingface.co/papers/2512.02457,8,"[""video"", ""audio"", ""https""]"
doc2549046,PromptBridge: Cross-Model Prompt Transfer for Large Language Models,doc2549046.json,,https://huggingface.co/papers/2512.01420,8,"[""model"", ""prompt"", ""promptbridge""]"
doc2549047,SCALE: Selective Resource Allocation for Overcoming Performance Bottlenecks in Mathematical Test-time Scaling,doc2549047.json,https://github.com/XiaoYang66/DualThinking,https://huggingface.co/papers/2512.00466,8,"[""sub"", ""sub problems"", ""problems""]"
doc2549048,DualCamCtrl: Dual-Branch Diffusion Model for Geometry-Aware Camera-Controlled Video Generation,doc2549048.json,https://github.com/EnVision-Research/DualCamCtrl,https://huggingface.co/papers/2511.23127,8,"[""dualcamctrl"", ""https"", ""camera""]"
doc2549049,Captain Safari: A World Engine,doc2549049.json,,https://huggingface.co/papers/2511.22815,8,"[""camera"", ""world"", ""long""]"
doc2549050,World in a Frame: Understanding Culture Mixing as a New Challenge for Vision-Language Models,doc2549050.json,,https://huggingface.co/papers/2511.22787,8,"[""food"", ""cultural"", ""background""]"
doc2549051,Script: Graph-Structured and Query-Conditioned Semantic Token Pruning for Multimodal Large Language Models,doc2549051.json,,https://huggingface.co/papers/2512.01949,7,"[""script"", ""comment"", ""pruning""]"
doc2549052,DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models,doc2549052.json,https://github.com/BeingBeyond/DiG-Flow,https://huggingface.co/papers/2512.01715,7,"[""flow"", ""dig"", ""dig flow""]"
doc2549053,Lotus-2: Advancing Geometric Dense Prediction with Powerful Image Generative Model,doc2549053.json,https://github.com/EnVision-Research/Lotus-2,https://huggingface.co/papers/2512.01030,7,"[""lotus"", ""geometric"", ""https""]"
doc2549054,Glance: Accelerating Diffusion Models with 1 Sample,doc2549054.json,,https://huggingface.co/papers/2512.02899,6,"[""models"", ""lora"", ""generalization""]"
doc2549055,HiconAgent: History Context-aware Policy Optimization for GUI Agents,doc2549055.json,https://github.com/JiuTian-VL/HiconAgent,https://huggingface.co/papers/2512.01763,5,"[""history"", ""gui"", ""context""]"
doc2549056,StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos,doc2549056.json,https://github.com/daeunni/StreamGaze,https://huggingface.co/papers/2512.01707,5,"[""gaze"", ""streaming"", ""streamgaze""]"
doc2549057,ORION: Teaching Language Models to Reason Efficiently in the Language of Thought,doc2549057.json,,https://huggingface.co/papers/2511.22891,5,"[""reasoning"", ""models"", ""accuracy""]"
doc2549058,The Collapse of Patches,doc2549058.json,https://github.com/wguo-ai/CoP,https://huggingface.co/papers/2511.22281,5,"[""image"", ""patch"", ""patches""]"
doc2549059,OralGPT-Omni: A Versatile Dental Multimodal Large Language Model,doc2549059.json,https://github.com/isbrycee/OralGPT,https://huggingface.co/papers/2511.22055,5,"[""dental"", ""analysis"", ""oralgpt""]"
doc2549060,The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models,doc2549060.json,https://github.com/dmis-lab/analogical-reasoning,https://huggingface.co/papers/2511.20344,5,"[""relational"", ""level"", ""llms""]"
doc2549061,SO-Bench: A Structural Output Evaluation of Multimodal LLMs,doc2549061.json,,https://huggingface.co/papers/2511.21750,5,"[""visual"", ""schema"", ""benchmark""]"
doc2549062,PAI-Bench: A Comprehensive Benchmark For Physical AI,doc2549062.json,https://github.com/SHI-Labs/physical-ai-bench,https://huggingface.co/papers/2512.01989,4,"[""models"", ""physical"", ""physical ai""]"
doc2549063,POLARIS: Projection-Orthogonal Least Squares for Robust and Adaptive Inversion in Diffusion Models,doc2549063.json,https://github.com/Chatonz/POLARIS,https://huggingface.co/papers/2512.00369,4,"[""inversion"", ""step"", ""error""]"
doc2549064,Test-time scaling of diffusions with flow maps,doc2549064.json,,https://huggingface.co/papers/2511.22688,4,"[""flow"", ""map"", ""time""]"
doc2549065,Revisiting the Necessity of Lengthy Chain-of-Thought in Vision-centric Reasoning Generalization,doc2549065.json,,https://huggingface.co/papers/2511.22586,4,"[""cot"", ""reasoning"", ""visual""]"
doc2549066,Asking like Socrates: Socrates helps VLMs understand remote sensing images,doc2549066.json,https://github.com/GeoX-Lab/Asking_like_Socrates,https://huggingface.co/papers/2511.22396,4,"[""reasoning"", ""rs"", ""evidence""]"
doc2549067,Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information,doc2549067.json,,https://huggingface.co/papers/2511.22176,4,"[""cot"", ""reasoning"", ""input""]"
doc2549068,Agentic Policy Optimization via Instruction-Policy Co-Evolution,doc2549068.json,https://github.com/cambridgeltl/inspo,https://huggingface.co/papers/2512.01945,3,"[""instruction"", ""instructions"", ""inspo""]"
doc2549069,CauSight: Learning to Supersense for Visual Causal Discovery,doc2549069.json,https://github.com/OpenCausaLab/CauSight,https://huggingface.co/papers/2512.01827,3,"[""causal"", ""https"", ""paper""]"
doc2549070,TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition,doc2549070.json,https://github.com/opendatalab/TRivia,https://huggingface.co/papers/2512.01248,3,"[""tr"", ""table"", ""models""]"
doc2549071,Learning Eigenstructures of Unstructured Data Manifolds,doc2549071.json,,https://huggingface.co/papers/2512.01103,3,"[""operator"", ""data"", ""manifold""]"
doc2549072,SwiftVLA: Unlocking Spatiotemporal Dynamics for Lightweight VLA Models at Minimal Overhead,doc2549072.json,https://github.com/GigaAI-research/SwiftVLA,https://huggingface.co/papers/2512.00903,3,"[""4d"", ""swiftvla"", ""vlm""]"
doc2549073,From Pixels to Feelings: Aligning MLLMs with Human Cognitive Perception of Images,doc2549073.json,,https://huggingface.co/papers/2511.22805,3,"[""human"", ""properties"", ""image""]"
doc2549074,OmniRefiner: Reinforcement-Guided Local Diffusion Refinement,doc2549074.json,https://github.com/yaoliliu/OmniRefiner,https://huggingface.co/papers/2511.19990,3,"[""image"", ""reference"", ""refinement""]"
doc2549075,Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation,doc2549075.json,,https://huggingface.co/papers/2512.03040,2,"[""video"", ""tasks"", ""spatial""]"
doc2549076,The Art of Scaling Test-Time Compute for Large Language Models,doc2549076.json,https://github.com/Aradhye2002/art_of_tts,https://huggingface.co/papers/2512.02008,2,"[""type"", ""paper"", ""problem difficulty""]"
doc2549077,OpenREAD: Reinforced Open-Ended Reasoing for End-to-End Autonomous Driving with LLM-as-Critic,doc2549077.json,https://github.com/wyddmw/OpenREAD,https://huggingface.co/papers/2512.01830,2,"[""driving"", ""open"", ""model""]"
doc2549078,ChronosObserver: Taming 4D World with Hyperspace Diffusion Sampling,doc2549078.json,,https://huggingface.co/papers/2512.01481,2,"[""hyperspace"", ""time"", ""view""]"
doc2549079,Generalist Large Language Models Outperform Clinical Tools on Medical Benchmarks,doc2549079.json,,https://huggingface.co/papers/2512.01191,2,"[""clinical"", ""ai"", ""tools""]"
doc2549080,Seeing the Wind from a Falling Leaf,doc2549080.json,,https://huggingface.co/papers/2512.00762,2,"[""video"", ""paper"", ""end""]"
doc2549081,WiseEdit: Benchmarking Cognition- and Creativity-Informed Image Editing,doc2549081.json,,https://huggingface.co/papers/2512.00387,2,"[""knowledge"", ""editing"", ""image editing""]"
doc2549082,BlockVid: Block Diffusion for High-Quality and Consistent Minute-Long Video Generation,doc2549082.json,https://github.com/alibaba-damo-academy/Inferix/,https://huggingface.co/papers/2511.22973,2,"[""long"", ""videos"", ""minute""]"
doc2549083,Layer-Aware Video Composition via Split-then-Merge,doc2549083.json,,https://huggingface.co/papers/2511.20809,2,"[""video"", ""stm"", ""merge""]"
doc2549084,YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection,doc2549084.json,,https://huggingface.co/papers/2511.13344,2,"[""paper"", ""experts"", ""object detection""]"
doc2549085,YingVideo-MV: Music-Driven Multi-Stage Video Generation,doc2549085.json,,https://huggingface.co/papers/2512.02492,1,"[""videos"", ""camera"", ""music""]"
doc2549086,GUI Exploration Lab: Enhancing Screen Navigation in Agents via Multi-Turn Reinforcement Learning,doc2549086.json,,https://huggingface.co/papers/2512.02423,1,"[""gui"", ""navigation"", ""agent""]"
doc2549087,Artemis: Structured Visual Reasoning for Perception Policy Learning,doc2549087.json,https://github.com/WayneTomas/Artemis,https://huggingface.co/papers/2512.01988,1,"[""reasoning"", ""perception"", ""visual""]"
doc2549088,DreamingComics: A Story Visualization Pipeline via Subject and Layout Customized Generation using Video Models,doc2549088.json,,https://huggingface.co/papers/2512.01686,1,"[""layout"", ""visualization"", ""story""]"
doc2549089,IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages,doc2549089.json,https://github.com/ayushbits/IndicParam,https://huggingface.co/papers/2512.00333,1,"[""indicparam"", ""resource"", ""low""]"
doc2549090,Fast3Dcache: Training-free 3D Geometry Synthesis Acceleration,doc2549090.json,https://github.com/Westlake-AGI-Lab/Fast3Dcache,https://huggingface.co/papers/2511.22533,1,"[""fast3dcache"", ""3d"", ""inference""]"
doc2549091,FedRE: A Representation Entanglement Framework for Model-Heterogeneous Federated Learning,doc2549091.json,https://github.com/AIResearch-Group/FedRE,https://huggingface.co/papers/2511.22265,1,"[""fedre"", ""model"", ""privacy""]"
doc2549092,C^2DLM: Causal Concept-Guided Diffusion Large Language Models,doc2549092.json,,https://huggingface.co/papers/2511.22146,1,"[""language"", ""textbf"", ""causal""]"
doc2549093,A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs,doc2549093.json,https://github.com/heyzbw/HuSls,https://huggingface.co/papers/2512.00077,1,"[""balancing"", ""based"", ""walking""]"
doc2549094,Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench,doc2549094.json,,https://huggingface.co/papers/2512.02942,0,"[""video"", ""scientific"", ""models""]"
doc2549095,Generative Video Motion Editing with 3D Point Tracks,doc2549095.json,,https://huggingface.co/papers/2512.02015,0,"[""video"", ""editing"", ""object""]"
doc2549096,UnicEdit-10M: A Dataset and Benchmark Breaking the Scale-Quality Barrier via Unified Verification for Reasoning-Enriched Edits,doc2549096.json,,https://huggingface.co/papers/2512.02790,0,"[""quality"", ""scale"", ""model""]"
doc2549097,MEGConformer: Conformer-Based MEG Decoder for Robust Speech and Phoneme Classification,doc2549097.json,https://github.com/neural2speech/libribrain-experiments,https://huggingface.co/papers/2512.01443,0,"[""speech"", ""phoneme"", ""phoneme classification""]"
doc2549098,Doppler-Enhanced Deep Learning: Improving Thyroid Nodule Segmentation with YOLOv5 Instance Segmentation,doc2549098.json,,https://huggingface.co/papers/2512.00639,0,"[""images"", ""yolov5"", ""performance""]"
doc2549099,OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion,doc2549099.json,https://github.com/saikoneru/OmniFusion,https://huggingface.co/papers/2512.00234,0,"[""translation"", ""multimodal"", ""speech""]"
doc2549100,Structured Extraction from Business Process Diagrams Using Vision-Language Models,doc2549100.json,https://github.com/pritamdeka/BPMN-VLM,https://huggingface.co/papers/2511.22448,0,"[""bpmn"", ""vlms"", ""ocr""]"
doc2549101,Xmodel-2.5: 1.3B Data-Efficient Reasoning SLM,doc2549101.json,https://github.com/XiaoduoAILab/Xmodel-2.5,https://huggingface.co/papers/2511.19496,0,"[""xmodel"", ""parameter"", ""xiaoduoailab""]"
doc2549102,MRI Super-Resolution with Deep Learning: A Comprehensive Survey,doc2549102.json,https://github.com/mkhateri/Awesome-MRI-Super-Resolution,https://huggingface.co/papers/2511.16854,0,"[""resolution"", ""super"", ""mri""]"
doc2549103,Click2Graph: Interactive Panoptic Video Scene Graphs from a Single Click,doc2549103.json,,https://huggingface.co/papers/2511.15948,0,"[""scene"", ""video"", ""graph""]"
doc2549104,"Find the Leak, Fix the Split: Cluster-Based Method to Prevent Leakage in Video-Derived Datasets",doc2549104.json,,https://huggingface.co/papers/2511.13944,0,"[""frames"", ""similar"", ""similar frames""]"
doc2549105,Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models,doc2549105.json,,https://huggingface.co/papers/2511.13276,0,"[""videos"", ""ucf"", ""ucf crime""]"

doc_id,paper_name,doc_file,github_url,huggingface_url,upvote,tags
doc2549001,From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence,doc2549001.json,,https://huggingface.co/papers/2511.18538,0,"[""code"", ""research"", ""llms""]"
doc2549002,"LongVT: Incentivizing ""Thinking with Long Videos"" via Native Tool Calling",doc2549002.json,https://github.com/EvolvingLMMs-Lab/LongVT,https://huggingface.co/papers/2511.20785,0,"[""https"", ""longvt"", ""video""]"
doc2549003,Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer,doc2549003.json,https://github.com/Tongyi-MAI/Z-Image,https://huggingface.co/papers/2511.22699,0,"[""image"", ""model"", ""https""]"
doc2549004,Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights,doc2549004.json,https://github.com/opendatalab-raiser/Envision,https://huggingface.co/papers/2512.01816,0,"[""models"", ""world"", ""image""]"
doc2549005,Stabilizing Reinforcement Learning with LLMs: Formulation and Practices,doc2549005.json,,https://huggingface.co/papers/2512.01374,0,"[""training"", ""level"", ""paper""]"
doc2549006,DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning,doc2549006.json,,https://huggingface.co/papers/2511.22570,0,"[""reasoning"", ""self"", ""step""]"
doc2549007,REASONEDIT: Towards Reasoning-Enhanced Image Editing Models,doc2549007.json,https://github.com/stepfun-ai/Step1X-Edit?tab=readme-ov-file#step1x-edit-v1p2-v12,https://huggingface.co/papers/2511.22625,0,"[""editing"", ""image"", ""edit""]"
doc2549008,How Far Are We from Genuinely Useful Deep Research Agents?,doc2549008.json,https://github.com/OPPO-PersonalAI/FINDER_DEFT,https://huggingface.co/papers/2512.01948,0,"[""research"", ""dras"", ""reports""]"
doc2549009,What about gravity in video generation? Post-Training Newton's Laws with Verifiable Rewards,doc2549009.json,https://github.com/cvlab-stonybrook/NewtonRewards,https://huggingface.co/papers/2512.00425,0,"[""physics"", ""physical"", ""training""]"
doc2549010,Vision Bridge Transformer at Scale,doc2549010.json,https://github.com/Yuanshi9815/ViBT,https://huggingface.co/papers/2511.23199,0,"[""bridge"", ""models"", ""data""]"
doc2549011,Infinity-RoPE: Action-Controllable Infinite Video Generation Emerges From Autoregressive Self-Rollout,doc2549011.json,,https://huggingface.co/papers/2511.20649,0,"[""rope"", ""video"", ""temporal""]"
doc2549012,AnyTalker: Scaling Multi-Person Talking Video Generation with Interactivity Refinement,doc2549012.json,https://github.com/HKUST-C4G/AnyTalker,https://huggingface.co/papers/2511.23475,0,"[""person"", ""multi"", ""multi person""]"
doc2549013,The Consistency Critic: Correcting Inconsistencies in Generated Images via Reference-Guided Attentive Alignment,doc2549013.json,https://github.com/HVision-NKU/ImageCritic,https://huggingface.co/papers/2511.20614,0,"[""imagecritic"", ""paper"", ""reference""]"
doc2549014,Geometrically-Constrained Agent for Spatial Reasoning,doc2549014.json,https://github.com/gca-spatial-reasoning/gca,https://huggingface.co/papers/2511.22659,0,"[""reasoning"", ""gca"", ""semantic""]"
doc2549015,TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models,doc2549015.json,,https://huggingface.co/papers/2512.02014,0,"[""unified"", ""generation"", ""paper""]"
doc2549016,LFM2 Technical Report,doc2549016.json,,https://huggingface.co/papers/2511.23404,0,"[""lfm2"", ""models"", ""strong""]"
doc2549017,Architecture Decoupling Is Not All You Need For Unified Multimodal Model,doc2549017.json,https://github.com/zhengdian1/AIA,https://huggingface.co/papers/2511.22663,0,"[""decoupling"", ""generation"", ""attention""]"
doc2549018,"Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models",doc2549018.json,https://github.com/screemix/Wikontic,https://huggingface.co/papers/2512.00590,0,"[""wikontic"", ""kgs"", ""quality""]"
doc2549019,CaptionQA: Is Your Caption as Useful as the Image Itself?,doc2549019.json,https://github.com/bronyayang/CaptionQA,https://huggingface.co/papers/2511.21025,0,"[""utility"", ""captions"", ""image""]"
doc2549020,Flash-DMD: Towards High-Fidelity Few-Step Image Generation with Efficient Distillation and Joint Reinforcement Learning,doc2549020.json,,https://huggingface.co/papers/2511.20549,0,"[""training"", ""models"", ""distillation""]"
doc2549021,DiP: Taming Diffusion Models in Pixel Space,doc2549021.json,,https://huggingface.co/papers/2511.18822,0,"[""dip"", ""diffusion"", ""generation""]"
doc2549022,Rectifying LLM Thought from Lens of Optimization,doc2549022.json,https://github.com/open-compass/RePro,https://huggingface.co/papers/2512.01925,0,"[""reasoning"", ""process"", ""cot""]"
doc2549023,VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference,doc2549023.json,https://github.com/mit-han-lab/vlash,https://huggingface.co/papers/2512.01031,0,"[""vlash"", ""vlas"", ""execution""]"
doc2549024,DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action,doc2549024.json,,https://huggingface.co/papers/2511.22134,0,"[""action"", ""data"", ""vla""]"
doc2549025,DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models,doc2549025.json,,https://huggingface.co/papers/2512.02556,0,"[""deepseek"", ""v3"", ""deepseek v3""]"
doc2549026,Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models,doc2549026.json,,https://huggingface.co/papers/2511.23319,0,"[""context"", ""long"", ""attention""]"
doc2549027,GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation,doc2549027.json,,https://huggingface.co/papers/2512.01801,0,"[""rl"", ""gr rl"", ""gr""]"
doc2549028,Adversarial Flow Models,doc2549028.json,,https://huggingface.co/papers/2511.22475,0,"[""models"", ""flow"", ""af""]"
doc2549029,Guided Self-Evolving LLMs with Minimal Human Supervision,doc2549029.json,,https://huggingface.co/papers/2512.02472,0,"[""human"", ""self"", ""training""]"
doc2549030,Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models,doc2549030.json,,https://huggingface.co/papers/2511.18890,0,"[""latency"", ""real"", ""accuracy""]"
doc2549031,InternVideo-Next: Towards General Video Foundation Models without Video-Text Supervision,doc2549031.json,,https://huggingface.co/papers/2512.01342,0,"[""level"", ""stage"", ""pixel""]"
doc2549032,"Decoupled DMD: CFG Augmentation as the Spear, Distribution Matching as the Shield",doc2549032.json,https://github.com/Tongyi-MAI/Z-Image/tree/main,https://huggingface.co/papers/2511.22677,0,"[""distillation"", ""matching"", ""step""]"
doc2549033,SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs,doc2549033.json,,https://huggingface.co/papers/2512.00722,0,"[""specontext"", ""model"", ""paper""]"
doc2549034,Flow Straighter and Faster: Efficient One-Step Generative Modeling via MeanFlow on Rectified Trajectories,doc2549034.json,https://github.com/Xinxi-Zhang/Re-MeanFlow,https://huggingface.co/papers/2511.23342,0,"[""rectified"", ""meanflow"", ""step""]"
doc2549035,RefineBench: Evaluating Refinement Capability of Language Models via Checklists,doc2549035.json,https://github.com/RefineBench/refinebench-eval,https://huggingface.co/papers/2511.22173,0,"[""refinement"", ""lms"", ""self""]"
doc2549036,Accelerating Streaming Video Large Language Models via Hierarchical Token Compression,doc2549036.json,https://github.com/lern-to-write/STC,https://huggingface.co/papers/2512.00891,0,"[""stc"", ""textbf"", ""llm""]"
doc2549037,Where Culture Fades: Revealing the Cultural Gap in Text-to-Image Generation,doc2549037.json,,https://huggingface.co/papers/2511.17282,0,"[""cultural"", ""models"", ""paper""]"
doc2549038,Does Hearing Help Seeing? Investigating Audio-Video Joint Denoising for Video Generation,doc2549038.json,https://github.com/jianzongwu/Does-Hearing-Help-Seeing,https://huggingface.co/papers/2512.02457,0,"[""video"", ""audio"", ""https""]"
doc2549039,PromptBridge: Cross-Model Prompt Transfer for Large Language Models,doc2549039.json,,https://huggingface.co/papers/2512.01420,0,"[""model"", ""prompt"", ""promptbridge""]"
doc2549040,SCALE: Selective Resource Allocation for Overcoming Performance Bottlenecks in Mathematical Test-time Scaling,doc2549040.json,https://github.com/XiaoYang66/DualThinking,https://huggingface.co/papers/2512.00466,0,"[""sub"", ""sub problems"", ""problems""]"
doc2549041,MultiBanana: A Challenging Benchmark for Multi-Reference Text-to-Image Generation,doc2549041.json,https://github.com/matsuolab/multibanana,https://huggingface.co/papers/2511.22989,0,"[""reference"", ""multi reference"", ""multi""]"
doc2549042,Captain Safari: A World Engine,doc2549042.json,,https://huggingface.co/papers/2511.22815,0,"[""camera"", ""world"", ""long""]"
doc2549043,World in a Frame: Understanding Culture Mixing as a New Challenge for Vision-Language Models,doc2549043.json,,https://huggingface.co/papers/2511.22787,0,"[""food"", ""cultural"", ""background""]"
doc2549044,Script: Graph-Structured and Query-Conditioned Semantic Token Pruning for Multimodal Large Language Models,doc2549044.json,,https://huggingface.co/papers/2512.01949,0,"[""script"", ""comment"", ""pruning""]"
doc2549045,DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models,doc2549045.json,https://github.com/BeingBeyond/DiG-Flow,https://huggingface.co/papers/2512.01715,0,"[""flow"", ""dig"", ""dig flow""]"
doc2549046,Lotus-2: Advancing Geometric Dense Prediction with Powerful Image Generative Model,doc2549046.json,https://github.com/EnVision-Research/Lotus-2,https://huggingface.co/papers/2512.01030,0,"[""lotus"", ""geometric"", ""https""]"
doc2549047,DualCamCtrl: Dual-Branch Diffusion Model for Geometry-Aware Camera-Controlled Video Generation,doc2549047.json,https://github.com/EnVision-Research/DualCamCtrl,https://huggingface.co/papers/2511.23127,0,"[""dualcamctrl"", ""https"", ""camera""]"
doc2549048,HiconAgent: History Context-aware Policy Optimization for GUI Agents,doc2549048.json,https://github.com/JiuTian-VL/HiconAgent,https://huggingface.co/papers/2512.01763,0,"[""history"", ""gui"", ""context""]"
doc2549049,StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos,doc2549049.json,https://github.com/daeunni/StreamGaze,https://huggingface.co/papers/2512.01707,0,"[""gaze"", ""streaming"", ""streamgaze""]"
doc2549050,The Collapse of Patches,doc2549050.json,https://github.com/wguo-ai/CoP,https://huggingface.co/papers/2511.22281,0,"[""image"", ""patch"", ""patches""]"
doc2549051,OralGPT-Omni: A Versatile Dental Multimodal Large Language Model,doc2549051.json,https://github.com/isbrycee/OralGPT,https://huggingface.co/papers/2511.22055,0,"[""dental"", ""analysis"", ""oralgpt""]"
doc2549052,SO-Bench: A Structural Output Evaluation of Multimodal LLMs,doc2549052.json,,https://huggingface.co/papers/2511.21750,0,"[""visual"", ""schema"", ""benchmark""]"
doc2549053,POLARIS: Projection-Orthogonal Least Squares for Robust and Adaptive Inversion in Diffusion Models,doc2549053.json,https://github.com/Chatonz/POLARIS,https://huggingface.co/papers/2512.00369,0,"[""inversion"", ""step"", ""error""]"
doc2549054,ORION: Teaching Language Models to Reason Efficiently in the Language of Thought,doc2549054.json,,https://huggingface.co/papers/2511.22891,0,"[""reasoning"", ""models"", ""accuracy""]"
doc2549055,Test-time scaling of diffusions with flow maps,doc2549055.json,,https://huggingface.co/papers/2511.22688,0,"[""flow"", ""map"", ""time""]"
doc2549056,Asking like Socrates: Socrates helps VLMs understand remote sensing images,doc2549056.json,https://github.com/GeoX-Lab/Asking_like_Socrates,https://huggingface.co/papers/2511.22396,0,"[""reasoning"", ""rs"", ""evidence""]"
doc2549057,Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information,doc2549057.json,,https://huggingface.co/papers/2511.22176,0,"[""cot"", ""reasoning"", ""input""]"
doc2549058,Glance: Accelerating Diffusion Models with 1 Sample,doc2549058.json,,https://huggingface.co/papers/2512.02899,0,"[""models"", ""lora"", ""generalization""]"
doc2549059,PAI-Bench: A Comprehensive Benchmark For Physical AI,doc2549059.json,https://github.com/SHI-Labs/physical-ai-bench,https://huggingface.co/papers/2512.01989,0,"[""models"", ""physical"", ""physical ai""]"
doc2549060,Agentic Policy Optimization via Instruction-Policy Co-Evolution,doc2549060.json,https://github.com/cambridgeltl/inspo,https://huggingface.co/papers/2512.01945,0,"[""instruction"", ""instructions"", ""inspo""]"
doc2549061,Learning Eigenstructures of Unstructured Data Manifolds,doc2549061.json,,https://huggingface.co/papers/2512.01103,0,"[""operator"", ""data"", ""manifold""]"
doc2549062,From Pixels to Feelings: Aligning MLLMs with Human Cognitive Perception of Images,doc2549062.json,,https://huggingface.co/papers/2511.22805,0,"[""human"", ""properties"", ""image""]"
doc2549063,OmniRefiner: Reinforcement-Guided Local Diffusion Refinement,doc2549063.json,https://github.com/yaoliliu/OmniRefiner,https://huggingface.co/papers/2511.19990,0,"[""image"", ""reference"", ""refinement""]"
doc2549064,The Art of Scaling Test-Time Compute for Large Language Models,doc2549064.json,https://github.com/Aradhye2002/art_of_tts,https://huggingface.co/papers/2512.02008,0,"[""type"", ""paper"", ""problem difficulty""]"
doc2549065,OpenREAD: Reinforced Open-Ended Reasoing for End-to-End Autonomous Driving with LLM-as-Critic,doc2549065.json,https://github.com/wyddmw/OpenREAD,https://huggingface.co/papers/2512.01830,0,"[""driving"", ""open"", ""model""]"
doc2549066,ChronosObserver: Taming 4D World with Hyperspace Diffusion Sampling,doc2549066.json,,https://huggingface.co/papers/2512.01481,0,"[""hyperspace"", ""time"", ""view""]"
doc2549067,Generalist Large Language Models Outperform Clinical Tools on Medical Benchmarks,doc2549067.json,,https://huggingface.co/papers/2512.01191,0,"[""clinical"", ""ai"", ""tools""]"
doc2549068,Seeing the Wind from a Falling Leaf,doc2549068.json,,https://huggingface.co/papers/2512.00762,0,"[""video"", ""paper"", ""end""]"
doc2549069,WiseEdit: Benchmarking Cognition- and Creativity-Informed Image Editing,doc2549069.json,,https://huggingface.co/papers/2512.00387,0,"[""knowledge"", ""editing"", ""image editing""]"
doc2549070,Revisiting the Necessity of Lengthy Chain-of-Thought in Vision-centric Reasoning Generalization,doc2549070.json,,https://huggingface.co/papers/2511.22586,0,"[""cot"", ""reasoning"", ""visual""]"
doc2549071,Layer-Aware Video Composition via Split-then-Merge,doc2549071.json,,https://huggingface.co/papers/2511.20809,0,"[""video"", ""stm"", ""merge""]"
doc2549072,YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection,doc2549072.json,,https://huggingface.co/papers/2511.13344,0,"[""paper"", ""experts"", ""object detection""]"
doc2549073,GUI Exploration Lab: Enhancing Screen Navigation in Agents via Multi-Turn Reinforcement Learning,doc2549073.json,,https://huggingface.co/papers/2512.02423,0,"[""gui"", ""navigation"", ""agent""]"
doc2549074,CauSight: Learning to Supersense for Visual Causal Discovery,doc2549074.json,https://github.com/OpenCausaLab/CauSight,https://huggingface.co/papers/2512.01827,0,"[""causal"", ""https"", ""paper""]"
doc2549075,DreamingComics: A Story Visualization Pipeline via Subject and Layout Customized Generation using Video Models,doc2549075.json,,https://huggingface.co/papers/2512.01686,0,"[""layout"", ""visualization"", ""story""]"
doc2549076,IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages,doc2549076.json,https://github.com/ayushbits/IndicParam,https://huggingface.co/papers/2512.00333,0,"[""indicparam"", ""resource"", ""low""]"
doc2549077,SimScale: Learning to Drive via Real-World Simulation at Scale,doc2549077.json,https://github.com/OpenDriveLab/SimScale,https://huggingface.co/papers/2511.23369,0,"[""world"", ""real"", ""real world""]"
doc2549078,Fast3Dcache: Training-free 3D Geometry Synthesis Acceleration,doc2549078.json,https://github.com/Westlake-AGI-Lab/Fast3Dcache,https://huggingface.co/papers/2511.22533,0,"[""fast3dcache"", ""3d"", ""inference""]"
doc2549079,FedRE: A Representation Entanglement Framework for Model-Heterogeneous Federated Learning,doc2549079.json,https://github.com/AIResearch-Group/FedRE,https://huggingface.co/papers/2511.22265,0,"[""fedre"", ""model"", ""privacy""]"
doc2549080,A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs,doc2549080.json,https://github.com/heyzbw/HuSls,https://huggingface.co/papers/2512.00077,0,"[""balancing"", ""based"", ""walking""]"
doc2549081,Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation,doc2549081.json,,https://huggingface.co/papers/2512.03040,0,"[""video"", ""tasks"", ""spatial""]"
doc2549082,Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench,doc2549082.json,,https://huggingface.co/papers/2512.02942,0,"[""video"", ""scientific"", ""models""]"
doc2549083,YingVideo-MV: Music-Driven Multi-Stage Video Generation,doc2549083.json,,https://huggingface.co/papers/2512.02492,0,"[""videos"", ""camera"", ""music""]"
doc2549084,WorldMM: Dynamic Multimodal Memory Agent for Long Video Reasoning,doc2549084.json,https://github.com/wgcyeo/WorldMM,https://huggingface.co/papers/2512.02425,0,"[""memory"", ""video"", ""multiple""]"
doc2549085,Generative Video Motion Editing with 3D Point Tracks,doc2549085.json,,https://huggingface.co/papers/2512.02015,0,"[""video"", ""editing"", ""object""]"
doc2549086,UnicEdit-10M: A Dataset and Benchmark Breaking the Scale-Quality Barrier via Unified Verification for Reasoning-Enriched Edits,doc2549086.json,,https://huggingface.co/papers/2512.02790,0,"[""quality"", ""scale"", ""model""]"
doc2549087,MEGConformer: Conformer-Based MEG Decoder for Robust Speech and Phoneme Classification,doc2549087.json,https://github.com/neural2speech/libribrain-experiments,https://huggingface.co/papers/2512.01443,0,"[""speech"", ""phoneme"", ""phoneme classification""]"
doc2549088,Doppler-Enhanced Deep Learning: Improving Thyroid Nodule Segmentation with YOLOv5 Instance Segmentation,doc2549088.json,,https://huggingface.co/papers/2512.00639,0,"[""images"", ""yolov5"", ""performance""]"
doc2549089,OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion,doc2549089.json,https://github.com/saikoneru/OmniFusion,https://huggingface.co/papers/2512.00234,0,"[""translation"", ""multimodal"", ""speech""]"
doc2549090,Structured Extraction from Business Process Diagrams Using Vision-Language Models,doc2549090.json,https://github.com/pritamdeka/BPMN-VLM,https://huggingface.co/papers/2511.22448,0,"[""bpmn"", ""vlms"", ""ocr""]"
doc2549091,Xmodel-2.5: 1.3B Data-Efficient Reasoning SLM,doc2549091.json,https://github.com/XiaoduoAILab/Xmodel-2.5,https://huggingface.co/papers/2511.19496,0,"[""xmodel"", ""parameter"", ""xiaoduoailab""]"
doc2549092,MRI Super-Resolution with Deep Learning: A Comprehensive Survey,doc2549092.json,https://github.com/mkhateri/Awesome-MRI-Super-Resolution,https://huggingface.co/papers/2511.16854,0,"[""resolution"", ""super"", ""mri""]"
doc2549093,"Find the Leak, Fix the Split: Cluster-Based Method to Prevent Leakage in Video-Derived Datasets",doc2549093.json,,https://huggingface.co/papers/2511.13944,0,"[""frames"", ""similar"", ""similar frames""]"
doc2549094,Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models,doc2549094.json,,https://huggingface.co/papers/2511.13276,0,"[""videos"", ""ucf"", ""ucf crime""]"

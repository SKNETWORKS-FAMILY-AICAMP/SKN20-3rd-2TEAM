{
  "context": "Z-Image, a 6B-parameter Scalable Single-Stream Diffusion Transformer (S3-DiT) model, achieves high-performance image generation with reduced computational cost, offering sub-second inference and compatibility with consumer hardware. The landscape of high-performance image generation models is currently dominated by proprietary systems, such as Nano Banana Pro and Seedream 4.0. Leading open-source alternatives, including Qwen-Image, Hunyuan-Image-3.0 and FLUX.2, are characterized by massive parameter counts (20B to 80B), making them impractical for inference, and fine-tuning on consumer-grade hardware. To address this gap, we propose Z-Image, an efficient 6B-parameter foundation generative model built upon aScalable Single-Stream Diffusion Transformer(S3-DiT) architecture that challenges the \"scale-at-all-costs\" paradigm. By systematically optimizing the entire model lifecycle -- from a curated data infrastructure to a streamlined training curriculum -- we complete the full training workflow in just 314KH800 GPUhours (approx. $630K). Our few-stepdistillation schemewithreward post-trainingfurther yields Z-Image-Turbo, offering both sub-second inference latency on an enterprise-gradeH800 GPUand compatibility with consumer-grade hardware (<16GBVRAM). Additionally, ouromni-pre-trainingparadigm also enables efficient training of Z-Image-Edit, an editing model with impressiveinstruction-following capabilities. Both qualitative and quantitative experiments demonstrate that our model achieves performance comparable to or surpassing that of leading competitors across various dimensions. Most notably, Z-Image exhibits exceptional capabilities inphotorealistic image generationandbilingual text rendering, delivering results that rival top-tier commercial models, thereby demonstrating that state-of-the-art results are achievable with significantly reduced computational overhead. We publicly release our code, weights, and online demo to foster the development of accessible, budget-friendly, yet state-of-the-art generative models. GitHub:https://github.com/Tongyi-MAI/Z-ImageModelScope:https://modelscope.ai/models/Tongyi-MAI/Z-Image-Turbo/summaryHuggingFace:https://huggingface.co/Tongyi-MAI/Z-Image-TurboZ-Image gallry :https://modelscope.cn/studios/Tongyi-MAI/Z-Image-GalleryComfyUI:https://huggingface.co/Comfy-Org/z_image_turbo This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "paper_name": "Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer",
    "github_url": "https://github.com/Tongyi-MAI/Z-Image",
    "huggingface_url": "https://huggingface.co/papers/2511.22699",
    "upvote": 127,
    "tags": [
      "image",
      "http",
      "mai"
    ]
  }
}
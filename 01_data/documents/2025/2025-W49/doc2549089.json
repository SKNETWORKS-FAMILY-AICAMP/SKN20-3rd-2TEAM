{
  "context": "RS-EoT, a language-driven iterative visual evidence-seeking paradigm, addresses pseudo reasoning in remote sensing tasks by using a self-play multi-agent system and a two-stage RL strategy, achieving state-of-the-art performance on RS VQA benchmarks. Recentmultimodal reasoningmodels, inspired byDeepSeek-R1, have significantly advanced vision-language systems. However, inremote sensing(RS) tasks, we observe widespreadpseudo reasoning: models narrate the process of reasoning rather than genuinely reason toward the correct answer based on visual evidence. We attribute this to theGlance Effect, where a single, coarse perception of large-scale RS imagery results in incomplete understanding and reasoning based on linguistic self-consistency instead of visual evidence. To address this, we proposeRS-EoT(Remote SensingEvidence-of-Thought), alanguage-driven,iterative visual evidence-seekingparadigm. To instill this paradigm, we proposeSocraticAgent, aself-play multi-agentsystem that synthesizesreasoning tracesvia alternating cycles of reasoning andvisual inspection. To enhance and generalize these patterns, we propose a two-stageprogressive RLstrategy: first, RL on fine-grainedGrounding tasksto enhanceRS-EoTcapabilities, followed by RL onRS VQAto generalize to broader understanding scenarios. Experiments showRS-EoTachieves state-of-the-art performance on multipleRS VQAand grounding benchmarks. Analyses reveal clear iterative cycles of reasoning and evidence seeking, confirmingRS-EoTmitigates theGlance Effectand enables genuineevidence-grounded reasoning. Our code, data, and models are available at https://geox-lab.github.io/Asking_like_Socrates Recent multimodal reasoning models, inspired by DeepSeek-R1, have significantly advanced vision-language systems. However, in remote sensing (RS) tasks, we observe widespread pseudo reasoning: models narrate the process of reasoning rather than genuinely reason toward the correct answer based on visual evidence. We attribute this to the Glance Effect, where a single, coarse perception of large-scale RS imagery results in incomplete understanding and reasoning based on linguistic self-consistency instead of visual evidence. To address this, we propose RS-EoT (Remote Sensing Evidence-of-Thought), a language-driven, iterative visual evidence-seeking paradigm. To instill this paradigm, we propose SocraticAgent, a self-play multi-agent system that synthesizes reasoning traces via alternating cycles of reasoning and visual inspection. To enhance and generalize these patterns, we propose a two-stage progressive RL strategy: first, RL on fine-grained Grounding tasks to enhance RS-EoT capabilities, followed by RL on RS VQA to generalize to broader understanding scenarios. Experiments show RS-EoT achieves state-of-the-art performance on multiple RS VQA and grounding benchmarks. Analyses reveal clear iterative cycles of reasoning and evidence seeking, confirming RS-EoT mitigates the Glance Effect and enables genuine evidence-grounded reasoning. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "paper_name": "Asking like Socrates: Socrates helps VLMs understand remote sensing images",
    "github_url": "https://github.com/GeoX-Lab/Asking_like_Socrates",
    "huggingface_url": "https://huggingface.co/papers/2511.22396",
    "upvote": 4,
    "tag1": "reasoning",
    "tag2": "evidence",
    "tag3": "visual"
  }
}
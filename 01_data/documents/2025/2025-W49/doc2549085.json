{
  "context": "PAI-Bench evaluates the perception and prediction capabilities of multi-modal large language models and video generative models, revealing limitations in physical coherence and causal reasoning. Physical AI aims to develop models that can perceive and predict real-world dynamics; yet, the extent to which currentmulti-modal large language modelsandvideo generative modelssupport these abilities is insufficiently understood. We introduce Physical AI Bench (PAI-Bench), a unified and comprehensive benchmark that evaluates perception and prediction capabilities acrossvideo generation,conditional video generation, andvideo understanding, comprising 2,808 real-world cases with task-aligned metrics designed to capturephysical plausibilityanddomain-specific reasoning. Our study provides a systematic assessment of recent models and shows thatvideo generative models, despite strong visual fidelity, often struggle to maintainphysically coherent dynamics, whilemulti-modal large language modelsexhibit limited performance inforecastingandcausal interpretation. These observations suggest that current systems are still at an early stage in handling the perceptual and predictive demands of Physical AI. In summary, PAI-Bench establishes a realistic foundation for evaluating Physical AI and highlights key gaps that future systems must address. Physical AI aims to develop models that can perceive and predict real-world dynamics; yet, the extent to which current multi-modal large language models and video generative models support these abilities is insufficiently understood. We introduce Physical AI Bench (PAI-Bench), a unified and comprehensive benchmark that evaluates perception and prediction capabilities across video generation, conditional video generation, and video understanding, comprising 2,808 real-world cases with task-aligned metrics designed to capture physical plausibility and domain-specific reasoning. Our study provides a systematic assessment of recent models and shows that video generative models, despite strong visual fidelity, often struggle to maintain physically coherent dynamics, while multi-modal large language models exhibit limited performance in forecasting and causal interpretation. These observations suggest that current systems are still at an early stage in handling the perceptual and predictive demands of Physical AI. In summary, PAI-Bench establishes a realistic foundation for evaluating Physical AI and highlights key gaps that future systems must address. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "paper_name": "PAI-Bench: A Comprehensive Benchmark For Physical AI",
    "github_url": "https://github.com/SHI-Labs/physical-ai-bench",
    "huggingface_url": "https://huggingface.co/papers/2512.01989",
    "upvote": 4,
    "tags": [
      "physical",
      "bench",
      "video"
    ]
  }
}
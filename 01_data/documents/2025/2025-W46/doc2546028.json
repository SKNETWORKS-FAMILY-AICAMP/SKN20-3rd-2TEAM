{
  "context": "A text-to-image model trained on long structured captions with DimFusion fusion mechanism and TaBR evaluation protocol achieves state-of-the-art prompt alignment and improved controllability.\nAI-generated summary\nText-to-image models have rapidly evolved from casual creative tools to professional-grade systems, achieving unprecedented levels of image quality and realism. Yet, most models are trained to map short prompts into detailed images, creating a gap between sparse textual input and rich visual outputs. This mismatch reduces controllability, as models often fill in missing details arbitrarily, biasing toward average user preferences and limiting precision for professional use. We address this limitation by training the first open-source text-to-image model on long structured captions, where every training sample is annotated with the same set of fine-grained attributes. This design maximizes expressive coverage and enables disentangled control over visual factors. To process long captions efficiently, we propose DimFusion, a fusion mechanism that integrates intermediate tokens from a lightweight LLM without increasing token length. We also introduce the Text-as-a-Bottleneck Reconstruction (TaBR) evaluation protocol. By assessing how well real images can be reconstructed through a captioning-generation loop, TaBR directly measures controllability and expressiveness, even for very long captions where existing evaluation methods fail. Finally, we demonstrate our contributions by training the large-scale model FIBO, achieving state-of-the-art prompt alignment among open-source models. Model weights are publicly available at https://huggingface.co/briaai/FIBO",
  "metadata": {
    "paper_name": "Generating an Image From 1,000 Words: Enhancing Text-to-Image With Structured Captions",
    "github_url": "https://github.com/Bria-AI/FIBO",
    "huggingface_url": "https://huggingface.co/papers/2511.06876",
    "upvote": 26,
    "tags": [
      "text",
      "image",
      "long"
    ]
  }
}
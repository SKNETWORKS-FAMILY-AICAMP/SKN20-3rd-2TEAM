{
  "context": "Recent progress in large language models (LLMs) has been propelled byreinforcement learning with verifiable rewards(RLVR) andtest-time scaling. However, the limited output length of LLMs constrains the depth of reasoning attainable in a single inference process.Multi-agent reasoning systemsoffer a promising alternative by employing multiple agents includingSolver,Verifier, andCorrector, to iteratively refine solutions. While effective in closed-source models like Gemini 2.5 Pro, they struggle to generalize to open-source models due to insufficient critic and correction capabilities. To address this, we propose MarsRL, a novel reinforcement learning framework withagentic pipeline parallelism, designed to jointly optimize all agents in the system. MarsRL introducesagent-specific reward mechanismsto mitigate reward noise and employspipeline-inspired trainingto enhance efficiency in handling long trajectories. Applied to Qwen3-30B-A3B-Thinking-2507, MarsRL improvesAIME2025accuracy from 86.5% to 93.3% andBeyondAIMEfrom 64.9% to 73.8%, even surpassing Qwen3-235B-A22B-Thinking-2507. These findings highlight the potential of MarsRL to advancemulti-agent reasoning systemsand broaden their applicability across diverse reasoning tasks.",
  "metadata": {
    "paper_name": "MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism",
    "github_url": "https://github.com/liushulinle/MarsRL",
    "huggingface_url": "https://huggingface.co/papers/2511.11373",
    "upvote": "12",
    "tags": [
      "marsrl",
      "reasoning",
      "models"
    ]
  }
}
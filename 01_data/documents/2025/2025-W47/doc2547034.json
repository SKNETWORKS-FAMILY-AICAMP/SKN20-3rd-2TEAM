{
  "context": "Diffusion Transformers, particularly for video generation, achieve remarkable quality but suffer fromquadratic attention complexity, leading to prohibitive latency. Existing acceleration methods face a fundamental trade-off: dynamically estimatingsparse attention patternsat each denoising step incurs high computational overhead and estimation errors, while static sparsity patterns remain fixed and often suboptimal throughout denoising. We identify a key structural property ofdiffusion attention, namely, its sparsity patterns exhibit strong temporal coherence acrossdenoising steps. Tiles deemed non-essential at step t typically remain so at step t+Î´. Leveraging this observation, we introduceLiteAttention, a method that exploits temporal coherence to enableevolutionary computation skipsacross the denoising sequence. By marking non-essential tiles early and propagating skip decisions forward,LiteAttentioneliminates redundant attention computations without repeated profiling overheads, combining the adaptivity of dynamic methods with the efficiency of static ones. We implement a highly optimizedLiteAttentionkernel on top ofFlashAttentionand demonstrate substantial speedups on productionvideo diffusion models, with no degradation in quality. The code and implementation details will be publicly released.",
  "metadata": {
    "paper_name": "LiteAttention: A Temporal Sparse Attention for Diffusion Transformers",
    "github_url": "https://github.com/moonmath-ai/LiteAttention",
    "huggingface_url": "https://huggingface.co/papers/2511.11062",
    "upvote": "29",
    "tags": [
      "attention",
      "denoising",
      "step"
    ]
  }
}
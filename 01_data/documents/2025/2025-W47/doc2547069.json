{
  "context": "We introduceMoS(Mixture of States), a novel fusion paradigm formultimodal diffusion modelsthat merges modalities using flexible, state-based interactions. The core ofMoSis a learnable,token-wise routerthat createsdenoising timestep- andinput-dependent interactionsbetween modalities'hidden states, precisely aligning token-level features with thediffusion trajectory. This router sparsely selects thetop-k hidden statesand is trained with anÎµ-greedy strategy, efficiently selectingcontextual featureswith minimal learnable parameters and negligible computational overhead. We validate our design with text-to-image generation (MoS-Image) and editing (MoS-Editing), which achieve state-of-the-art results. With only 3B to 5B parameters, our models match or surpass counterparts up to 4times larger. These findings establishMoSas a flexible andcompute-efficient paradigmfor scalingmultimodal diffusion models.",
  "metadata": {
    "paper_name": "Mixture of States: Routing Token-Level Dynamics for Multimodal Generation",
    "github_url": null,
    "huggingface_url": "https://huggingface.co/papers/2511.12207",
    "upvote": "6",
    "tags": [
      "diffusion",
      "editing",
      "flexible"
    ]
  }
}
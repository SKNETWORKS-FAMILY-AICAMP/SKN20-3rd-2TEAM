{
  "context": "WhileChain-of-Thought(CoT) prompting enables sophisticated symbolic reasoning inLLMs, it remains confined to discrete text and cannot simulate the continuous, physics-governed dynamics of the real world. Recent video generation models have emerged as potential world simulators throughChain-of-Frames(CoF) reasoning -- materializing thought as frame-by-frame visual sequences, with each frame representing a physically-grounded reasoning step. Despite compelling demonstrations, a challenge persists: existing benchmarks, focusing on fidelity or alignment, do not assess CoF reasoning and thus cannot measure core cognitive abilities in multi-step planning, algorithmic logic, or abstract pattern extrapolation. This evaluation void prevents systematic understanding of model capabilities and principled guidance for improvement. We introduce Gen-ViRe (Generative Visual Reasoning Benchmark), a framework grounded in cognitive science and real-world AI applications, which decomposes CoF reasoning into six cognitive dimensions -- fromperceptual logictoabstract planning-- and 24 subtasks. Through multi-source data curation, minimal prompting protocols, and hybridVLM-assisted evaluationwith detailed criteria, Gen-ViRe delivers the first quantitative assessment of video models as reasoners. Our experiments on SOTA systems reveal substantial discrepancies between impressive visual quality and actual reasoning depth, establishing baselines and diagnostic tools to advance genuine world simulators.",
  "metadata": {
    "paper_name": "Can World Simulators Reason? Gen-ViRe: A Generative Visual Reasoning Benchmark",
    "github_url": "https://github.com/L-CodingSpace/GVR",
    "huggingface_url": "https://huggingface.co/papers/2511.13853",
    "upvote": "34",
    "tags": [
      "reasoning",
      "world",
      "cof"
    ]
  }
}
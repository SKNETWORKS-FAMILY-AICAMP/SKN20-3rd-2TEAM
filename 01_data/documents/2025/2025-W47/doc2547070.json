{
  "context": "We introduce proactive hearing assistants that automatically identify and separate the wearer's conversation partners, without requiring explicit prompts. Our system operates onegocentric binaural audioand uses the wearer'sself-speechas an anchor, leveragingturn-taking behavioranddialogue dynamicsto inferconversational partnersand suppress others. To enablereal-time,on-device operation, we propose adual-model architecture: alightweight streaming modelruns every 12.5 ms for low-latency extraction of the conversation partners, while a slower model runs less frequently to capture longer-range conversational dynamics. Results on real-world 2- and 3-speaker conversation test sets, collected with binaural egocentric hardware from 11 participants totaling 6.8 hours, showgeneralizationin identifying and isolatingconversational partnersinmulti-conversation settings. Our work marks a step toward hearing assistants that adapt proactively to conversational dynamics and engagement. More information can be found on our website: https://proactivehearing.cs.washington.edu/",
  "metadata": {
    "paper_name": "Proactive Hearing Assistants that Isolate Egocentric Conversations",
    "github_url": "https://github.com/guilinhu/proactive_hearing_assistant",
    "huggingface_url": "https://huggingface.co/papers/2511.11473",
    "upvote": "6",
    "tags": [
      "conversation",
      "assistants",
      "binaural"
    ]
  }
}
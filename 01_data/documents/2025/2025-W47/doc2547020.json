{
  "context": "What role does the first frame play invideo generation models? Traditionally, it's viewed as the spatial-temporal starting point of a video, merely a seed for subsequent animation. In this work, we reveal a fundamentally different perspective: video models implicitly treat the first frame as aconceptual memory bufferthat stores visual entities for later reuse during generation. Leveraging this insight, we show that it's possible to achieve robust and generalized video content customization in diverse scenarios, using only 20-50 training examples without architectural changes or large-scale finetuning. This unveils a powerful, overlooked capability ofvideo generation modelsforreference-based video customization.",
  "metadata": {
    "paper_name": "First Frame Is the Place to Go for Video Content Customization",
    "github_url": "https://github.com/zli12321/FFGO-Video-Customization?tab=readme-ov-file",
    "huggingface_url": "https://huggingface.co/papers/2511.15700",
    "upvote": "52",
    "tags": [
      "video",
      "generation",
      "customization"
    ]
  }
}
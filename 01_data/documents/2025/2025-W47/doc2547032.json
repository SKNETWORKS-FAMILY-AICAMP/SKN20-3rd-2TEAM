{
  "context": "The advent ofUnified Multimodal Models(UMMs) signals a paradigm shift in artificial intelligence, moving from passive perception to active, cross-modal generation. Despite their unprecedented ability to synthesize information, a critical gap persists inevaluation: existingbenchmarks primarily assessdiscriminative understandingorunconstrained image generationseparately, failing to measure the integrated cognitive process ofgenerative reasoning. To bridge this gap, we propose thatgeometric constructionprovides an ideal testbed as it inherently demands a fusion oflanguage comprehensionand precisevisual generation. We introduce GGBench, abenchmarkdesigned specifically to evaluate geometricgenerative reasoning. It provides a comprehensive framework for systematically diagnosing a model's ability to not only understand and reason but to actively construct a solution, thereby setting a more rigorous standard for the next generation of intelligent systems. Project website: https://opendatalab-raiser.github.io/GGBench/.",
  "metadata": {
    "paper_name": "GGBench: A Geometric Generative Reasoning Benchmark for Unified Multimodal Models",
    "github_url": null,
    "huggingface_url": "https://huggingface.co/papers/2511.11134",
    "upvote": "31",
    "tags": [
      "generation",
      "ability",
      "gap"
    ]
  }
}
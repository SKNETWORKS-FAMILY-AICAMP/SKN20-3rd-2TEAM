{
  "context": "The applicability of current lesion segmentation models for chest X-rays (CXRs) has been limited both by a small number of target labels and the reliance on long, detailed expert-level text inputs, creating a barrier to practical use. To address these limitations, we introduce a new paradigm:instruction-guided lesion segmentation(ILS), which is designed to segment diverse lesion types based on simple, user-friendly instructions. Under this paradigm, we constructMIMIC-ILS, the first large-scale instruction-answer dataset for CXR lesion segmentation, using our fully automatedmultimodal pipelinethat generates annotations from chest X-ray images and their corresponding reports.MIMIC-ILScontains 1.1M instruction-answer pairs derived from 192K images and 91K unique segmentation masks, covering seven major lesion types. To empirically demonstrate its utility, we introduce ROSALIA, avision-language modelfine-tuned onMIMIC-ILS. ROSALIA can segment diverse lesions and provide textual explanations in response to user instructions. The model achieves high segmentation and textual accuracy in our newly proposed task, highlighting the effectiveness of our pipeline and the value ofMIMIC-ILSas a foundational resource forpixel-level CXR lesion grounding.",
  "metadata": {
    "paper_name": "Instruction-Guided Lesion Segmentation for Chest X-rays with Automatically Generated Large-Scale Dataset",
    "github_url": null,
    "huggingface_url": "https://huggingface.co/papers/2511.15186",
    "upvote": "25",
    "tags": [
      "lesion",
      "segmentation",
      "ils"
    ]
  }
}
{
  "context": "AI research agentsoffer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure ofagent trajectoriesare not fully understood. We examine the role thatideation diversityplays in agent performance. First, we analyseagent trajectoriesonMLE-bench, a well-known benchmark to evaluateAI research agents, across different models andagent scaffolds. Our analysis reveals that different models andagent scaffoldsyield varying degrees ofideation diversity, and that higher-performing agents tend to have increasedideation diversity. Further, we run a controlled experiment where we modify the degree ofideation diversity, demonstrating that higherideation diversityresults in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring ofMLE-bench, showing that our findings still hold across other agent performance metrics.",
  "metadata": {
    "paper_name": "What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity",
    "github_url": null,
    "huggingface_url": "https://huggingface.co/papers/2511.15593",
    "upvote": "54",
    "tags": [
      "diversity",
      "models",
      "performance"
    ]
  }
}
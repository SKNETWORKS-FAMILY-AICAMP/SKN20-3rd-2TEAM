{
  "context": "Recent progress ingenerative video models, such asVeo-3, has shown surprisingzero-shot reasoningabilities, creating a growing need for systematic and reliable evaluation. We introduce V-ReasonBench, abenchmarkdesigned to assess video reasoning across four key dimensions:structured problem-solving,spatial cognition,pattern-based inference, andphysical dynamics. Thebenchmarkis built from both synthetic andreal-world image sequencesand provides a diverse set ofanswer-verifiable tasksthat arereproducible,scalable, andunambiguous. Evaluations of six state-of-the-art video models reveal clear dimension-wise differences, with strong variation in structured, spatial, pattern-based, and physical reasoning. We further compare video models with strong image models, analyze common hallucination behaviors, and study how video duration affectsChain-of-Frames reasoning. Overall, V-ReasonBench offers a unified andreproducibleframework for measuring video reasoning and aims to support the development of models with more reliable,human-aligned reasoning skills.",
  "metadata": {
    "paper_name": "V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models",
    "github_url": "https://github.com/yangluo7/V-ReasonBench",
    "huggingface_url": "https://huggingface.co/papers/2511.16668",
    "upvote": "53",
    "tags": [
      "video",
      "models",
      "reasoning"
    ]
  }
}
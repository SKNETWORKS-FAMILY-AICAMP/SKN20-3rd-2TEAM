{
  "context": "Large Language Models(LLMs) have greatly advancedknowledge graph question answering(KGQA), yet existing systems are typically optimized for returning highly relevant but predictable answers. A missing yet desired capacity is to exploitLLMsto suggest surprise and novel (\"serendipitious\") answers. In this paper, we formally define theserendipity-aware KGQAtask and propose theSerenQAframework to evaluateLLMs' ability to uncover unexpected insights in scientificKGQAtasks.SerenQAincludes a rigorousserendipity metricbased on relevance, novelty, and surprise, along with an expert-annotated benchmark derived from the Clinical Knowledge Graph, focused ondrug repurposing. Additionally, it features a structured evaluation pipeline encompassing three subtasks:knowledge retrieval,subgraph reasoning, andserendipity exploration. Our experiments reveal that while state-of-the-artLLMsperform well on retrieval, they still struggle to identify genuinely surprising and valuable discoveries, underscoring a significant room for future improvements. Our curated resources and extended version are released at: https://cwru-db-group.github.io/serenQA.",
  "metadata": {
    "paper_name": "Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing",
    "github_url": "https://github.com/CWRU-DB-Group/DrugKG",
    "huggingface_url": "https://huggingface.co/papers/2511.12472",
    "upvote": "5",
    "tags": [
      "answers",
      "graph",
      "knowledge"
    ]
  }
}
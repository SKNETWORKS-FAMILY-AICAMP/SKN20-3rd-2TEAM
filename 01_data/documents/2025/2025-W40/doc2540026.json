{
    "context": "StockBench evaluates large language models in realistic stock trading environments, revealing challenges and opportunities in developing LLM-powered financial agents. Large language models(LLMs) have recently demonstrated strong capabilities\nas autonomous agents, showing promise inreasoning,tool use, and sequential\ndecision-making. While prior benchmarks have evaluatedLLM agentsin domains\nsuch assoftware engineeringandscientific discovery, thefinance domainremains underexplored, despite its direct relevance to economic value and\nhigh-stakes decision-making. Existingfinancial benchmarksprimarily test\nstatic knowledge throughquestion answering, but they fall short of capturing\nthe dynamic and iterative nature of trading. To address this gap, we introduce\nStockBench, acontamination-free benchmarkdesigned to evaluateLLM agentsin\nrealistic, multi-month stock trading environments. Agents receive daily market\nsignals -- includingprices,fundamentals, andnews-- and must make sequential\nbuy,sell, orhold decisions. Performance is assessed using financial metrics\nsuch ascumulative return,maximum drawdown, and theSortino ratio. Our\nevaluation of state-of-the-art proprietary (e.g.,GPT-5,Claude-4) and\nopen-weight (e.g.,Qwen3,Kimi-K2,GLM-4.5) models shows that while most LLM\nagents struggle to outperform the simplebuy-and-hold baseline, several models\ndemonstrate the potential to deliver higher returns and manage risk more\neffectively. These findings highlight both the challenges and opportunities in\ndeveloping LLM-powered financial agents, showing that excelling at static\nfinancial knowledge tasks does not necessarily translate into successfultrading strategies. We release StockBench as an open-source resource to support\nreproducibility and advance future research in this domain. Large language models (LLMs) have recently demonstrated strong capabilities as autonomous agents, showing promise in reasoning, tool use, and sequential decision-making. While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making. Existing financial benchmarks primarily test static knowledge through question answering, but they fall short of capturing the dynamic and iterative nature of trading. To address this gap, we introduce StockBench, a contamination-free benchmark designed to evaluate LLM agents in realistic, multi-month stock trading environments. Agents receive daily market signals -- including prices, fundamentals, and news -- and must make sequential buy, sell, or hold decisions. Performance is assessed using financial metrics such as cumulative return, maximum drawdown, and the Sortino ratio. Our evaluation of state-of-the-art proprietary (e.g., GPT-5, Claude-4) and open-weight (e.g., Qwen3, Kimi-K2, GLM-4.5) models shows that while most LLM agents struggle to outperform the simple buy-and-hold baseline, several models demonstrate the potential to deliver higher returns and manage risk more effectively. These findings highlight both the challenges and opportunities in developing LLM-powered financial agents, showing that excelling at static financial knowledge tasks does not necessarily translate into successful trading strategies. We release StockBench as an open-source resource to support reproducibility and advance future research in this domain. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend really cool paper! fascinating! Â·Sign uporlog into comment",
    "metadata": {
        "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world\n  Markets?",
        "authors": [
            "Yanxu Chen"
        ],
        "publication_year": 2025,
        "github_url": "",
        "huggingface_url": "https://huggingface.co/papers/2510.02209",
        "upvote": 52
    }
}
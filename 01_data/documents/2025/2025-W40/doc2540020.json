{
    "context": "StableToken, a multi-branch consensus-driven tokenizer, enhances token stability and robustness in speech processing, improving SpeechLLMs' performance under noisy conditions. Prevalentsemantic speech tokenizers, designed to capture linguistic content,\nare surprisingly fragile. We find they are not robust to meaning-irrelevantacoustic perturbations; even at highSignal-to-Noise Ratios(SNRs) where speech\nis perfectly intelligible, their output token sequences can change drastically,\nincreasing thelearning burdenfordownstream LLMs. This instability stems from\ntwo flaws: abrittle single-path quantizationarchitecture and a distanttraining signalindifferent to intermediatetoken stability. To address this,\nwe introduce StableToken, a tokenizer that achieves stability through a\nconsensus-driven mechanism. Itsmulti-branch architectureprocesses audio in\nparallel, and these representations are merged via a powerful bit-wise voting\nmechanism to form a single, stable token sequence. StableToken sets a new\nstate-of-the-art intoken stability, drastically reducingUnit Edit Distance(UED) under diverse noise conditions. This foundational stability translates\ndirectly to downstream benefits, significantly improving the robustness ofSpeechLLMson a variety of tasks. Prevalent semantic speech tokenizers, designed to capture linguistic content, are surprisingly fragile. We find they are not robust to meaning-irrelevant acoustic perturbations; even at high Signal-to-Noise Ratios (SNRs) where speech is perfectly intelligible, their output token sequences can change drastically, increasing the learning burden for downstream LLMs. This instability stems from two flaws: a brittle single-path quantization architecture and a distant training signal indifferent to intermediate token stability. To address this, we introduce StableToken, a tokenizer that achieves stability through a consensus-driven mechanism. Its multi-branch architecture processes audio in parallel, and these representations are merged via a powerful bit-wise voting mechanism to form a single, stable token sequence. StableToken sets a new state-of-the-art in token stability, drastically reducing Unit Edit Distance (UED) under diverse noise conditions. This foundational stability translates directly to downstream benefits, significantly improving the robustness of SpeechLLMs on a variety of tasks.   This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
    "metadata": {
        "title": "StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient\n  SpeechLLMs",
        "authors": [
            "Yuhan Song"
        ],
        "publication_year": 2025,
        "github_url": "",
        "huggingface_url": "https://huggingface.co/papers/2509.22220",
        "upvote": 65
    }
}
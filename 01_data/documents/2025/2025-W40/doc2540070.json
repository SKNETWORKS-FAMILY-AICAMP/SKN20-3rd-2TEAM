{
    "context": "Rolling Forcing is a novel video generation technique that reduces error accumulation in long video streams by using joint denoising, attention sink mechanism, and efficient training with non-overlapping windows. Streaming video generation, as one fundamental component in interactive world\nmodels and neural game engines, aims to generate high-quality, low-latency, and\ntemporally coherent long video streams. However, most existing work suffers\nfrom severeerror accumulationthat often significantly degrades the generated\nstream videos over long horizons. We design Rolling Forcing, a novel video\ngeneration technique that enables streaming long videos with minimal error\naccumulation. Rolling Forcing comes with three novel designs. First, instead of\niteratively sampling individual frames, which accelerates error propagation, we\ndesign ajoint denoisingscheme that simultaneously denoises multiple frames\nwith progressively increasing noise levels. This design relaxes the strict\ncausality across adjacent frames, effectively suppressing error growth. Second,\nwe introduce theattention sink mechanisminto the long-horizon stream video\ngeneration task, which allows the model to keep key value states of initial\nframes as aglobal context anchorand thereby enhances long-term global\nconsistency. Third, we design anefficient training algorithmthat enablesfew-step distillationover largely extendeddenoising windows. This algorithm\noperates on non-overlapping windows and mitigatesexposure biasconditioned on\nself-generated histories. Extensive experiments show that Rolling Forcing\nenables real-time streaming generation of multi-minute videos on a single GPU,\nwith substantially reducederror accumulation. Streaming video generation, as one fundamental component in interactive world models and neural game engines, aims to generate high-quality, low-latency, and temporally coherent long video streams. However, most existing work suffers from severe error accumulation that often significantly degrades the generated stream videos over long horizons. We design Rolling Forcing, a novel video generation technique that enables streaming long videos with minimal error accumulation. Rolling Forcing comes with three novel designs. First, instead of iteratively sampling individual frames, which accelerates error propagation, we design a joint denoising scheme that simultaneously denoises multiple frames with progressively increasing noise levels. This design relaxes the strict causality across adjacent frames, effectively suppressing error growth. Second, we introduce the attention sink mechanism into the long-horizon stream video generation task, which allows the model to keep key value states of initial frames as a global context anchor and thereby enhances long-term global consistency. Third, we design an efficient training algorithm that enables few-step distillation over largely extended denoising windows. This algorithm operates on non-overlapping windows and mitigates exposure bias conditioned on self-generated histories. Extensive experiments show that Rolling Forcing enables real-time streaming generation of multi-minute videos on a single GPU, with substantially reduced error accumulation.  https://github.com/TencentARC/RollingForcing Code repo placeholderwill release within Oct. Â·Sign uporlog into comment",
    "metadata": {
        "title": "Rolling Forcing: Autoregressive Long Video Diffusion in Real Time",
        "authors": [
            "Kunhao Liu",
            "Wenbo Hu"
        ],
        "publication_year": 2025,
        "github_url": "https://github.com/TencentARC/RollingForcing",
        "huggingface_url": "https://huggingface.co/papers/2509.25161",
        "upvote": 24
    }
}
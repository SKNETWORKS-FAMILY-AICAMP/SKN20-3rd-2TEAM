{
  "context": "A specialized reward model, EditScore, enables effective reinforcement learning for instruction-guided image editing by providing a high-fidelity reward signal. Instruction-guided image editing has achieved remarkable progress, yet\ncurrent models still face challenges with complex instructions and often\nrequire multiple samples to produce a desired result.Reinforcement Learning(RL) offers a promising solution, but its adoption in image editing has been\nseverely hindered by the lack of a high-fidelity, efficient reward signal. In\nthis work, we present a comprehensive methodology to overcome this barrier,\ncentered on the development of a state-of-the-art, specializedreward model. We\nfirst introduceEditReward-Bench, a comprehensive benchmark to systematically\nevaluatereward models on editing quality. Building on this benchmark, we\ndevelopEditScore, a series ofreward models (7B-72B) for evaluating the\nquality of instruction-guided image editing. Through meticulous data curation\nand filtering,EditScoreeffectively matches the performance of learning\nproprietary VLMs. Furthermore, coupled with an effective self-ensemble strategy\ntailored for the generative nature ofEditScore, our largest variant even\nsurpasses GPT-5 in the benchmark. We then demonstrate that a high-fidelityreward modelis the key to unlocking online RL for image editing. Our\nexperiments show that, while even the largest open-source VLMs fail to provide\nan effective learning signal,EditScoreenables efficient and robust policy\noptimization. Applying our framework to a strong base model,OmniGen2, results\nin a final model that shows a substantial and consistent performance uplift.\nOverall, this work provides the first systematic path from benchmarking toreward modeling to RL training in image editing, showing that a high-fidelity,\ndomain-specializedreward modelis the key to unlocking the full potential of\nRL in this domain. Project Page:https://github.com/VectorSpaceLab/EditScore This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Quick question for the authors, in the Table 2 (Benchmark results on EditReward-Bench). The score for EditScore models is given both for Base and Avg@4, but for the reference models (GPT5 ...) it's not specified if it's Base or Avg@4. Which one is it ? Hi, thank you for interest! all other models are reported with base setting @librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "title": "EditScore: Unlocking Online RL for Image Editing via High-Fidelity\n  Reward Modeling",
    "authors": [
      "Xin Luo",
      "Chenyuan Wu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/VectorSpaceLab/EditScore",
    "huggingface_url": "https://huggingface.co/papers/2509.23909",
    "upvote": 31,
    "tags": []
  }
}
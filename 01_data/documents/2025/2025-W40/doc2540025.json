{
  "context": "OpenGPT-4o-Image, a large-scale dataset with hierarchical task taxonomy and automated generation, significantly improves performance in image generation and editing tasks. The performance ofunified multimodal modelsforimage generationand editing\nis fundamentally constrained by the quality and comprehensiveness of theirtraining data. While existing datasets have covered basic tasks like style\ntransfer and simple object manipulation, they often lack the systematic\nstructure and challenging scenarios required for real-world applications. To\naddress this bottleneck, we introduce OpenGPT-4o-Image, a large-scale dataset\nconstructed using a novel methodology that combineshierarchical task taxonomywithautomated data generation. Our taxonomy not only includes fundamental\ncapabilities such astext renderingandstyle controlbut also introduces\nhighly practical yet challenging categories likescientific imageryfor\nchemistry illustrations andcomplex instruction editingrequiring simultaneous\nexecution of multiple operations. Through an automated pipeline leveraging\nstructured resource pools and GPT-4o, we generate 80k high-qualityinstruction-image pairswithcontrolled diversity, covering 11 major domains\nand 51 subtasks. Extensive experiments show thatfine-tuningleading models on\nour dataset achieves significant performance gains across multiple benchmarks,\nwith improvements of up to 18\\% on editing tasks (UniWorld-V1onImgEdit-Bench)\nand 13% on generation tasks (HarmononGenEval). Our work demonstrates that\nsystematic data construction is key to advancing multimodal AI capabilities. The performance of unified multimodal models for image generation and editing is fundamentally constrained by the quality and comprehensiveness of their training data. While existing datasets have covered basic tasks like style transfer and simple object manipulation, they often lack the systematic structure and challenging scenarios required for real-world applications. To address this bottleneck, we introduce OpenGPT-4o-Image, a large-scale dataset constructed using a novel methodology that combines hierarchical task taxonomy with automated data generation. Our taxonomy not only includes fundamental capabilities such as text rendering and style control but also introduces highly practical yet challenging categories like scientific imagery for chemistry illustrations and complex instruction editing requiring simultaneous execution of multiple operations. Through an automated pipeline leveraging structured resource pools and GPT-4o, we generate 80k high-quality instruction-image pairs with controlled diversity, covering 11 major domains and 51 subtasks. Extensive experiments show that fine-tuning leading models on our dataset achieves significant performance gains across multiple benchmarks, with improvements of up to 18% on editing tasks (UniWorld-V1 on ImgEdit-Bench) and 13% on generation tasks (Harmon on GenEval). Our work demonstrates that systematic data construction is key to advancing multimodal AI capabilities. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "title": "OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation\n  and Editing",
    "authors": [
      "Yang Shi"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2509.24900",
    "upvote": 53,
    "tags": []
  }
}
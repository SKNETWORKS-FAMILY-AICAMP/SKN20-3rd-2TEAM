{
    "context": "RealUnify evaluates the bidirectional synergy between understanding and generation in unified multimodal models, revealing that current models lack effective integration despite architectural unification. The integration of visual understanding and generation into unifiedmultimodal modelsrepresents a significant stride toward general-purpose AI.\nHowever, a fundamental question remains unanswered by existing benchmarks: does\nthis architectural unification actually enable synergetic interaction between\nthe constituent capabilities? Existing evaluation paradigms, which primarily\nassess understanding and generation in isolation, are insufficient for\ndetermining whether a unified model can leverage its understanding to enhance\nits generation, or use generative simulation to facilitate deeper\ncomprehension. To address this critical gap, we introduceRealUnify, a\nbenchmark specifically designed to evaluatebidirectional capability synergy.RealUnifycomprises 1,000 meticulously human-annotated instances spanning 10\ncategories and 32 subtasks. It is structured around two core axes: 1)Understanding Enhances Generation, which requires reasoning (e.g., commonsense,\nlogic) to guide image generation, and 2)Generation Enhances Understanding,\nwhich necessitates mental simulation or reconstruction (e.g., of transformed or\ndisordered visual inputs) to solve reasoning tasks. A key contribution is ourdual-evaluation protocol, which combines direct end-to-end assessment with a\ndiagnostic stepwise evaluation that decomposes tasks into distinct\nunderstanding and generation phases. This protocol allows us to precisely\ndiscern whether performance bottlenecks stem from deficiencies in core\nabilities or from a failure to integrate them. Through large-scale evaluations\nof 12 leadingunified modelsand 6specialized baselines, we find that currentunified modelsstill struggle to achieve effective synergy, indicating that\narchitectural unification alone is insufficient. These results highlight the\nneed for new training strategies and inductive biases to fully unlock the\npotential of unified modeling. The integration of visual understanding and generation into unified multimodal models represents a significant stride toward general-purpose AI. However, a fundamental question remains unanswered by existing benchmarks: does this architectural unification actually enable synergetic interaction between the constituent capabilities? Existing evaluation paradigms, which primarily assess understanding and generation in isolation, are insufficient for determining whether a unified model can leverage its understanding to enhance its generation, or use generative simulation to facilitate deeper comprehension. To address this critical gap, we introduce RealUnify, a benchmark specifically designed to evaluate bidirectional capability synergy. RealUnify comprises 1,000 meticulously human-annotated instances spanning 10 categories and 32 subtasks. It is structured around two core axes: 1) Understanding Enhances Generation, which requires reasoning (e.g., commonsense, logic) to guide image generation, and 2) Generation Enhances Understanding, which necessitates mental simulation or reconstruction (e.g., of transformed or disordered visual inputs) to solve reasoning tasks. A key contribution is our dual-evaluation protocol, which combines direct end-to-end assessment with a diagnostic stepwise evaluation that decomposes tasks into distinct understanding and generation phases. This protocol allows us to precisely discern whether performance bottlenecks stem from deficiencies in core abilities or from a failure to integrate them. Through large-scale evaluations of 12 leading unified models and 6 specialized baselines, we find that current unified models still struggle to achieve effective synergy, indicating that architectural unification alone is insufficient. These results highlight the need for new training strategies and inductive biases to fully unlock the potential of unified modeling. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
    "metadata": {
        "title": "RealUnify: Do Unified Models Truly Benefit from Unification? A\n  Comprehensive Benchmark",
        "authors": [
            "Yang Shi",
            "Yuhao Dong",
            "Yuran Wang",
            "Haochen Tian",
            "Zuyan Liu",
            "Xinlong Chen",
            "Bozhou Li"
        ],
        "publication_year": 2025,
        "github_url": "https://github.com/FrankYang-17/RealUnify",
        "huggingface_url": "https://huggingface.co/papers/2509.24897",
        "upvote": 46
    }
}
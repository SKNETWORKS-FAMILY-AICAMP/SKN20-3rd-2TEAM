{
    "context": "LongCodeZip is a code compression framework for LLMs that uses dual-stage compression to reduce context size without degrading performance, improving efficiency in code intelligence applications. Code generation under long contexts is becoming increasingly critical asLarge Language Models(LLMs) are required to reason over extensive information\nin the codebase. While recent advances enablecode LLMsto process long inputs,\nhigh API costs and generation latency remain substantial bottlenecks. Existingcontext pruningtechniques, such asLLMLingua, achieve promising results for\ngeneral text but overlook code-specific structures and dependencies, leading to\nsuboptimal performance in programming tasks. In this paper, we propose\nLongCodeZip, a novel plug-and-play code compression framework designed\nspecifically forcode LLMs. LongCodeZip employs a dual-stage strategy: (1)\ncoarse-grained compression, which identifies and ranksfunction-level chunksusingconditional perplexitywith respect to the instruction, retaining only\nthe most relevant functions; and (2)fine-grained compression, which segments\nretained functions into blocks based on perplexity and selects an optimal\nsubset under an adaptivetoken budgetto maximize relevance. Evaluations across\nmultiple tasks, includingcode completion, summarization, and question\nanswering, show that LongCodeZip consistently outperforms baseline methods,\nachieving up to a 5.6x compression ratio without degrading task performance. By\neffectively reducing context size while preserving essential information,\nLongCodeZip enables LLMs to better scale to real-world, large-scale code\nscenarios, advancing the efficiency and capability of code intelligence\napplications. How to compress long code context? üìö Check out our LongCodeZip! Paper just got accepted to ASE 2025. üî• Code:https://github.com/YerbaPage/LongCodeZipPaper:https://huggingface.co/papers/2510.00446 Congratulation boys!! Ranks function-level chunks conditional perplexions relative to the instruction, proportionating the ATB.This is awesome work, guys! Congratulations! üî•üëè  This is promising will try ! This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend wc nbüëç You deserve all the best! ¬∑Sign uporlog into comment",
    "metadata": {
        "title": "LongCodeZip: Compress Long Context for Code Language Models",
        "authors": [
            "Yuling Shi",
            "Yichun Qian"
        ],
        "publication_year": 2025,
        "github_url": "https://github.com/YerbaPage/LongCodeZip",
        "huggingface_url": "https://huggingface.co/papers/2510.00446",
        "upvote": 108
    }
}
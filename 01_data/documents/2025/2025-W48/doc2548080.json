{
  "context": "Realistic 3D city generation is fundamental to a wide range of applications, including virtual reality and digital twins. However, most existing methods rely on training a single diffusion model , which limits their ability to generate personalized and boundless city-scale scenes. In this paper, we present Yo'City, a novel agentic framework that enables user-customized and infinitely expandable 3D city generation by leveraging the reasoning and compositional capabilities of off-the-shelf large models. Specifically, Yo'City first conceptualize the city through a top-down planning strategy that defines a hierarchical \" City-District-Grid \" structure. The Global Planner determines the overall layout and potential functional districts, while the Local Designer further refines each district with detailed grid-level descriptions. Subsequently, the grid-level 3D generation is achieved through a \" produce-refine-evaluate \" isometric image synthesis loop, followed by image-to-3D generation . To simulate continuous city evolution, Yo'City further introduces a user-interactive, relationship-guided expansion mechanism, which performs scene graph -based distance- and semantics-aware layout optimization , ensuring spatially coherent city growth. To comprehensively evaluate our method, we construct a diverse benchmark dataset and design six multi-dimensional metrics that assess generation quality from the perspectives of semantics, geometry, texture, and layout. Extensive experiments demonstrate that Yo'City consistently outperforms existing state-of-the-art methods across all evaluation aspects.",
  "metadata": {
    "paper_name": "Yo'City: Personalized and Boundless 3D Realistic City Scene Generation via Self-Critic Expansion",
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.18734",
    "upvote": 6,
    "tags": [
      "city",
      "generation",
      "yo city"
    ]
  }
}
{
  "context": "Large Language Models (LLMs) demonstrate partial forecasting competence across social, political, and economic events. Yet, their predictive ability varies sharply with domain structure and prompt framing . We investigate how forecasting performance varies with different model families on real-world questions about events that happened beyond the model cutoff date . We analyze how context , question type , and external knowledge affect accuracy and calibration , and how adding factual news context modifies belief formation and failure modes . Our results show that forecasting ability is highly variable as it depends on what, and how, we ask.",
  "metadata": {
    "paper_name": "Future Is Unevenly Distributed: Forecasting Ability of LLMs Depends on What We're Asking",
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.18394",
    "upvote": 1,
    "tags": [
      "forecasting",
      "varies",
      "events"
    ]
  }
}
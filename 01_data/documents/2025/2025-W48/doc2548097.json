{
  "context": "Recent advancements in multimodal large language models (MLLMs) and video agent systems have significantly improved general video understanding. However, when applied to scientific video understanding and educating, a domain that demands external professional knowledge integration and rigorous step-wise reasoning, existing approaches often struggle. To bridge this gap, we propose SciEducator, the first iterative self-evolving multi-agent system for scientific video comprehension and education. Rooted in the classical Deming Cycle from management science, our design reformulates its Plan-Do-Study-Act philosophy into a self-evolving reasoning and feedback mechanism, which facilitates the interpretation of intricate scientific activities in videos. Moreover, SciEducator can produce multimodal educational content tailored to specific scientific processes, including textual instructions , visual guides , audio narrations , and interactive references . To support evaluation, we construct SciVBench , a benchmark consisting of 500 expert-verified and literature-grounded science QA pairs across five categories, covering physical, chemical, and everyday phenomena . Extensive experiments demonstrate that SciEducator substantially outperforms leading closed-source MLLMs (e.g., Gemini, GPT-4o) and state-of-the-art video agents on the benchmark, establishing a new paradigm for the community.",
  "metadata": {
    "paper_name": "SciEducator: Scientific Video Understanding and Educating via Deming-Cycle Multi-Agent System",
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.17943",
    "upvote": 2,
    "tags": [
      "video",
      "scientific",
      "scieducator"
    ]
  }
}
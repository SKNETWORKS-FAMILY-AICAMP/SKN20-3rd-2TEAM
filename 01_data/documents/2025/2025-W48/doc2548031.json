{
  "context": "Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only \"thinking\" in tokens but also \"acting\" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack \"budget awareness\" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker , a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS ( Budget Aware Test-time Scaling ), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to \"dig deeper\" on a promising lead or \"pivot\" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption . We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier . Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.",
  "metadata": {
    "paper_name": "Budget-Aware Tool-Use Enables Effective Agent Scaling",
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.17006",
    "upvote": 24,
    "tags": [
      "tool",
      "scaling",
      "agents"
    ]
  }
}
{
  "context": "Brain-IT uses a Brain Interaction Transformer to reconstruct images from fMRI data with high fidelity, surpassing current methods and requiring less training data.\nReconstructing images seen by people from their fMRI brain recordings provides a non-invasive window into the human brain. Despite recent progress enabled by diffusion models, current methods often lack faithfulness to the actual seen images. We present \"Brain-IT\", a brain-inspired approach that addresses this challenge through a Brain Interaction Transformer (BIT), allowing effective interactions between clusters of functionally-similar brain-voxels. These functional-clusters are shared by all subjects, serving as building blocks for integrating information both within and across brains. All model components are shared by all clusters & subjects, allowing efficient training with a limited amount of data. To guide the image reconstruction, BIT predicts two complementary localized patch-level image features: (i)high-level semantic features which steer the diffusion model toward the correct semantic content of the image; and (ii)low-level structural features which help to initialize the diffusion process with the correct coarse layout of the image. BIT's design enables direct flow of information from brain-voxel clusters to localized image features. Through these principles, our method achieves image reconstructions from fMRI that faithfully reconstruct the seen images, and surpass current SotA approaches both visually and by standard objective metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve results comparable to current methods trained on full 40-hour recordings.",
  "metadata": {
    "paper_name": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer",
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2510.25976",
    "upvote": 14,
    "tags": [
      "brain",
      "image",
      "images"
    ]
  }
}
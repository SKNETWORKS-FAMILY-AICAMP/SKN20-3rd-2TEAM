"""
Streamlit UI ì»´í¬ë„ŒíŠ¸ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ HuggingFace DailyPapers RAG ì±—ë´‡ì˜ UI ì»´í¬ë„ŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- ë¦¬ì†ŒìŠ¤ ë¡œë”© (VectorDB, KeywordManager, RAG System)
- ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
- UI ë Œë”ë§ (í—¤ë”, ì±„íŒ…, ì‚¬ì´ë“œë°”)
"""

import streamlit as st
from pathlib import Path
from typing import List, Tuple

# í”„ë¡œì íŠ¸ ê²½ë¡œ
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_DIR = PROJECT_ROOT / "01_data"
SRC_DIR = PROJECT_ROOT / "02_src"

# HuggingFace ìŠ¤íƒ€ì¼ CSS
HUGGINGFACE_STYLE = """
<style>
    /* ë©”ì¸ ì»¨í…Œì´ë„ˆ */
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }

    /* í—¤ë” ìŠ¤íƒ€ì¼ */
    .header-container {
        background: white;
        padding: 2rem;
        border-radius: 1rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        margin-bottom: 2rem;
    }

    /* í‚¤ì›Œë“œ íƒœê·¸ ìŠ¤íƒ€ì¼ */
    .stPills {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
    }

    /* ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .stChatMessage {
        background: white;
        border-radius: 0.75rem;
        padding: 1rem;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 0.5rem;
        padding: 0.5rem 1rem;
        font-weight: 600;
        transition: all 0.3s ease;
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    }

    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
    .css-1d391kg {
        background: #f8f9fa;
    }

    /* ë©”íŠ¸ë¦­ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .stMetric {
        background: white;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    /* ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ */
    .stTextInput > div > div > input {
        border-radius: 0.5rem;
        border: 2px solid #e0e0e0;
        padding: 0.75rem;
    }

    /* HuggingFace ë¡œê³  ìƒ‰ìƒ */
    .hf-color {
        color: #FF9D00;
    }

    /* ë…¼ë¬¸ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .paper-card {
        background: white;
        border-radius: 0.75rem;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
        transition: all 0.3s ease;
    }

    .paper-card:hover {
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        transform: translateY(-2px);
    }
</style>
"""

# ==================== ë¦¬ì†ŒìŠ¤ ë¡œë”© ====================

@st.cache_resource
def load_vectorstore():
    """VectorDB ë¡œë“œ (ìºì‹±)

    Returns:
        VectorStore ë˜ëŠ” None: ChromaDB ë²¡í„° ì €ì¥ì†Œ
    """
    try:
        import pickle
        from langchain_openai import OpenAIEmbeddings
        from langchain_chroma import Chroma

        # chunks_all.pkl íŒŒì¼ ë¡œë“œ
        chunks_path = DATA_DIR / "chunks" / "chunks_all.pkl"

        if not chunks_path.exists():
            st.error(f"âŒ chunks_all.pkl íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {chunks_path}")
            return None

        with open(chunks_path, "rb") as f:
            chunks = pickle.load(f)

        # ChromaDB ìƒì„± (in-memory)
        embeddings = OpenAIEmbeddings(model='text-embedding-3-small')
        vectorstore = Chroma.from_documents(
            documents=chunks,
            collection_name='huggingface_papers',
            embedding=embeddings
        )

        st.success(f"âœ… VectorDB ë¡œë“œ ì™„ë£Œ: {len(chunks)}ê°œ ë¬¸ì„œ")
        return vectorstore

    except Exception as e:
        st.error(f"âŒ VectorDB ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        st.error(traceback.format_exc())
        return None


@st.cache_resource
def load_keyword_manager():
    """KeywordManager ë¡œë“œ (ìºì‹±)

    Returns:
        KeywordManager ë˜ëŠ” None: í‚¤ì›Œë“œ ê´€ë¦¬ ê°ì²´
    """
    try:
        # TODO: KeywordManager ë¡œë“œ ë¡œì§ êµ¬í˜„
        # ì˜ˆì‹œ:
        # import sys
        # sys.path.insert(0, str(SRC_DIR / "02_utils"))
        # from documents import load_all_documents
        # from keyword_manager import KeywordManager
        #
        # documents = load_all_documents(year=2025, weeks=[49, 48, 47, 46, 45])
        # km = KeywordManager(documents)
        # return km

        st.info("âš ï¸ KeywordManager ë¡œë“œ ëŒ€ê¸° ì¤‘ - í‚¤ì›Œë“œ ì‹œìŠ¤í…œ ë¯¸êµ¬í˜„")
        return None

    except Exception as e:
        st.error(f"KeywordManager ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


@st.cache_resource
def load_rag_system(_vectorstore):
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ìºì‹±)

    Args:
        _vectorstore: VectorStore ê°ì²´ (ì–¸ë”ìŠ¤ì½”ì–´ëŠ” ìºì‹± ì œì™¸ë¥¼ ìœ„í•œ ê´€ë¡€)

    Returns:
        SimpleRAGSystem ë˜ëŠ” None: RAG ì‹œìŠ¤í…œ ê°ì²´
    """
    try:
        if _vectorstore is None:
            st.warning("âš ï¸ VectorDBê°€ ë¡œë“œë˜ì§€ ì•Šì•„ RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # SimpleRAGSystem ì„í¬íŠ¸
        import sys
        sys.path.insert(0, str(SRC_DIR / "04_rag"))
        from simpleRAGsystem_2 import SimpleRAGSystem
        from langchain_openai import ChatOpenAI

        # LLM ì´ˆê¸°í™”
        llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)

        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (retriever_k=3ìœ¼ë¡œ ìƒìœ„ 3ê°œ ë¬¸ì„œ ê²€ìƒ‰)
        rag_system = SimpleRAGSystem(_vectorstore, llm, retriever_k=3)

        st.success("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        return rag_system

    except Exception as e:
        st.error(f"âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        st.error(traceback.format_exc())
        return None


# ==================== ì„¸ì…˜ ì´ˆê¸°í™” ====================

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

    Streamlit session_stateì— í•„ìš”í•œ ë³€ìˆ˜ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "selected_keyword" not in st.session_state:
        st.session_state.selected_keyword = None  # ë‹¨ì¼ í‚¤ì›Œë“œ

    if "search_mode" not in st.session_state:
        st.session_state.search_mode = "chat"  # "chat" or "keyword"


# ==================== UI ë Œë”ë§ ====================

def render_header(keyword_manager, rag_system=None):
    """í—¤ë”: ì œëª© & íŠ¸ë Œë“œ í‚¤ì›Œë“œ

    Args:
        keyword_manager: KeywordManager ê°ì²´ ë˜ëŠ” None
        rag_system: SimpleRAGSystem ê°ì²´ ë˜ëŠ” None (í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ìš©)
    """
    # HuggingFace ìŠ¤íƒ€ì¼ CSS ì ìš©
    st.markdown(HUGGINGFACE_STYLE, unsafe_allow_html=True)

    # í—¤ë” ì»¨í…Œì´ë„ˆ
    st.markdown("""
        <div style='text-align: center;'>
            <h1 style='color: #FF9D00; font-size: 3rem; margin-bottom: 0.5rem;'>
                ğŸ¤— HuggingFace DailyPapers
            </h1>
            <p style='color: #6c757d; font-size: 1.2rem; margin-top: 0;'>
                RAG ê¸°ë°˜ ìµœì‹  ML/DL/LLM ë…¼ë¬¸ ê²€ìƒ‰ ì±—ë´‡
            </p>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("---")

    # íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì˜ì—­
    st.markdown("### ğŸ”¥ íŠ¸ë Œë”© í‚¤ì›Œë“œ")
    
    # keyword_manager êµ¬í˜„ ì „ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
    if keyword_manager is None:
        st.info("ğŸ’¡ í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
        # ë°ëª¨ìš© ë”ë¯¸ ë°ì´í„°
        trending = [
            ("LLM", 45), ("Transformer", 38), ("RAG", 32),
            ("Vision", 28), ("Diffusion", 25), ("Agent", 22),
            ("Multimodal", 20), ("RL", 18), ("NLP", 15), ("CV", 12)
        ]
    else:
        trending = keyword_manager.get_trending_keywords(
            year=2025,
            weeks=[49, 48, 47, 46, 45],
            top_n=10
        )

    # st.pillsë¡œ í‚¤ì›Œë“œ í‘œì‹œ (ë‹¨ì¼ ì„ íƒìœ¼ë¡œ ë³€ê²½)
    keyword_labels = [f"{kw} ({count})" for kw, count in trending]

    selected = st.pills(
        label="í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì—¬ ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ì„¸ìš”",
        options=keyword_labels,
        selection_mode="single"  # ë‹¨ì¼ ì„ íƒìœ¼ë¡œ ë³€ê²½
    )

    # ì„ íƒëœ í‚¤ì›Œë“œ ì²˜ë¦¬
    if selected:
        # "í‚¤ì›Œë“œ (count)" â†’ "í‚¤ì›Œë“œ" ì¶”ì¶œ (ë‹¨ì¼ ì„ íƒì´ë¯€ë¡œ ë¬¸ìì—´)
        keyword = selected.split(" (")[0]

        # ìƒíƒœ ì—…ë°ì´íŠ¸ (ë‹¨ì¼ í‚¤ì›Œë“œ)
        if keyword != st.session_state.get("selected_keyword", None):
            st.session_state.selected_keyword = keyword

            # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ë©”ì‹œì§€
            query = f"ğŸ“Œ ì„ íƒí•œ í‚¤ì›Œë“œ: {keyword}"

            # RAG ì‹œìŠ¤í…œ ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ì‘ë‹µ ìƒì„±
            if rag_system is None:
                # RAG ì‹œìŠ¤í…œì´ ì—†ìœ¼ë©´ ì˜ˆì‹œ ì‘ë‹µ ì‚¬ìš©
                result_text = get_example_keyword_response(keyword)
            else:
                # ì‹¤ì œ RAG ì‹œìŠ¤í…œìœ¼ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±
                keyword_query = f"{keyword}ì— ëŒ€í•œ ìµœì‹  ì—°êµ¬ ë™í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”."
                result_text = rag_system.ask(keyword_query)

            add_message("user", query)
            add_message("assistant", result_text)

            st.rerun()

    st.markdown("---")


def render_chat_interface(rag_system):
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤

    Args:
        rag_system: SimpleRAGSystem ê°ì²´ ë˜ëŠ” None
    """
    # ì±„íŒ… í—¤ë”
    st.markdown("### ğŸ’¬ ë…¼ë¬¸ ê²€ìƒ‰ ì±„íŒ…")
    
    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar="ğŸ¤—" if message["role"] == "assistant" else "ğŸ‘¤"):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input(
        placeholder="ğŸ” ë…¼ë¬¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
    )

    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(user_input)
        add_message("user", user_input)

        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant", avatar="ğŸ¤—"):
            with st.spinner("ğŸ” ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                # RAG ì‹œìŠ¤í…œì´ ì—†ìœ¼ë©´ ì˜ˆì‹œ ì‘ë‹µ ì‚¬ìš©
                if rag_system is None:
                    # simpleRAGsystem_2.pyì˜ ì¶œë ¥ í˜•ì‹ì„ ì‹œë®¬ë ˆì´ì…˜
                    result = get_example_rag_response(user_input)
                    response_text = result['answer']
                else:
                    # ì‹¤ì œ RAG ì‹œìŠ¤í…œ í˜¸ì¶œ
                    result = rag_system.ask_with_sources(user_input)
                    response_text = result['answer']

            # ì‘ë‹µ í‘œì‹œ
            st.markdown(response_text)

            # ì°¸ì¡° ë…¼ë¬¸ í‘œì‹œ
            sources = result.get('sources', [])
            if sources:
                st.markdown("---")
                with st.expander(f"ğŸ“š ì°¸ì¡°ëœ ë…¼ë¬¸ ({len(sources)}ê°œ)", expanded=True):
                    for i, source in enumerate(sources, 1):
                        render_paper_card(source, i)
            else:
                st.info("ğŸ’¡ ê²€ìƒ‰ëœ ê´€ë ¨ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì €ì¥ (ë‹µë³€ë§Œ ì €ì¥, ì¶œì²˜ëŠ” ì œì™¸)
        add_message("assistant", response_text)

        st.rerun()


def render_sidebar(keyword_manager):
    """ì‚¬ì´ë“œë°”: ì„¤ì • & í†µê³„

    Args:
        keyword_manager: KeywordManager ê°ì²´ ë˜ëŠ” None
    """
    with st.sidebar:
        # ë¡œê³  ì˜ì—­
        st.markdown("""
            <div style='text-align: center; padding: 1rem 0; margin-bottom: 1rem;'>
                <h2 style='color: #FF9D00; margin: 0;'>ğŸ¤—</h2>
                <p style='color: #6c757d; font-size: 0.9rem; margin: 0;'>HuggingFace Papers</p>
            </div>
        """, unsafe_allow_html=True)

        st.markdown("---")

        # ì„¤ì • ì„¹ì…˜
        st.markdown("### âš™ï¸ ì„¤ì •")

        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True, type="primary"):
            st.session_state.messages = []
            st.session_state.selected_keyword = None
            st.rerun()

        # ìºì‹œ ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ìºì‹œ ì´ˆê¸°í™”", use_container_width=True):
            st.cache_resource.clear()
            st.rerun()

        st.markdown("---")

        # í†µê³„ ì„¹ì…˜
        st.markdown("### ğŸ“Š í†µê³„")

        # keyword_manager êµ¬í˜„ ì „ N/A í‘œì‹œ
        if keyword_manager is None:
            st.metric("ğŸ“„ ë…¼ë¬¸ ê°œìˆ˜", "ë¡œë”© ì¤‘...")
            st.metric("ğŸ·ï¸ í‚¤ì›Œë“œ ê°œìˆ˜", "ë¡œë”© ì¤‘...")
            st.info("ğŸ’¡ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.")
        else:
            keyword_stats = keyword_manager.get_keyword_stats()
            total_keywords = len(keyword_stats)
            total_papers = len(keyword_manager.documents)

            # ë©”íŠ¸ë¦­ í‘œì‹œ
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ğŸ“„ ë…¼ë¬¸", total_papers)
            with col2:
                st.metric("ğŸ·ï¸ í‚¤ì›Œë“œ", total_keywords)

            st.metric("í‰ê·  í‚¤ì›Œë“œ/ë…¼ë¬¸", f"{total_keywords/total_papers:.1f}")

            # ì „ì²´ í‚¤ì›Œë“œ TOP 20 ì°¨íŠ¸ (ì„ íƒì )
            with st.expander("ğŸ† ì¸ê¸° í‚¤ì›Œë“œ TOP 20"):
                import pandas as pd

                top_keywords = sorted(
                    keyword_stats.items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:20]

                df = pd.DataFrame(
                    top_keywords,
                    columns=["í‚¤ì›Œë“œ", "ë…¼ë¬¸ ìˆ˜"]
                )

                st.bar_chart(df.set_index("í‚¤ì›Œë“œ"))

        st.markdown("---")

        # ì •ë³´ ì„¹ì…˜
        st.markdown("### â„¹ï¸ ì •ë³´")
        st.markdown("""
            <div style='font-size: 0.85rem; color: #6c757d;'>
                <p><strong>ë°ì´í„° ì†ŒìŠ¤:</strong><br/>HuggingFace DailyPapers</p>
                <p><strong>ì—…ë°ì´íŠ¸:</strong><br/>ìµœê·¼ 5ì£¼ ë…¼ë¬¸</p>
                <p><strong>ê¸°ìˆ  ìŠ¤íƒ:</strong><br/>RAG + LangChain + OpenAI</p>
            </div>
        """, unsafe_allow_html=True)


# ==================== í—¬í¼ í•¨ìˆ˜ ====================

def add_message(role: str, content: str):
    """ë©”ì‹œì§€ ì¶”ê°€

    Args:
        role: "user" ë˜ëŠ” "assistant"
        content: ë©”ì‹œì§€ ë‚´ìš©
    """
    st.session_state.messages.append({
        "role": role,
        "content": content
    })


def get_example_keyword_response(keyword: str) -> str:
    """í‚¤ì›Œë“œ ì„ íƒ ì‹œ ì˜ˆì‹œ ì‘ë‹µ ìƒì„±

    Args:
        keyword: ì„ íƒëœ í‚¤ì›Œë“œ

    Returns:
        str: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ì‘ë‹µ
    """
    return f"""
### ğŸ” '{keyword}' ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼

ì„ íƒí•˜ì‹  í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ìµœì‹  ë…¼ë¬¸ë“¤ì…ë‹ˆë‹¤.

#### ğŸ“Š ê²€ìƒ‰ í†µê³„
- ì „ì²´ ë…¼ë¬¸ ìˆ˜: **3ê°œ**
- í‰ê·  ì¶”ì²œìˆ˜: **203.3**
- ì£¼ìš” ì—°êµ¬ ë¶„ì•¼: Machine Learning, Deep Learning

---

**ğŸ’¡ ì°¸ê³ **: ì´ëŠ” RAG ì‹œìŠ¤í…œì´ êµ¬í˜„ë˜ì—ˆì„ ë•Œì˜ ì˜ˆì‹œ ì¶œë ¥ì…ë‹ˆë‹¤.
ì‹¤ì œ ì‹œìŠ¤í…œì´ ì—°ê²°ë˜ë©´ VectorDBì—ì„œ '{keyword}' í‚¤ì›Œë“œë¡œ íƒœê·¸ëœ ë…¼ë¬¸ë“¤ì„ ê²€ìƒ‰í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.

**ì‹¤ì œ êµ¬í˜„ ì‹œ ë™ì‘:**
1. KeywordManagerê°€ '{keyword}' íƒœê·¸ë¥¼ ê°€ì§„ ë…¼ë¬¸ë“¤ì„ ê²€ìƒ‰
2. ê´€ë ¨ë„ê°€ ë†’ì€ ìƒìœ„ 10ê°œ ë…¼ë¬¸ì„ ì„ íƒ
3. ê° ë…¼ë¬¸ì˜ ë©”íƒ€ë°ì´í„°(ì œëª©, ë§í¬, ì¶”ì²œìˆ˜, íƒœê·¸)ë¥¼ ì¹´ë“œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
"""


def get_example_rag_response(question: str) -> dict:
    """RAG ì‹œìŠ¤í…œ ì˜ˆì‹œ ì‘ë‹µ ìƒì„±

    ì‹¤ì œ RAG ì‹œìŠ¤í…œì´ ì—°ê²°ë˜ë©´ ì´ í•¨ìˆ˜ëŠ” ì œê±°ë˜ê³ 
    rag_system.ask_with_sources()ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.

    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸

    Returns:
        dict: {"answer": str, "sources": list} í˜•ì‹
    """
    # ì˜ˆì‹œ ì‘ë‹µ - simpleRAGsystem_2.pyì˜ ì¶œë ¥ í˜•ì‹ê³¼ ë™ì¼
    example_answer = f"""
### ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€

**ì§ˆë¬¸:** {question}

#### ğŸ“Œ í•µì‹¬ ìš”ì•½
RAG(Retrieval-Augmented Generation)ëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ LLMì˜ ë‹µë³€ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.

#### ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
- **ê²€ìƒ‰ ê¸°ë°˜ ìƒì„±**: ê´€ë ¨ ë¬¸ì„œë¥¼ ë¨¼ì € ê²€ìƒ‰í•œ í›„ LLMì´ ë‹µë³€ ìƒì„±
- **í™˜ê°(Hallucination) ê°ì†Œ**: ì‹¤ì œ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ ì œê³µ
- **ìµœì‹  ì •ë³´ í™œìš©**: í•™ìŠµ ë°ì´í„° ì™¸ì˜ ìµœì‹  ì •ë³´ë„ í™œìš© ê°€ëŠ¥
- **ì»¨í…ìŠ¤íŠ¸ í™•ì¥**: ê¸´ ë¬¸ë§¥ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬

#### ğŸ“š ê´€ë ¨ ë…¼ë¬¸ (ìƒìœ„ 3ê°œ)

1. **Retrieval-Augmented Generation for Large Language Models: A Survey**
   - RAG ì‹œìŠ¤í…œì˜ ì „ë°˜ì ì¸ êµ¬ì¡°ì™€ ìµœì‹  íŠ¸ë Œë“œë¥¼ ë‹¤ë£¬ ì„œë² ì´ ë…¼ë¬¸
   - ë‹¤ì–‘í•œ RAG ë³€í˜• ê¸°ë²•ë“¤ì„ ë¹„êµ ë¶„ì„

2. **Self-RAG: Learning to Retrieve, Generate, and Critique**
   - ìê¸° ì„±ì°° ê¸°ë°˜ RAG ì‹œìŠ¤í…œ
   - ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆì„ ìŠ¤ìŠ¤ë¡œ í‰ê°€í•˜ê³  ê°œì„ 

3. **CRAG: Corrective Retrieval Augmented Generation**
   - ê²€ìƒ‰ ê²°ê³¼ì˜ ì˜¤ë¥˜ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” ê¸°ë²•
   - ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§ ì ìš©

#### ğŸ“– ìƒì„¸ ì„¤ëª…

RAGëŠ” í¬ê²Œ 3ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

1. **ê²€ìƒ‰(Retrieval)**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
2. **ì¦ê°•(Augmentation)**: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
3. **ìƒì„±(Generation)**: LLMì´ ì¦ê°•ëœ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±

ìµœê·¼ ì—°êµ¬ íŠ¸ë Œë“œ:
- Hybrid Retrieval (Dense + Sparse)
- Self-Reflection RAG
- Adaptive Retrieval (í•„ìš”ì‹œì—ë§Œ ê²€ìƒ‰)
- Multi-hop RAG (ë‹¤ë‹¨ê³„ ê²€ìƒ‰)

---

**ğŸ’¡ ì°¸ê³ **: ì´ëŠ” RAG ì‹œìŠ¤í…œì´ êµ¬í˜„ë˜ì—ˆì„ ë•Œì˜ ì˜ˆì‹œ ì¶œë ¥ì…ë‹ˆë‹¤.
ì‹¤ì œ ì‹œìŠ¤í…œì´ ì—°ê²°ë˜ë©´ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë…¼ë¬¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì´ ìƒì„±ë©ë‹ˆë‹¤.
"""

    # ì˜ˆì‹œ ì¶œì²˜ ë°ì´í„° - simpleRAGsystem_2.pyì˜ sources í˜•ì‹ê³¼ ë™ì¼
    example_sources = [
        {
            "paper_name": "Retrieval-Augmented Generation for Large Language Models: A Survey",
            "huggingface_url": "https://huggingface.co/papers/2312.10997",
            "github_url": "https://github.com/example/rag-survey",
            "upvote": 245,
            "tags": ["RAG", "LLM", "Survey", "Retrieval"]
        },
        {
            "paper_name": "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",
            "huggingface_url": "https://huggingface.co/papers/2310.11511",
            "github_url": "https://github.com/example/self-rag",
            "upvote": 198,
            "tags": ["RAG", "Self-Reflection", "LLM"]
        },
        {
            "paper_name": "CRAG: Corrective Retrieval Augmented Generation",
            "huggingface_url": "https://huggingface.co/papers/2401.15884",
            "github_url": None,
            "upvote": 167,
            "tags": ["RAG", "Corrective", "Retrieval"]
        }
    ]

    return {
        "answer": example_answer,
        "sources": example_sources
    }


def format_papers_as_markdown(papers: List) -> str:
    """ë…¼ë¬¸ ëª©ë¡ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í¬ë§·íŒ…

    Args:
        papers: Document ê°ì²´ ë¦¬ìŠ¤íŠ¸

    Returns:
        str: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë…¼ë¬¸ ëª©ë¡
    """
    if not papers:
        return "ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    output = "### ğŸ“š ê²€ìƒ‰ ê²°ê³¼\n\n"

    for i, doc in enumerate(papers, 1):
        metadata = doc.metadata

        title = metadata.get('paper_name', 'N/A')
        upvote = metadata.get('upvote', 0)
        tags = metadata.get('tags', [])
        hf_url = metadata.get('huggingface_url', '#')
        github_url = metadata.get('github_url', None)

        output += f"**{i}. {title}**\n"
        output += f"- ğŸ‘ ì¶”ì²œìˆ˜: {upvote}\n"
        output += f"- ğŸ·ï¸ íƒœê·¸: {', '.join(tags[:3])}\n"
        output += f"- ğŸ”— [HuggingFace ë…¼ë¬¸]({hf_url})"

        if github_url:
            output += f" | [GitHub]({github_url})"

        output += "\n\n"

    return output


def render_paper_card(source: dict, index: int):
    """ë…¼ë¬¸ ì¹´ë“œ ë Œë”ë§ (HuggingFace ìŠ¤íƒ€ì¼)

    simpleRAGsystem_2.pyì˜ sources í˜•ì‹ì— ë§ì¶° ë Œë”ë§:
    {
        "paper_name": str,
        "huggingface_url": str,
        "github_url": str or None,
        "upvote": int,
        "tags": list
    }

    Args:
        source: ë…¼ë¬¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        index: ë…¼ë¬¸ ìˆœì„œ ë²ˆí˜¸
    """
    # ë…¼ë¬¸ ì œëª©ê³¼ ì¶”ì²œìˆ˜
    paper_name = source.get('paper_name', '(ì œëª© ì—†ìŒ)')
    upvote = source.get('upvote', 0)

    # ì¹´ë“œ ì»¨í…Œì´ë„ˆ
    st.markdown(f"""
        <div style='background: white; border-radius: 0.75rem; padding: 1.5rem; margin: 1rem 0;
                    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08); border-left: 4px solid #FF9D00;'>
            <div style='display: flex; justify-content: space-between; align-items: start; margin-bottom: 0.75rem;'>
                <div style='flex: 1;'>
                    <h4 style='color: #1f2937; margin: 0; font-size: 1.1rem;'>{index}. {paper_name}</h4>
                </div>
                <div style='margin-left: 1rem;'>
                    <span style='background: #FF9D00; color: white; padding: 0.35rem 0.75rem;
                                 border-radius: 1rem; font-size: 0.9rem; font-weight: 600;'>
                        ğŸ‘ {upvote}
                    </span>
                </div>
            </div>
        </div>
    """, unsafe_allow_html=True)

    # íƒœê·¸ í‘œì‹œ
    tags = source.get('tags', [])
    if tags:
        tag_badges = []
        for tag in tags:
            tag_badges.append(
                f"<span style='background: #f3f4f6; color: #374151; padding: 0.25rem 0.75rem; "
                f"border-radius: 9999px; font-size: 0.85rem; margin-right: 0.5rem; "
                f"display: inline-block; margin-bottom: 0.25rem;'>"
                f"ğŸ·ï¸ {tag}</span>"
            )
        st.markdown("".join(tag_badges), unsafe_allow_html=True)

    st.markdown("")  # ê³µë°±

    # ë§í¬
    col1, col2 = st.columns(2)
    with col1:
        hf_url = source.get('huggingface_url', '#')
        if hf_url and hf_url != '#':
            st.markdown(f"[ğŸ¤— HuggingFace ë…¼ë¬¸]({hf_url})")

    with col2:
        github_url = source.get('github_url', None)
        if github_url:
            st.markdown(f"[ğŸ’» GitHub ì €ì¥ì†Œ]({github_url})")

    st.markdown("---")

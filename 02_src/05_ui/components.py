"""
Streamlit UI ì»´í¬ë„ŒíŠ¸ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ HuggingFace DailyPapers RAG ì±—ë´‡ì˜ UI ì»´í¬ë„ŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- ë¦¬ì†ŒìŠ¤ ë¡œë”© (VectorDB, KeywordManager, RAG System)
- ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
- UI ë Œë”ë§ (í—¤ë”, ì±„íŒ…, ì‚¬ì´ë“œë°”)
"""

import streamlit as st
from pathlib import Path
from typing import List, Tuple
import sys
import json
from collections import Counter
from langchain_openai import OpenAIEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI

# í”„ë¡œì íŠ¸ ê²½ë¡œ
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_DIR = PROJECT_ROOT / "01_data"
SRC_DIR = PROJECT_ROOT / "02_src"

# vectordb ëª¨ë“ˆ import
sys.path.insert(0, str(SRC_DIR / "02_utils"))
from vectordb import load_vectordb

# SimpleRAGSystem ì„í¬íŠ¸
sys.path.insert(0, str(SRC_DIR / "04_rag"))
from simpleRAGsystem_2 import SimpleRAGSystem

# HuggingFace ìŠ¤íƒ€ì¼ CSS
HUGGINGFACE_STYLE = """
<style>
    /* ë©”ì¸ ì»¨í…Œì´ë„ˆ */
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }

    /* í—¤ë” ìŠ¤íƒ€ì¼ */
    .header-container {
        background: white;
        padding: 2rem;
        border-radius: 1rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        margin-bottom: 2rem;
    }

    /* í‚¤ì›Œë“œ íƒœê·¸ ìŠ¤íƒ€ì¼ */
    .stPills {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
    }

    /* ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .stChatMessage {
        background: white;
        border-radius: 0.75rem;
        padding: 1rem;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 0.5rem;
        padding: 0.5rem 1rem;
        font-weight: 600;
        transition: all 0.3s ease;
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    }

    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
    .css-1d391kg {
        background: #f8f9fa;
    }

    /* ë©”íŠ¸ë¦­ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .stMetric {
        background: white;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    /* ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ */
    .stTextInput > div > div > input {
        border-radius: 0.5rem;
        border: 2px solid #e0e0e0;
        padding: 0.75rem;
    }

    /* HuggingFace ë¡œê³  ìƒ‰ìƒ */
    .hf-color {
        color: #FF9D00;
    }

    /* ë…¼ë¬¸ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .paper-card {
        background: white;
        border-radius: 0.75rem;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
        transition: all 0.3s ease;
    }

    .paper-card:hover {
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        transform: translateY(-2px);
    }

    /* Streamlitì˜ text_input ì»´í¬ë„ŒíŠ¸ì˜ íŠ¹ì • í´ë˜ìŠ¤(data-testid)ë¥¼ íƒ€ê²ŸíŒ…í•˜ì—¬ ì»¨í…Œì´ë„ˆì— ë§ê²Œ ìŠ¤íƒ€ì¼ ì¡°ì • */
    .fixed-bottom-container div[data-testid="stTextInput"] {
        margin-bottom: 0;
    }

    /* ë©”ì¸ ì»¨í…ì¸  ì˜ì—­ - í•˜ë‹¨ ê³ ì • ìš”ì†Œë¥¼ ìœ„í•œ ì—¬ë°± */
    .main-content {
        padding-bottom: 280px;
        min-height: 100vh;
    }

    /* íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì œëª© ìŠ¤íƒ€ì¼ */
    .trend-title {
        color: #FF9D00;
        font-weight: 600;
        font-size: 1rem;
        margin-bottom: 0.75rem;
    }

    /* ê²€ìƒ‰ ì œëª© ìŠ¤íƒ€ì¼ */
    .search-title {
        color: #FF9D00;
        font-weight: 600;
        font-size: 1rem;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
    }
</style>
"""


# ==================== í‚¤ì›Œë“œ ì¶”ì¶œ ====================

def get_trending_keywords_from_json(weeks: int = 6, top_n: int = 7) -> List[Tuple[str, int]]:
    """
    ìµœê·¼ Nì£¼ê°„ì˜ JSON ë°ì´í„°ì—ì„œ íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ì¶œ

    Args:
        weeks: ë¶„ì„í•  ìµœê·¼ ì£¼ ìˆ˜ (ê¸°ë³¸ê°’: 6)
        top_n: ë°˜í™˜í•  ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜ (ê¸°ë³¸ê°’: 7)

    Returns:
        List of tuples: [(í‚¤ì›Œë“œ, ê°œìˆ˜), ...]
    """
    try:
        docs_dir = PROJECT_ROOT / "01_data" / "documents" / "2025"

        if not docs_dir.exists():
            raise FileNotFoundError("ë¬¸ì„œ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        all_keywords = []

        # ëª¨ë“  ì£¼ì°¨ ë””ë ‰í† ë¦¬ë¥¼ ì´ë¦„ìˆœìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
        week_dirs = sorted([d for d in docs_dir.iterdir() if d.is_dir()], reverse=True)

        # ìµœê·¼ Nì£¼ ë°ì´í„° ì²˜ë¦¬
        for week_dir in week_dirs[:weeks]:
            for json_file in week_dir.glob('*.json'):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        tags = data.get('metadata', {}).get('tags', [])
                        all_keywords.extend(tags)
                except Exception:
                    # ë¬¸ì œê°€ ìˆëŠ” íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                    continue

        # í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì˜ˆì™¸ ë°œìƒ
        if not all_keywords:
            raise ValueError("í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # í‚¤ì›Œë“œ ê°œìˆ˜ ê³„ì‚° í›„ ìƒìœ„ Nê°œ ë°˜í™˜
        keyword_counts = Counter(all_keywords)
        return keyword_counts.most_common(top_n)

    except Exception:
        # ëª¨ë“  ì˜ˆì™¸ ë°œìƒ ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
        return [
            ("LLM", 45), ("Transformer", 38), ("RAG", 32),
            ("Vision", 28), ("Diffusion", 25), ("Agent", 22),
            ("Multimodal", 20)
        ][:top_n]


# ==================== ë¦¬ì†ŒìŠ¤ ë¡œë”© ====================
def load_vectorstore():
    """VectorDB ë¡œë“œ (ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì‚¬ìš©)

    Returns:
        VectorStore ë˜ëŠ” None: ChromaDB ë²¡í„° ì €ì¥ì†Œ
    """
    # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ì¬ì‚¬ìš©
    if "vectorstore" in st.session_state:
        return st.session_state.vectorstore

    try:
        with st.spinner("ğŸ”„ VectorDB ë¡œë”© ì¤‘..."):
            # vectordb.pyì˜ load_vectordb() í•¨ìˆ˜ í˜¸ì¶œ
            vectorstore = load_vectordb(
                model_name="MiniLM-L6",
                chunk_size=100,
                chunk_overlap=10
            )

            # ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ì €ì¥
            st.session_state.vectorstore = vectorstore
            st.toast("âœ… VectorDB ë¡œë“œ ì™„ë£Œ", icon="âœ…")
            return vectorstore

    except Exception as e:
        st.error(f"âŒ VectorDB ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        st.error(traceback.format_exc())
        return None


def load_rag_system(vectorstore):
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì‚¬ìš©)

    Args:
        vectorstore: VectorStore ê°ì²´

    Returns:
        SimpleRAGSystem ë˜ëŠ” None: RAG ì‹œìŠ¤í…œ ê°ì²´
    """
    # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ì¬ì‚¬ìš©
    if "rag_system" in st.session_state:
        return st.session_state.rag_system

    try:
        if vectorstore is None:
            st.warning("âš ï¸ VectorDBê°€ ë¡œë“œë˜ì§€ ì•Šì•„ RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        with st.spinner("ğŸ”„ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
            # LLM ì´ˆê¸°í™”
            llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)

            # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (retriever_k=3ìœ¼ë¡œ ìƒìœ„ 3ê°œ ë¬¸ì„œ ê²€ìƒ‰)
            rag_system = SimpleRAGSystem(vectorstore, llm, retriever_k=3)

            # ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ì €ì¥
            st.session_state.rag_system = rag_system
            st.toast("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ", icon="âœ…")
            return rag_system

    except Exception as e:
        st.error(f"âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        st.error(traceback.format_exc())
        return None


# ==================== ì„¸ì…˜ ì´ˆê¸°í™” ====================

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

    Streamlit session_stateì— í•„ìš”í•œ ë³€ìˆ˜ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "selected_keyword" not in st.session_state:
        st.session_state.selected_keyword = None  # ë‹¨ì¼ í‚¤ì›Œë“œ

    if "search_mode" not in st.session_state:
        st.session_state.search_mode = "chat"  # "chat" or "keyword"

    if "last_searched_keyword" not in st.session_state:
        st.session_state.last_searched_keyword = None  # ì¤‘ë³µ ê²€ìƒ‰ ë°©ì§€

    if "keyword_selection_key" not in st.session_state:
        st.session_state.keyword_selection_key = 0  # pills ìœ„ì ¯ ì´ˆê¸°í™”ìš© ì¹´ìš´í„°


# ==================== UI ë Œë”ë§ ====================

def render_header():
    """í—¤ë”: ì œëª©"""
    # HuggingFace ìŠ¤íƒ€ì¼ CSS ì ìš©
    st.markdown(HUGGINGFACE_STYLE, unsafe_allow_html=True)

    # í—¤ë” ì»¨í…Œì´ë„ˆ
    st.markdown("""
        <div style='text-align: center;'>
            <h1 style='color: #FF9D00; font-size: 3rem; margin-bottom: 0.5rem;'>
                ğŸ¤— HuggingFace DailyPapers
            </h1>
            <p style='color: #6c757d; font-size: 1.2rem; margin-top: 0;'>
                RAG ê¸°ë°˜ ìµœì‹  ML/DL/LLM ë…¼ë¬¸ ê²€ìƒ‰ ì±—ë´‡
            </p>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("---")


def render_chat_interface(rag_system):
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤

    Args:
        rag_system: SimpleRAGSystem ê°ì²´ ë˜ëŠ” None
    """
    # 1. ë©”ì¸ ì»¨í…ì¸  ì˜ì—­ (ë‹µë³€ í‘œì‹œ)
    # st.markdown('<div class="main-content">', unsafe_allow_html=True)

    # Q&A ë©”ì‹œì§€ í‘œì‹œ
    if len(st.session_state.messages) == 0:
        st.markdown("""
            <div style='text-align: center; color: #6c757d; padding: 3rem 1rem;'>
                <h3 style='color: #FF9D00;'>ğŸ’¬ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”!</h3>
                <p>í•˜ë‹¨ì˜ íŠ¸ë Œë“œ í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ê±°ë‚˜ ê²€ìƒ‰ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.</p>
            </div>
        """, unsafe_allow_html=True)
    else:
        for message in st.session_state.messages:
            with st.chat_message(message["role"], avatar="ğŸ¤—" if message["role"] == "assistant" else "ğŸ‘¤"):
                st.markdown(message["content"])

    # st.markdown('</div>', unsafe_allow_html=True)

    # 2. í•˜ë‹¨ ê³ ì • ì˜ì—­ (íŠ¸ë Œë“œ í‚¤ì›Œë“œ + ê²€ìƒ‰ì°½)
    # íŠ¸ë Œë“œ í‚¤ì›Œë“œ
    st.markdown('<div class="trend-title">ğŸ”¥ íŠ¸ë Œë“œ í‚¤ì›Œë“œ</div>', unsafe_allow_html=True)

    trending = get_trending_keywords_from_json(weeks=6, top_n=7)
    keyword_labels = [kw for kw, count in trending]  # ê°œìˆ˜ ì œê±°, í‚¤ì›Œë“œë§Œ í‘œì‹œ

    selected = st.pills(
        label="trend keyword",
        options=keyword_labels,
        selection_mode="single",
        label_visibility="collapsed",
        key=f"keyword_pills_{st.session_state.keyword_selection_key}"
    )

    user_input = st.chat_input(
        placeholder=" ğŸ” ë…¼ë¬¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
    )

    # 3. í‚¤ì›Œë“œ ì„ íƒ ì‹œ ê²€ìƒ‰ ì‹¤í–‰
    if selected:
        keyword = selected

        # ì¤‘ë³µ ê²€ìƒ‰ ë°©ì§€
        if keyword != st.session_state.get("last_searched_keyword", None):
            # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ë©”ì‹œì§€
            query = f"ğŸ“Œ ì„ íƒí•œ í‚¤ì›Œë“œ: {keyword}"

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.markdown(query)
            add_message("user", query)

            # AI ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant", avatar="ğŸ¤—"):
                # RAG ì‹œìŠ¤í…œì´ ì—†ìœ¼ë©´ ì˜ˆì‹œ ì‘ë‹µ ì‚¬ìš©
                if rag_system is None:
                    with st.spinner("ğŸ” ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        result_text = get_example_keyword_response(keyword)
                    st.markdown(result_text)
                else:
                    # ì‹¤ì œ RAG ì‹œìŠ¤í…œìœ¼ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
                    keyword_query = f"{keyword}ì— ëŒ€í•œ ìµœì‹  ì—°êµ¬ ë™í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”."

                    with st.spinner("ğŸ” ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘..."):
                        result = rag_system.ask_with_sources(keyword_query, stream=True)

                    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í‘œì‹œ
                    result_text = st.write_stream(result['answer_stream'])

                # ì°¸ì¡° ë…¼ë¬¸ í‘œì‹œ
                # if rag_system is not None:
                #     sources = result.get('sources', [])
                #     if sources:
                #         st.markdown("---")
                #         with st.expander(f"ğŸ“š ì°¸ì¡°ëœ ë…¼ë¬¸ ({len(sources)}ê°œ)", expanded=True):
                #             for i, source in enumerate(sources, 1):
                #                 render_paper_card(source, i)
                #     else:
                #         st.info("ğŸ’¡ ê²€ìƒ‰ëœ ê´€ë ¨ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

            # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì €ì¥
            add_message("assistant", result_text)

            # í‚¤ì›Œë“œ ì„ íƒ í•´ì œ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.last_searched_keyword = keyword
            st.session_state.keyword_selection_key += 1
            st.rerun()

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if user_input:
        # í‚¤ì›Œë“œ ì„ íƒ í•´ì œ
        st.session_state.keyword_selection_key += 1
        st.session_state.last_searched_keyword = None

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(user_input)
        add_message("user", user_input)

        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant", avatar="ğŸ¤—"):
            # RAG ì‹œìŠ¤í…œì´ ì—†ìœ¼ë©´ ì˜ˆì‹œ ì‘ë‹µ ì‚¬ìš©
            if rag_system is None:
                with st.spinner("ğŸ” ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    # simpleRAGsystem_2.pyì˜ ì¶œë ¥ í˜•ì‹ì„ ì‹œë®¬ë ˆì´ì…˜
                    result = get_example_rag_response(user_input)
                    response_text = result['answer']
                st.markdown(response_text)
            else:
                # ì‹¤ì œ RAG ì‹œìŠ¤í…œ í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
                with st.spinner("ğŸ” ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘..."):
                    result = rag_system.ask_with_sources(user_input, stream=True)

                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í‘œì‹œ
                response_text = st.write_stream(result['answer_stream'])

            # ì°¸ì¡° ë…¼ë¬¸ í‘œì‹œ
            # sources = result.get('sources', [])
            # if sources:
            #     st.markdown("---")
            #     with st.expander(f"ğŸ“š ì°¸ì¡°ëœ ë…¼ë¬¸ ({len(sources)}ê°œ)", expanded=True):
            #         for i, source in enumerate(sources, 1):
            #             render_paper_card(source, i)
            # else:
            #     st.info("ğŸ’¡ ê²€ìƒ‰ëœ ê´€ë ¨ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì €ì¥ (ë‹µë³€ë§Œ ì €ì¥, ì¶œì²˜ëŠ” ì œì™¸)
        add_message("assistant", response_text)


def render_sidebar(rag_system=None):
    """ì‚¬ì´ë“œë°”: ì„¤ì • & í†µê³„

    Args:
        rag_system: SimpleRAGSystem ê°ì²´ (ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”ìš©)
    """
    with st.sidebar:
        # ë¡œê³  ì˜ì—­
        st.markdown("""
            <div style='text-align: center; padding: 1rem 0; margin-bottom: 1rem;'>
                <h2 style='color: #FF9D00; margin: 0;'>ğŸ¤—</h2>
                <p style='color: #6c757d; font-size: 0.9rem; margin: 0;'>HuggingFace Papers</p>
            </div>
        """, unsafe_allow_html=True)

        st.markdown("---")

        # ì„¤ì • ì„¹ì…˜
        st.markdown("### âš™ï¸ ì„¤ì •")

        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True, type="primary"):
            st.session_state.messages = []
            st.session_state.selected_keyword = None
            st.session_state.last_searched_keyword = None
            # í‚¤ì›Œë“œ ì„ íƒ í•´ì œ
            st.session_state.keyword_selection_key += 1
            # RAG ì‹œìŠ¤í…œì˜ chat_historyë„ ì´ˆê¸°í™”
            if rag_system is not None:
                rag_system.clear_history()
            st.toast("âœ… ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤", icon="âœ…")
            st.rerun()

        # ìºì‹œ ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ìºì‹œ ì´ˆê¸°í™”", use_container_width=True):
            # ëŒ€í™” ì´ˆê¸°í™”
            st.session_state.messages = []
            st.session_state.selected_keyword = None
            st.session_state.last_searched_keyword = None
            # í‚¤ì›Œë“œ ì„ íƒ í•´ì œ
            st.session_state.keyword_selection_key += 1
            # ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì—ì„œ VectorDBì™€ RAG ì‹œìŠ¤í…œ ì œê±°
            if "vectorstore" in st.session_state:
                del st.session_state.vectorstore
            if "rag_system" in st.session_state:
                del st.session_state.rag_system
            st.toast("âœ… ìºì‹œì™€ ëŒ€í™”ê°€ ëª¨ë‘ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ìš”ì²­ ì‹œ ì¬ë¡œë“œë©ë‹ˆë‹¤.", icon="âœ…")
            st.rerun()

        st.markdown("---")

        # í†µê³„ ì„¹ì…˜
        st.markdown("### ğŸ“Š í†µê³„")

        # ë…¼ë¬¸ ë° í‚¤ì›Œë“œ ê°œìˆ˜ í‘œì‹œ
        st.metric("ğŸ“„ ë…¼ë¬¸ ê°œìˆ˜", "506")
        st.metric("ğŸ·ï¸ í‚¤ì›Œë“œ ê°œìˆ˜", "1,449")
        st.info("ğŸ’¡ ìµœê·¼ 6ì£¼ê°„ì˜ ë°ì´í„°")

        st.markdown("---")

        # ì •ë³´ ì„¹ì…˜
        st.markdown("### â„¹ï¸ ì •ë³´")
        st.markdown("""
            <div style='font-size: 0.85rem; color: #6c757d;'>
                <p><strong>ë°ì´í„° ì†ŒìŠ¤:</strong><br/>HuggingFace DailyPapers</p>
                <p><strong>ì—…ë°ì´íŠ¸:</strong><br/>ìµœê·¼ 5ì£¼ ë…¼ë¬¸</p>
                <p><strong>ê¸°ìˆ  ìŠ¤íƒ:</strong><br/>RAG + LangChain + OpenAI</p>
            </div>
        """, unsafe_allow_html=True)


# ==================== í—¬í¼ í•¨ìˆ˜ ====================

def add_message(role: str, content: str):
    """ë©”ì‹œì§€ ì¶”ê°€

    Args:
        role: "user" ë˜ëŠ” "assistant"
        content: ë©”ì‹œì§€ ë‚´ìš©
    """
    st.session_state.messages.append({
        "role": role,
        "content": content
    })


def get_example_keyword_response(keyword: str) -> str:
    """í‚¤ì›Œë“œ ì„ íƒ ì‹œ ì˜ˆì‹œ ì‘ë‹µ ìƒì„±

    Args:
        keyword: ì„ íƒëœ í‚¤ì›Œë“œ

    Returns:
        str: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ì‘ë‹µ
    """
    return f"""
### ğŸ” '{keyword}' ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼

ì„ íƒí•˜ì‹  í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ìµœì‹  ë…¼ë¬¸ë“¤ì…ë‹ˆë‹¤.

#### ğŸ“Š ê²€ìƒ‰ í†µê³„
- ì „ì²´ ë…¼ë¬¸ ìˆ˜: **3ê°œ**
- í‰ê·  ì¶”ì²œìˆ˜: **203.3**
- ì£¼ìš” ì—°êµ¬ ë¶„ì•¼: Machine Learning, Deep Learning

---

**ğŸ’¡ ì°¸ê³ **: ì´ëŠ” RAG ì‹œìŠ¤í…œì´ êµ¬í˜„ë˜ì—ˆì„ ë•Œì˜ ì˜ˆì‹œ ì¶œë ¥ì…ë‹ˆë‹¤.
ì‹¤ì œ ì‹œìŠ¤í…œì´ ì—°ê²°ë˜ë©´ VectorDBì—ì„œ '{keyword}' í‚¤ì›Œë“œë¡œ íƒœê·¸ëœ ë…¼ë¬¸ë“¤ì„ ê²€ìƒ‰í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.

**ì‹¤ì œ êµ¬í˜„ ì‹œ ë™ì‘:**
1. KeywordManagerê°€ '{keyword}' íƒœê·¸ë¥¼ ê°€ì§„ ë…¼ë¬¸ë“¤ì„ ê²€ìƒ‰
2. ê´€ë ¨ë„ê°€ ë†’ì€ ìƒìœ„ 10ê°œ ë…¼ë¬¸ì„ ì„ íƒ
3. ê° ë…¼ë¬¸ì˜ ë©”íƒ€ë°ì´í„°(ì œëª©, ë§í¬, ì¶”ì²œìˆ˜, íƒœê·¸)ë¥¼ ì¹´ë“œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
"""


def get_example_rag_response(question: str) -> dict:
    """RAG ì‹œìŠ¤í…œ ì˜ˆì‹œ ì‘ë‹µ ìƒì„±

    ì‹¤ì œ RAG ì‹œìŠ¤í…œì´ ì—°ê²°ë˜ë©´ ì´ í•¨ìˆ˜ëŠ” ì œê±°ë˜ê³ 
    rag_system.ask_with_sources()ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.

    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸

    Returns:
        dict: {"answer": str, "sources": list} í˜•ì‹
    """
    # ì˜ˆì‹œ ì‘ë‹µ - simpleRAGsystem_2.pyì˜ ì¶œë ¥ í˜•ì‹ê³¼ ë™ì¼
    example_answer = f"""
### ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€

**ì§ˆë¬¸:** {question}

#### ğŸ“Œ í•µì‹¬ ìš”ì•½
RAG(Retrieval-Augmented Generation)ëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ LLMì˜ ë‹µë³€ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.

#### ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
- **ê²€ìƒ‰ ê¸°ë°˜ ìƒì„±**: ê´€ë ¨ ë¬¸ì„œë¥¼ ë¨¼ì € ê²€ìƒ‰í•œ í›„ LLMì´ ë‹µë³€ ìƒì„±
- **í™˜ê°(Hallucination) ê°ì†Œ**: ì‹¤ì œ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ ì œê³µ
- **ìµœì‹  ì •ë³´ í™œìš©**: í•™ìŠµ ë°ì´í„° ì™¸ì˜ ìµœì‹  ì •ë³´ë„ í™œìš© ê°€ëŠ¥
- **ì»¨í…ìŠ¤íŠ¸ í™•ì¥**: ê¸´ ë¬¸ë§¥ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬

#### ğŸ“š ê´€ë ¨ ë…¼ë¬¸ (ìƒìœ„ 3ê°œ)

1. **Retrieval-Augmented Generation for Large Language Models: A Survey**
   - RAG ì‹œìŠ¤í…œì˜ ì „ë°˜ì ì¸ êµ¬ì¡°ì™€ ìµœì‹  íŠ¸ë Œë“œë¥¼ ë‹¤ë£¬ ì„œë² ì´ ë…¼ë¬¸
   - ë‹¤ì–‘í•œ RAG ë³€í˜• ê¸°ë²•ë“¤ì„ ë¹„êµ ë¶„ì„

2. **Self-RAG: Learning to Retrieve, Generate, and Critique**
   - ìê¸° ì„±ì°° ê¸°ë°˜ RAG ì‹œìŠ¤í…œ
   - ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆì„ ìŠ¤ìŠ¤ë¡œ í‰ê°€í•˜ê³  ê°œì„ 

3. **CRAG: Corrective Retrieval Augmented Generation**
   - ê²€ìƒ‰ ê²°ê³¼ì˜ ì˜¤ë¥˜ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” ê¸°ë²•
   - ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§ ì ìš©

#### ğŸ“– ìƒì„¸ ì„¤ëª…

RAGëŠ” í¬ê²Œ 3ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

1. **ê²€ìƒ‰(Retrieval)**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
2. **ì¦ê°•(Augmentation)**: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
3. **ìƒì„±(Generation)**: LLMì´ ì¦ê°•ëœ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±

ìµœê·¼ ì—°êµ¬ íŠ¸ë Œë“œ:
- Hybrid Retrieval (Dense + Sparse)
- Self-Reflection RAG
- Adaptive Retrieval (í•„ìš”ì‹œì—ë§Œ ê²€ìƒ‰)
- Multi-hop RAG (ë‹¤ë‹¨ê³„ ê²€ìƒ‰)

---

**ğŸ’¡ ì°¸ê³ **: ì´ëŠ” RAG ì‹œìŠ¤í…œì´ êµ¬í˜„ë˜ì—ˆì„ ë•Œì˜ ì˜ˆì‹œ ì¶œë ¥ì…ë‹ˆë‹¤.
ì‹¤ì œ ì‹œìŠ¤í…œì´ ì—°ê²°ë˜ë©´ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë…¼ë¬¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì´ ìƒì„±ë©ë‹ˆë‹¤.
"""

    # ì˜ˆì‹œ ì¶œì²˜ ë°ì´í„° - simpleRAGsystem_2.pyì˜ sources í˜•ì‹ê³¼ ë™ì¼
    example_sources = [
        {
            "paper_name": "Retrieval-Augmented Generation for Large Language Models: A Survey",
            "huggingface_url": "https://huggingface.co/papers/2312.10997",
            "github_url": "https://github.com/example/rag-survey",
            "upvote": 245,
            "tags": ["RAG", "LLM", "Survey", "Retrieval"]
        },
        {
            "paper_name": "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",
            "huggingface_url": "https://huggingface.co/papers/2310.11511",
            "github_url": "https://github.com/example/self-rag",
            "upvote": 198,
            "tags": ["RAG", "Self-Reflection", "LLM"]
        },
        {
            "paper_name": "CRAG: Corrective Retrieval Augmented Generation",
            "huggingface_url": "https://huggingface.co/papers/2401.15884",
            "github_url": None,
            "upvote": 167,
            "tags": ["RAG", "Corrective", "Retrieval"]
        }
    ]

    return {
        "answer": example_answer,
        "sources": example_sources
    }


def format_papers_as_markdown(papers: List) -> str:
    """ë…¼ë¬¸ ëª©ë¡ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í¬ë§·íŒ…

    Args:
        papers: Document ê°ì²´ ë¦¬ìŠ¤íŠ¸

    Returns:
        str: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë…¼ë¬¸ ëª©ë¡
    """
    if not papers:
        return "ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    output = "### ğŸ“š ê²€ìƒ‰ ê²°ê³¼\n\n"

    for i, doc in enumerate(papers, 1):
        metadata = doc.metadata

        title = metadata.get('paper_name', 'N/A')
        upvote = metadata.get('upvote', 0)
        tags = metadata.get('tags', [])
        hf_url = metadata.get('huggingface_url', '#')
        github_url = metadata.get('github_url', None)

        output += f"**{i}. {title}**\n"
        output += f"- ğŸ‘ ì¶”ì²œìˆ˜: {upvote}\n"
        output += f"- ğŸ·ï¸ íƒœê·¸: {', '.join(tags[:3])}\n"
        output += f"- ğŸ”— [HuggingFace ë…¼ë¬¸]({hf_url})"

        if github_url:
            output += f" | [GitHub]({github_url})"

        output += "\n\n"

    return output


def render_paper_card(source: dict, index: int):
    """ë…¼ë¬¸ ì¹´ë“œ ë Œë”ë§ (HuggingFace ìŠ¤íƒ€ì¼)

    simpleRAGsystem_2.pyì˜ sources í˜•ì‹ì— ë§ì¶° ë Œë”ë§:
    {
        "paper_name": str,
        "huggingface_url": str,
        "github_url": str or None,
        "upvote": int,
        "tags": list
    }

    Args:
        source: ë…¼ë¬¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        index: ë…¼ë¬¸ ìˆœì„œ ë²ˆí˜¸
    """
    # ë…¼ë¬¸ ì œëª©ê³¼ ì¶”ì²œìˆ˜
    paper_name = source.get('paper_name', '(ì œëª© ì—†ìŒ)')
    upvote = source.get('upvote', 0)

    # ì¹´ë“œ ì»¨í…Œì´ë„ˆ
    st.markdown(f"""
        <div style='background: white; border-radius: 0.75rem; padding: 1.5rem; margin: 1rem 0;
                    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08); border-left: 4px solid #FF9D00;'>
            <div style='display: flex; justify-content: space-between; align-items: start; margin-bottom: 0.75rem;'>
                <div style='flex: 1;'>
                    <h4 style='color: #1f2937; margin: 0; font-size: 1.1rem;'>{index}. {paper_name}</h4>
                </div>
                <div style='margin-left: 1rem;'>
                    <span style='background: #FF9D00; color: white; padding: 0.35rem 0.75rem;
                                 border-radius: 1rem; font-size: 0.9rem; font-weight: 600;'>
                        ğŸ‘ {upvote}
                    </span>
                </div>
            </div>
        </div>
    """, unsafe_allow_html=True)

    # íƒœê·¸ í‘œì‹œ
    tags = source.get('tags', [])
    if tags:
        tag_badges = []
        for tag in tags:
            tag_badges.append(
                f"<span style='background: #f3f4f6; color: #374151; padding: 0.25rem 0.75rem; "
                f"border-radius: 9999px; font-size: 0.85rem; margin-right: 0.5rem; "
                f"display: inline-block; margin-bottom: 0.25rem;'>"
                f"ğŸ·ï¸ {tag}</span>"
            )
        st.markdown("".join(tag_badges), unsafe_allow_html=True)

    st.markdown("")  # ê³µë°±

    # ë§í¬
    col1, col2 = st.columns(2)
    with col1:
        hf_url = source.get('huggingface_url', '#')
        if hf_url and hf_url != '#':
            st.markdown(f"[ğŸ¤— HuggingFace ë…¼ë¬¸]({hf_url})")

    with col2:
        github_url = source.get('github_url', None)
        if github_url:
            st.markdown(f"[ğŸ’» GitHub ì €ì¥ì†Œ]({github_url})")

    st.markdown("---")

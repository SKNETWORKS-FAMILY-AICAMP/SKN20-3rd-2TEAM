{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f170bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pickle    # chunk, vectorDB 저장한것 사용\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 경고메세지 삭제\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "# openapi key 확인\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError('.env확인,  key없음')\n",
    "\n",
    "# 필수 라이브러리 로드\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class SimpleRAGSystem:\n",
    "    '''간단한 RAG 시스템 래퍼 클래스'''\n",
    "    def __init__(self, vectorstore, llm, retriever_k=3):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        self.retriever = vectorstore.as_retriever(search_type = 'similarity', search_kwargs={'k':retriever_k})\n",
    "        # self.retriever_chain = self._retriever_basic_chain()\n",
    "        self.chain = self._build_chain()\n",
    "    \n",
    "\n",
    "    def _build_chain(self): ### ---------> 최종 사용자에게 전달되는 프롬프트 수정\n",
    "        '''RAG 체인 구성''' \n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\",     \"\"\"\n",
    "    You are **\"AI Tech Trend Navigator\"**, an expert assistant for AI/ML research papers.\n",
    "\n",
    "    [Role]\n",
    "    - You help users understand and leverage recent AI/ML papers collected from HuggingFace DailyPapers.\n",
    "    - Your main goals are:\n",
    "      - Summarize and compare relevant papers clearly.\n",
    "      - Explain core ideas in simple terms.\n",
    "      - Highlight practical use-cases and implications for real-world services or products.\n",
    "\n",
    "    [Inputs]\n",
    "    The system provides:\n",
    "    - user_question: the user’s question.\n",
    "     - context: a set of retrieved documents, formatted as a single text block.\n",
    "        - Sometimes the context may be exactly the string \"NO_RELEVANT_PAPERS\".\n",
    "      - page_content: main text (abstract or summary)\n",
    "      - metadata:\n",
    "        - paper_name\n",
    "        - github_url (optional)\n",
    "        - huggingface_url (optional)\n",
    "        - upvote (integer, popularity signal)\n",
    "        - tags: list of keywords\n",
    "        - year, week, and other fields.\n",
    "\n",
    "    You must rely only on:\n",
    "    - the given context, and\n",
    "    - general, high-level AI/ML knowledge.\n",
    "    Do NOT invent specific paper titles, authors, datasets, metrics, or numerical results\n",
    "    that are not supported by the context.\n",
    "\n",
    "\n",
    "    [Context Handling]\n",
    "    - If the context is **\"NO_RELEVANT_PAPERS\"**, it means:\n",
    "    - The retrieval system could not find any clearly relevant papers.\n",
    "    - In this case, you may answer **purely from your own general AI/ML knowledge**.\n",
    "    - Do NOT fabricate specific paper titles, authors, datasets, or numerical results.\n",
    "    - You may skip the \"Related papers\" section or keep it very generic.\n",
    "\n",
    "    - If the context contains one or more papers:\n",
    "    - Prefer to base your answer on those papers.\n",
    "    - Use only the papers that are reasonably related to the user’s question.\n",
    "                 \n",
    "    [Main Tasks]\n",
    "\n",
    "    1. Understand the user’s intent\n",
    "       - Roughly classify the question as one of:\n",
    "         - (a) concept/background explanation\n",
    "         - (b) single-paper summary\n",
    "         - (c) comparison or trend analysis across multiple papers\n",
    "         - (d) practical application and use-case ideas\n",
    "       - If the intent is ambiguous, make a reasonable assumption and continue.\n",
    "         You may briefly state what you assumed.\n",
    "\n",
    "    2. Use only the relevant papers\n",
    "       - Focus on the most relevant 1–3 papers in the given context.\n",
    "       - If some papers look only weakly related to the question, you may ignore them.\n",
    "       - If nothing is clearly relevant, say that the context does not directly answer the question.\n",
    "\n",
    "    3. Summarize each selected paper\n",
    "       For each paper you rely on, briefly cover:\n",
    "       - What problem it tries to solve.\n",
    "       - What approach/model/idea it uses.\n",
    "       - What seems new or strong compared to typical or baseline methods.\n",
    "       - Any obvious limitations, trade-offs, or caveats that are visible from the context.\n",
    "\n",
    "    4. Produce a synthesized answer\n",
    "       - Do not just list papers. Synthesize them to directly answer the user’s question.\n",
    "       - When possible, cover:\n",
    "         - Common themes or trends across the papers.\n",
    "         - How these ideas relate to topics such as RAG, long-context, multimodal models, etc.,\n",
    "           when relevant.\n",
    "         - How someone could apply these ideas in a real-world project, prototype, or product.\n",
    "\n",
    "    5. Be honest about uncertainty\n",
    "       - If the given context is not enough to answer precisely, say so.\n",
    "       - Suggest what extra information, papers, or queries would be helpful.\n",
    "\n",
    "    [Style]\n",
    "    - Answer in the SAME LANGUAGE as the user’s question.\n",
    "      (If the question is in Korean, answer in Korean. If it is in English, answer in English.)\n",
    "    - Prefer clear, concise sentences over heavy academic wording.\n",
    "    - Briefly explain technical terms when needed.\n",
    "    - Never fabricate paper titles, authors, datasets, or numerical results.\n",
    "    \"\"\"),\n",
    "                \n",
    "    (\"human\", \"\"\"\n",
    "    [QUESTION]\n",
    "    {question}\n",
    "\n",
    "     [Context]\n",
    "    The following CONTEXT block may contain 0 or more papers. \n",
    "    If it is \"NO_RELEVANT_PAPERS\", please answer from your general AI/ML knowledge.\n",
    "     \n",
    "    [CONTEXT]\n",
    "    ======== START ========\n",
    "    {context}\n",
    "    ======== END =========\n",
    "\n",
    "    Please structure your answer as follows (flexible, but try to follow this):\n",
    "\n",
    "    1) One-line summary  \n",
    "    2) Key insights (3-6 bullets)  \n",
    "    3) Related papers (top 1~3)  \n",
    "    4) Detailed explanation  \n",
    "    5) Sources summary\n",
    "\n",
    "    ⚠ Do not hallucinate papers or details not shown in context.\n",
    "    All responses must be written in Korean.\n",
    "    \"\"\")\n",
    "            ])\n",
    "        return (\n",
    "            {\n",
    "                \"context\": self.retriever | self._format_docs,\n",
    "                \"question\": RunnablePassthrough(),\n",
    "                \"chat_history\": lambda x: \"\"\n",
    "            }\n",
    "            | prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _format_docs(docs):\n",
    "        \"\"\"retriever가 반환한 Document들을 프롬프트용 텍스트로 변환\"\"\"\n",
    "        if not docs:\n",
    "            # ⚠️ 컨텍스트가 전혀 없을 때는 이 문자열로 보냄\n",
    "            return \"NO_RELEVANT_PAPERS\"\n",
    "\n",
    "        lines = []\n",
    "        for i, doc in enumerate(docs, start=1):\n",
    "            md = doc.metadata or {}\n",
    "\n",
    "            # tag1, tag2, tag3 → tags 리스트로 재구성\n",
    "            tags = [\n",
    "                md.get(\"tag1\"),\n",
    "                md.get(\"tag2\"),\n",
    "                md.get(\"tag3\"),\n",
    "            ]\n",
    "            tags = [t for t in tags if t]  # None/빈 값 제거\n",
    "\n",
    "            tag_str = f\"tags: {', '.join(tags)}\" if tags else \"tags: (none)\"\n",
    "\n",
    "            paper_name = md.get(\"paper_name\", \"(no title)\")\n",
    "            hf_url = md.get(\"huggingface_url\", \"\")\n",
    "            gh_url = md.get(\"github_url\", \"\")\n",
    "\n",
    "            link_lines = []\n",
    "            if hf_url:\n",
    "                link_lines.append(f\"HuggingFace: {hf_url}\")\n",
    "            if gh_url:\n",
    "                link_lines.append(f\"GitHub: {gh_url}\")\n",
    "            links_block = \"\\n\".join(link_lines) if link_lines else \"\"\n",
    "\n",
    "            block = f\"\"\"[{i}] {paper_name}\n",
    "                                {tag_str}\n",
    "                                {links_block}\n",
    "\n",
    "                                {doc.page_content}\"\"\"\n",
    "            lines.append(block)\n",
    "\n",
    "        return \"\\n\\n\".join(lines)\n",
    "\n",
    "\n",
    "    def ask(self, question:str) -> str:\n",
    "        '''질문에 답변'''\n",
    "        return self.chain.invoke(question)\n",
    "    \n",
    "\n",
    "    def ask_with_sources(self, question: str) -> dict:\n",
    "        \"\"\"질문에 답변 + 출처 반환\"\"\"\n",
    "        answer = self.chain.invoke(question)\n",
    "        source_docs = self.retriever.invoke(question)\n",
    "\n",
    "        sources = []\n",
    "        for doc in source_docs:\n",
    "            md = doc.metadata or {}\n",
    "            tags = [\n",
    "                md.get(\"tag1\"),\n",
    "                md.get(\"tag2\"),\n",
    "                md.get(\"tag3\"),\n",
    "            ]\n",
    "            tags = [t for t in tags if t]\n",
    "\n",
    "            sources.append(\n",
    "                {\n",
    "                    \"paper_name\": md.get(\"paper_name\", \"(no title)\"),\n",
    "                    \"huggingface_url\": md.get(\"huggingface_url\"),\n",
    "                    \"github_url\": md.get(\"github_url\"),\n",
    "                    \"upvote\": md.get(\"upvote\"),\n",
    "                    \"tags\": tags,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"sources\": sources,\n",
    "        }\n",
    "   \n",
    "\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    # chunk 파일로 임시 확인\n",
    "    def get_project_root():\n",
    "        curr = Path().resolve()\n",
    "        for parent in [curr] + list(curr.parents):\n",
    "            if (parent / \".git\").exists():\n",
    "                return parent\n",
    "        raise FileNotFoundError(\"프로젝트 루트 찾기 실패\")\n",
    "\n",
    "    PROJECT_ROOT = get_project_root()\n",
    "    DATA_DIR = PROJECT_ROOT / \"01_data/chunks\"\n",
    "\n",
    "    chunks_path = DATA_DIR / \"chunks_all.pkl\"\n",
    "\n",
    "    with open(chunks_path, \"rb\") as f:\n",
    "        chunks = pickle.load(f)\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        collection_name='test',\n",
    "        embedding=OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "    )\n",
    "\n",
    "  \n",
    "    llm = ChatOpenAI( model = 'gpt-4o-mini', temperature=0 )\n",
    "\n",
    "    rag_system = SimpleRAGSystem(vectorstore, llm)\n",
    "    user_question = \"META에서 만든 SAM MODEL이 뭔지 설명해줘\"\n",
    "    result = rag_system.ask_with_sources(user_question)\n",
    "\n",
    "    print(f\"질문: {user_question}\")\n",
    "    print(\"\\n[답변]\\n\")\n",
    "    print(result[\"answer\"])\n",
    "\n",
    "    print(\"\\n[출처]\\n\")\n",
    "    for i, src in enumerate(result[\"sources\"], start=1):\n",
    "        print(f\"- [{i}] {src['paper_name']}\")\n",
    "        if src[\"huggingface_url\"]:\n",
    "            print(f\"  HF: {src['huggingface_url']}\")\n",
    "        if src[\"github_url\"]:\n",
    "            print(f\"  GitHub: {src['github_url']}\")\n",
    "        if src[\"tags\"]:\n",
    "            print(f\"  tags: {', '.join(src['tags'])}\")\n",
    "        if src[\"upvote\"] is not None:\n",
    "            print(f\"  upvote: {src['upvote']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

"""
FastAPI RAG Chatbot Server

ì´ ì„œë²„ëŠ” HTML í”„ë¡ íŠ¸ì—”ë“œì™€ LangGraph RAG ì‹œìŠ¤í…œ(langgraph_test.py)ì„ ì—°ê²°í•©ë‹ˆë‹¤.
- í†µê³„ ì •ë³´ ì œê³µ
- íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì œê³µ
- LangGraph ê¸°ë°˜ ì±„íŒ… ì‘ë‹µ (ë‚´ë¶€ ê²€ìƒ‰ + ì›¹ ê²€ìƒ‰)
"""

import os
import json
from pathlib import Path
from typing import List, Dict, Optional
from collections import Counter

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# â˜… ë³€ê²½: LangChain LLM (langgraph_testì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ë™ì¼ ëª¨ë¸)
from langchain_openai import ChatOpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ============================================================================
# ê²½ë¡œ ì„¤ì •
# ============================================================================

# main.py ìœ„ì¹˜: 02_src/04_ui/main.py
CURRENT_DIR = Path(__file__).parent  # 02_src/04_ui
SRC_DIR = CURRENT_DIR.parent  # 02_src
PROJECT_ROOT = SRC_DIR.parent  # project root

# ë°ì´í„° ë””ë ‰í† ë¦¬
DATA_DIR = PROJECT_ROOT / "01_data"
CLUSTERS_DIR = DATA_DIR / "clusters"

# ëª¨ë“ˆ ê²½ë¡œ
RAG_PATH = SRC_DIR / "03_rag"      # langgraph_test.py ìœ„ì¹˜
UTILS_PATH = SRC_DIR / "02_utils"  # vectordb.py ìœ„ì¹˜

# sys.pathì— ì¶”ê°€
import sys
sys.path.insert(0, str(RAG_PATH))
sys.path.insert(0, str(UTILS_PATH))

# ============================================================================
# FastAPI ì•± ìƒì„±
# ============================================================================

app = FastAPI(
    title="HuggingFace Papers RAG API",
    description="LangGraph ê¸°ë°˜ RAG ì±—ë´‡ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# ì „ì—­ ë³€ìˆ˜
# ============================================================================

# LangGraph ì•±ì„ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜
rag_application: Optional[object] = None

# â˜… ë³€ê²½: langgraph_testìš© ì „ì—­ ë¦¬ì†ŒìŠ¤
vectorstore = None
llm = None
cluster_metadata_path: Optional[str] = None


# ============================================================================
# Pydantic ëª¨ë¸
# ============================================================================

class ChatRequest(BaseModel):
    """ì±„íŒ… ìš”ì²­ ëª¨ë¸"""
    message: str


# ============================================================================
# ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸
# ============================================================================

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ LangGraph RAG ì‹œìŠ¤í…œ ë¡œë“œ"""
    global rag_application, vectorstore, llm, cluster_metadata_path
    
    print("\n" + "=" * 70)
    print("ğŸš€ HuggingFace Papers RAG Server - Starting Up (langgraph_test ë²„ì „)")
    print("=" * 70)
    
    try:
        # 1. ê²½ë¡œ í™•ì¸
        print(f"\n[INFO] í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")
        print(f"[INFO] RAG ê²½ë¡œ: {RAG_PATH}")
        print(f"[INFO] langgraph_test.py ì¡´ì¬: {(RAG_PATH / 'langgraph_test.py').exists()}")

        # 2. langgraph_test ëª¨ë“ˆ ì„í¬íŠ¸
        print("\n[STEP 1/4] langgraph_test ëª¨ë“ˆ ì„í¬íŠ¸ ì¤‘...")
        try:
            # â˜… ë³€ê²½: lg_grade ëŒ€ì‹  langgraph_test ì‚¬ìš©
            from langgraph_test import (
                build_langgraph_rag,
                MODEL_NAME,
                CHUNK_SIZE,
                CHUNK_OVERLAP,
            )
            from vectordb import load_vectordb
            print("âœ… langgraph_test ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ")
        except ImportError as e:
            print(f"âŒ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            print(f"[DEBUG] sys.path: {sys.path[:8]}")
            raise

        # 3. VectorStore / LLM / Cluster metadata ì´ˆê¸°í™”
        print("\n[STEP 2/4] VectorStore / LLM / Cluster ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™” ì¤‘...")

        # VectorStore ë¡œë“œ (langgraph_testì˜ __main__ê³¼ ë™ì¼ ë¡œì§)
        print(f"[LOAD] VectorStore ë¡œë”© ì¤‘... (MODEL_NAME={MODEL_NAME}, "
              f"CHUNK_SIZE={CHUNK_SIZE}, CHUNK_OVERLAP={CHUNK_OVERLAP})")
        vectorstore = load_vectordb(MODEL_NAME, CHUNK_SIZE, CHUNK_OVERLAP)
        print("[SUCCESS] VectorStore ë¡œë”© ì™„ë£Œ")

        # LLM ì´ˆê¸°í™” (langgraph_testì™€ ë™ì¼ ëª¨ë¸)
        print("[LOAD] LLM ì´ˆê¸°í™” ì¤‘...")
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        print("[SUCCESS] LLM ì´ˆê¸°í™” ì™„ë£Œ")

        # Cluster metadata ê²½ë¡œ (langgraph_testì˜ PROJECT_ROOT ê¸°ì¤€ê³¼ ë™ì¼)
        cluster_metadata_path = str(
            PROJECT_ROOT / "01_data" / "clusters" / "cluster_metadata.json"
        )
        print(f"[INFO] Cluster metadata path: {cluster_metadata_path}")

        # 4. LangGraph ì•± ì»´íŒŒì¼
        print("\n[STEP 3/4] LangGraph ê·¸ë˜í”„ ì»´íŒŒì¼ ì¤‘...")
        rag_application = build_langgraph_rag()
        print(f"âœ… LangGraph ì•± ìƒì„± ì™„ë£Œ (íƒ€ì…: {type(rag_application).__name__})")

        # 5. ì™„ë£Œ
        print("\n[STEP 4/4] ì´ˆê¸°í™” ì™„ë£Œ")
        print("\n" + "=" * 70)
        print("âœ… RAG ì„œë²„ ì¤€ë¹„ ì™„ë£Œ! (langgraph_test)")
        print("ğŸ“¡ API ë¬¸ì„œ: http://localhost:8000/docs")
        print("=" * 70 + "\n")
        
    except Exception as e:
        print(f"\nâŒ [FAILED] ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise


# ============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@app.get("/")
async def root():
    """ë£¨íŠ¸ ê²½ë¡œ - ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "message": "HuggingFace Papers RAG API Server (langgraph_test)",
        "rag_loaded": rag_application is not None,
        "endpoints": {
            "stats": "/api/stats",
            "trending_keywords": "/api/trending-keywords",
            "chat": "/api/chat",
            "docs": "/docs"
        }
    }


@app.get("/api/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy" if rag_application is not None else "initializing",
        "rag_loaded": rag_application is not None
    }


@app.get("/api/stats")
async def get_stats() -> Dict:
    """
    í†µê³„ ì •ë³´ ë°˜í™˜
    - ë…¼ë¬¸ ê°œìˆ˜
    - í‚¤ì›Œë“œ ê°œìˆ˜
    - ì‚¬ìš©ëœ ì£¼ì°¨ ìˆ˜
    """
    try:
        # cluster_assignments.jsonì—ì„œ ë¬¸ì„œ ê°œìˆ˜ í™•ì¸
        assignments_path = CLUSTERS_DIR / "cluster_assignments.json"
        
        if not assignments_path.exists():
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "paper_count": 0,
                "keyword_count": 0,
                "weeks_used": 0
            }
        
        with open(assignments_path, "r", encoding="utf-8") as f:
            assignments_data = json.load(f)
        
        paper_count = assignments_data.get("_metadata", {}).get("n_documents", 0)
        weeks_used = len(assignments_data.get("_metadata", {}).get("weeks_used", []))
        
        # cluster_metadata.jsonì—ì„œ í‚¤ì›Œë“œ ê°œìˆ˜ í™•ì¸
        metadata_path = CLUSTERS_DIR / "cluster_metadata.json"
        
        if not metadata_path.exists():
            keyword_count = 0
        else:
            with open(metadata_path, "r", encoding="utf-8") as f:
                metadata = json.load(f)
            
            # ëª¨ë“  í´ëŸ¬ìŠ¤í„°ì˜ ê³ ìœ  í‚¤ì›Œë“œ ìˆ˜ì§‘
            all_keywords = set()
            for cluster_id, info in metadata.get("clusters", {}).items():
                all_keywords.update(info.get("keywords", []))
            
            keyword_count = len(all_keywords)
        
        return {
            "paper_count": paper_count,
            "keyword_count": keyword_count,
            "weeks_used": weeks_used
        }
    
    except Exception as e:
        print(f"[ERROR] í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/trending-keywords")
async def get_trending_keywords(top_n: int = 7) -> Dict:
    """
    íŠ¸ë Œë“œ í‚¤ì›Œë“œ ë°˜í™˜
    - ëª¨ë“  í´ëŸ¬ìŠ¤í„°ì˜ í‚¤ì›Œë“œë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¹ˆë„ìˆ˜ ê¸°ì¤€ ìƒìœ„ Nê°œ ë°˜í™˜
    """
    try:
        metadata_path = CLUSTERS_DIR / "cluster_metadata.json"
        
        if not metadata_path.exists():
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í‚¤ì›Œë“œ ë°˜í™˜
            return {
                "keywords": ["LLM", "Transformer", "RAG", "Vision", "Diffusion", "Agent", "Multimodal"]
            }
        
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        
        # ëª¨ë“  í´ëŸ¬ìŠ¤í„°ì˜ í‚¤ì›Œë“œ ìˆ˜ì§‘
        all_keywords = []
        for cluster_id, info in metadata.get("clusters", {}).items():
            all_keywords.extend(info.get("keywords", []))
        
        # ë¹ˆë„ìˆ˜ ê³„ì‚° ë° ìƒìœ„ Nê°œ ì¶”ì¶œ
        keyword_counts = Counter(all_keywords)
        top_keywords = [kw for kw, _ in keyword_counts.most_common(top_n)]
        
        # ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ í‚¤ì›Œë“œë¡œ ì±„ìš°ê¸°
        default_keywords = ["LLM", "Transformer", "RAG", "Vision", "Diffusion", "Agent", "Multimodal"]
        for kw in default_keywords:
            if kw not in top_keywords and len(top_keywords) < top_n:
                top_keywords.append(kw)
        
        return {
            "keywords": top_keywords[:top_n]
        }
    
    except Exception as e:
        print(f"[ERROR] íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/chat")
async def chat(request: ChatRequest) -> Dict:
    """
    LangGraph RAG ê¸°ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„± (langgraph_test ì‚¬ìš©)
    1. LangGraph ì•± ì‹¤í–‰ (ë²ˆì—­ â†’ ë‚´ë¶€ ê²€ìƒ‰ â†’ ë¬¸ì„œ í‰ê°€ â†’ í´ëŸ¬ìŠ¤í„° ì²´í¬ â†’ ì›¹ ê²€ìƒ‰/ìƒì„±)
    2. ìµœì¢… ë‹µë³€ ë° ê²€ìƒ‰ íƒ€ì…, ì°¸ì¡° ë¬¸ì„œ ë°˜í™˜
    """
    # RAG ì‹œìŠ¤í…œ í™•ì¸
    if rag_application is None:
        raise HTTPException(
            status_code=503,
            detail="RAG ì‹œìŠ¤í…œì´ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
    
    try:
        query = request.message
        print(f"\n{'='*70}")
        print(f"ğŸ“ [QUERY] {query}")
        print(f"{'='*70}")
        
        # â˜… ë³€ê²½: langgraph_testì˜ GraphState êµ¬ì¡°ì— ë§ëŠ” ì´ˆê¸° ìƒíƒœ ì •ì˜
        initial_state = {
            # ì§ˆë¬¸ ê´€ë ¨
            "original_question": query,     # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì›ë³¸ ì§ˆë¬¸
            "question": query,              # ì´ˆê¸°ì—ëŠ” ë™ì¼, translate ë…¸ë“œì—ì„œ ê°±ì‹ 
            "translated_question": None,
            "is_korean": False,

            # ê²€ìƒ‰/í´ëŸ¬ìŠ¤í„° ê´€ë ¨
            "documents": [],
            "doc_scores": [],
            "cluster_id": None,
            "cluster_similarity_score": None,
            "search_type": "internal",
            "relevance_level": "",

            # ì¶œë ¥ ê´€ë ¨
            "answer": "",
            "sources": [],

            # ë‚´ë¶€ ë¦¬ì†ŒìŠ¤ ì£¼ì…
            "_vectorstore": vectorstore,
            "_llm": llm,
            "_cluster_metadata_path": cluster_metadata_path,
        }
        
        # LangGraph ì•± ì‹¤í–‰
        print("[LANGGRAPH] RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘... (langgraph_test)")
        result = rag_application.invoke(initial_state)
        
        # ê²°ê³¼ ì¶”ì¶œ
        answer = result.get("answer", "ë‹µë³€ ìƒì„± ì‹¤íŒ¨")
        search_type = result.get("search_type", "unknown")
        documents = result.get("documents", [])

        print(f"âœ… [SUCCESS] ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        print(f"   - ê²€ìƒ‰ íƒ€ì…: {search_type}")
        print(f"   - ë¬¸ì„œ ìˆ˜: {len(documents)}")
        
        # ì¶œì²˜ ì •ë³´ êµ¬ì„± (ê¸°ì¡´ ë°©ì‹ ìœ ì§€: Document ë©”íƒ€ë°ì´í„° ê¸°ë°˜)
        sources = []
        for doc in documents[:5]:  # ìµœëŒ€ 5ê°œë§Œ
            metadata = getattr(doc, "metadata", {}) or {}
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ì¸ ê²½ìš°
            if search_type == "web" or metadata.get("source_type") == "web":
                # â˜… langgraph_test.pyì—ì„œ ì´ë¯¸ ì •ë¦¬ëœ title ì‚¬ìš©
                sources.append({
                    "doc_id": str(metadata.get("source", "web_unknown"))[:50],
                    "title": metadata.get("title", "ì›¹ ê²€ìƒ‰ ê²°ê³¼"),  # Tavilyì˜ ì‹¤ì œ ì œëª©
                    "source_type": "web",
                    "url": metadata.get("source", "")
                })
            # ë‚´ë¶€ ë¬¸ì„œì¸ ê²½ìš°
            else:
                sources.append({
                    "doc_id": metadata.get("doc_id", "unknown"),
                    "title": metadata.get("title", "Unknown"),
                    "authors": metadata.get("authors", "Unknown"),
                    "year": metadata.get("publication_year", "Unknown"),
                    "source_type": "internal"
                })
        
        return {
            "response": answer,
            "sources": sources,
            "search_type": search_type,
            "doc_count": len(documents)
        }
    
    except Exception as e:
        print(f"âŒ [ERROR] ì±„íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


# ============================================================================
# ì„œë²„ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    print("\n" + "=" * 70)
    print("ğŸ¤— HuggingFace Papers RAG Server (langgraph_test ì—°ê²° ë²„ì „)")
    print("=" * 70)
    print("Starting server on http://localhost:8000")
    print("API Docs: http://localhost:8000/docs")
    print("=" * 70 + "\n")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
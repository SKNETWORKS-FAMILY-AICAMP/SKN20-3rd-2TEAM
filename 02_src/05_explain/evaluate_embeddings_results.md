# 임베딩 모델 평가 결과

## 개요

이 문서는 HuggingFace DailyPapers RAG 시스템을 위한 7가지 임베딩 모델의 평가 결과를 담고 있습니다.

**평가 날짜:** 2025-12-07
**전체 청크 수:** 18,336개 (평가를 위해 2,000개 샘플링)
**테스트 쿼리:** 10개 (KeyBERT 추출 태그 기반)

## 평가 지표

- **Recall@5 (R@5):** 상위 5개 결과에서 관련 문서를 찾은 비율
- **Recall@10 (R@10):** 상위 10개 결과에서 관련 문서를 찾은 비율
- **MRR (Mean Reciprocal Rank):** 첫 번째 관련 문서의 순위 역수 평균
- **Avg Time:** 평균 쿼리 시간 (초)

## 테스트 쿼리

KeyBERT로 추출된 실제 태그에 맞춰 설계된 테스트 쿼리:

1. video understanding and long video comprehension models
2. multimodal benchmarks and evaluation methods
3. code generation and programming with large language models
4. diffusion models for image and video generation
5. reinforcement learning with reward models and RLHF
6. mathematical reasoning and verifiable solutions
7. robotic manipulation and vision-language-action models
8. image editing and instruction-guided generation
9. attention mechanisms and transformer architectures
10. spatial reasoning and navigation with vision models

## 결과 요약

| 순위 | 모델 | R@5 | R@10 | MRR | 평균 시간 (초) |
|------|-------|-----|------|-----|--------------------|
| 🥇 1 | **MiniLM-L6** | 0.015 | **0.026** | 0.664 | **0.01** |
| 2 | MPNet | 0.013 | **0.025** | 0.698 | 0.02 |
| 3 | Paraphrase-Multi | **0.014** | **0.025** | 0.750 | 0.02 |
| 4 | SPECTER | 0.013 | 0.024 | 0.700 | 0.02 |
| 5 | OpenAI-small | 0.012 | 0.023 | 0.720 | 1.88 |
| 6 | BGE-M3 | 0.012 | 0.021 | **0.770** | 0.07 |
| 7 | MsMarco | 0.010 | 0.017 | 0.633 | **0.01** |

*참고: Jina-v2 모델은 초기화 오류로 인해 로드 실패*

## 상세 모델 분석

### 1. MiniLM-L6

- **모델:** `sentence-transformers/all-MiniLM-L6-v2`
- **차원:** 384
- **최고 지표:** Recall@10 (0.026), 가장 빠른 속도 (0.01초)
- **장점:**
  - 가장 높은 Recall@10 성능
  - **가장 빠른 추론 시간** (0.01초)
  - 가장 작은 모델 크기 (384 차원)
  - 우수한 속도 대비 성능 비율
- **단점:**
  - MRR이 다른 모델에 비해 낮음 (0.664)
  - 관련 문서의 순위가 다소 낮을 수 있음

**권장 사항:** 로컬 배포에 탁월한 선택. 최고의 속도 대비 성능 비율을 제공하며, 실시간 검색이 중요한 경우 최적.

---

### 2. MPNet

- **모델:** `sentence-transformers/all-mpnet-base-v2`
- **차원:** 768
- **성능:**
  - R@5: 0.013
  - R@10: 0.025 (공동 2위)
  - MRR: 0.698
- **장점:**
  - 우수한 Recall@10 성능
  - 균형 잡힌 MRR 점수
  - 고품질 임베딩
  - 안정적인 성능
- **단점:**
  - MiniLM-L6보다 2배 느림 (0.02초)
  - 더 큰 모델 크기 (768 차원)

**권장 사항:** 품질과 속도의 균형이 필요한 경우 선택. MiniLM-L6보다 약간 느리지만 안정적인 성능 제공.

---

### 3. Paraphrase-Multilingual

- **모델:** `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
- **차원:** 768
- **성능:**
  - R@5: 0.014 (2위)
  - R@10: 0.025 (공동 2위)
  - **MRR: 0.750** (2위)
- **장점:**
  - 높은 MRR 점수 (0.750)
  - 다국어 지원 (50개 이상 언어)
  - 관련 문서를 찾으면 높은 순위에 배치
  - 좋은 Recall@10 성능
- **단점:**
  - 영어 전용 과학 콘텐츠에 최적화되지 않을 수 있음
  - MPNet과 유사한 속도 (0.02초)

**권장 사항:** 다국어 지원이 필요하거나 첫 번째 결과의 품질이 중요한 경우 선택. 교차 언어 검색에 적합.

---

### 4. SPECTER (과학 논문 특화)

- **모델:** `sentence-transformers/allenai-specter`
- **차원:** 768
- **특화 분야:** 과학 논문
- **성능:**
  - R@5: 0.013
  - R@10: 0.024
  - MRR: 0.700
- **장점:**
  - 과학/학술 콘텐츠에 특화
  - 안정적인 MRR 점수 (0.700)
  - 과학 논문 데이터로 사전 학습
  - 적절한 속도 (0.02초)
- **단점:**
  - Recall@10이 다소 낮음
  - 범용 콘텐츠에는 최적이 아닐 수 있음

**권장 사항:** HuggingFace DailyPapers와 같은 과학 논문 데이터셋에 적합하나, KeyBERT 태그 기반 평가에서는 다른 모델과 비슷한 성능.

---

### 5. OpenAI text-embedding-3-small

- **모델:** `text-embedding-3-small`
- **차원:** 1536
- **성능:**
  - R@5: 0.012
  - R@10: 0.023
  - MRR: 0.720 (3위)
- **장점:**
  - 우수한 MRR 점수 (0.720)
  - 상용급 품질
  - 대형 모델 (1536 차원)
- **단점:**
  - **가장 느린 추론 시간** (1.88초, 로컬 모델 대비 **188배** 느림)
  - Recall@10이 낮음 (0.023)
  - 네트워크 지연 및 API 의존성
  - 높은 차원으로 인해 더 많은 스토리지 필요

**권장 사항:** 속도보다 MRR이 중요하고 API 비용을 감당할 수 있는 경우에만 고려. 대부분의 경우 로컬 모델이 더 나은 선택.

---

### 6. BGE-M3

- **모델:** `BAAI/bge-m3`
- **차원:** 1024
- **성능:**
  - R@5: 0.012
  - R@10: 0.021
  - **MRR: 0.770** (최고)
- **장점:**
  - **전체 모델 중 가장 높은 MRR** (0.770)
  - 중국어와 영어 지원
  - 관련 문서를 찾으면 매우 높은 순위에 배치
  - 대형 모델 (1024 차원)
- **단점:**
  - 로컬 모델 중 가장 느림 (0.07초)
  - Recall@10이 낮음 (0.021)
  - 영어 전용 콘텐츠에는 과한 사양
  - 메모리 사용량 많음

**권장 사항:** 첫 번째 결과의 정확도(MRR)가 가장 중요하고 속도가 덜 중요한 경우 선택. 중국어 지원이 필요한 경우 적합.

---

### 7. MsMarco-MiniLM

- **모델:** `sentence-transformers/msmarco-MiniLM-L-6-v3`
- **차원:** 384
- **성능:**
  - R@5: 0.010
  - R@10: 0.017
  - MRR: 0.633
- **장점:**
  - 빠른 추론 (0.01초)
  - 패시지 검색에 최적화
  - 작은 모델 크기 (384 차원)
- **단점:**
  - 전반적으로 가장 낮은 성능
  - MS MARCO 데이터셋(질의응답)으로 학습되어 과학 논문 및 KeyBERT 태그에 맞지 않을 수 있음

**권장 사항:** 이 사용 사례에는 권장하지 않음. MiniLM-L6가 동일한 속도에서 더 좋은 성능 제공.

---

## 주요 발견사항

1. **MiniLM-L6**가 최고의 Recall@10과 가장 빠른 속도로 속도 대비 성능 비율이 가장 우수
2. **BGE-M3**가 가장 높은 MRR(0.770)을 달성했지만 로컬 모델 중 가장 느림
3. **OpenAI text-embedding-3-small**은 MRR 0.720으로 우수하나, 속도가 매우 느림 (1.88초, 로컬 대비 188배)
4. **Paraphrase-Multilingual**과 **MPNet**이 Recall@10에서 공동 2위로 균형잡힌 성능 제공
5. KeyBERT로 추출된 태그 기반 평가에서 모든 모델이 낮은 Recall 점수를 보임
6. MRR이 Recall보다 높게 나온 것은 관련 문서를 찾으면 상위에 배치되지만, 전체적으로 찾는 비율은 낮다는 의미
7. OpenAI 모델의 속도 문제로 인해 실시간 RAG 시스템에는 로컬 모델이 훨씬 유리

## KeyBERT 태그 기반 평가의 특징

이번 평가는 KeyBERT로 추출된 태그(`tags` 필드)를 ground truth로 사용했습니다:

- **태그 예시:** `['programming future', 'andqwencoder critically', 'large codebases']`
- **매칭 방식:** 부분 문자열 매칭 (예: "video"가 "grained video"와 매칭)
- **특징:** KeyBERT 태그는 구문 기반(1-2단어)으로 구체적이고 도메인 특화적
- **한계:** 낮은 Recall 점수는 임베딩 모델이 키워드 매칭과는 다른 방식으로 의미를 포착함을 시사

## 성능 대 속도 비교

```
속도 (쿼리 시간)
MiniLM-L6:   0.01초  ████
MsMarco:     0.01초  ████
MPNet:       0.02초  ████████
SPECTER:     0.02초  ████████
Paraphrase:  0.02초  ████████
BGE-M3:      0.07초  ████████████████████████████
OpenAI:      1.88초  ████████████████████████████████████████████████████████████████████████████

Recall@10 성능
MiniLM-L6:   0.026  █████████████
MPNet:       0.025  ████████████▌
Paraphrase:  0.025  ████████████▌
SPECTER:     0.024  ████████████
OpenAI:      0.023  ███████████▌
BGE-M3:      0.021  ██████████▌
MsMarco:     0.017  ████████▌

MRR 성능
BGE-M3:      0.770  ██████████████████████████████████████▌
Paraphrase:  0.750  █████████████████████████████████████▌
OpenAI:      0.720  ████████████████████████████████████
SPECTER:     0.700  ███████████████████████████████████
MPNet:       0.698  ██████████████████████████████████▌
MiniLM-L6:   0.664  █████████████████████████████████
MsMarco:     0.633  ███████████████████████████████▌
```

## 성능-속도 효율성 분석

| 모델 | Recall@10 | 시간(초) | 효율성 (R@10/시간) |
|------|-----------|----------|-------------------|
| MiniLM-L6 | 0.026 | 0.01 | **2.600** |
| MPNet | 0.025 | 0.02 | 1.250 |
| Paraphrase-Multi | 0.025 | 0.02 | 1.250 |
| SPECTER | 0.024 | 0.02 | 1.200 |
| MsMarco | 0.017 | 0.01 | 1.700 |
| BGE-M3 | 0.021 | 0.07 | 0.300 |
| OpenAI | 0.023 | 1.88 | **0.012** |

**핵심 인사이트:** MiniLM-L6가 OpenAI보다 **216배** 더 효율적입니다!

## 사용 사례별 권장사항

### 로컬 배포 (속도 우선)
**권장:** `MiniLM-L6`
- 가장 빠른 추론 (0.01초)
- 최고의 Recall@10 (0.026)
- 가장 작은 모델 풋프린트 (384 차원)
- **최고의 성능-속도 효율성** (2.600)

### 로컬 배포 (품질 우선)
**권장:** `BGE-M3`
- 최고 MRR (0.770)
- 첫 번째 결과 정확도 최우선
- 중국어 지원

**대안:** `Paraphrase-Multi`
- 높은 MRR (0.750) + 다국어 지원
- 더 빠른 속도 (0.02초 vs 0.07초)

### 균형잡힌 성능
**권장:** `MPNet`
- 좋은 Recall@10 (0.025)
- 우수한 MRR (0.698)
- 적절한 속도 (0.02초)
- 안정적이고 신뢰할 수 있는 성능

### 다국어 지원
**권장:** `Paraphrase-Multilingual`
- 높은 MRR (0.750)
- 50개 이상의 언어 지원
- 교차 언어 검색에 적합
- 좋은 Recall@10 (0.025)

### 과학 논문 특화
**권장:** `SPECTER`
- 과학/학술 콘텐츠에 최적화
- 안정적인 성능 (MRR 0.700, Recall@10 0.024)
- HuggingFace DailyPapers와 같은 데이터셋에 적합

### API 기반
**권장:** `OpenAI text-embedding-3-small`
- 우수한 MRR (0.720)
- 상용급 품질
- **주의:** 매우 느린 속도 (1.88초)와 API 비용

**ROI 분석:**
- OpenAI: $0.09 + 느린 속도 (1.88초)
- MiniLM-L6: $0 + 빠른 속도 (0.01초) + 더 높은 Recall@10

**결론:** 로컬 모델이 비용과 성능 모두에서 우수

## 기술 노트

- 전체 18,336개 중 무작위로 샘플링한 2,000개 청크로 평가 수행
- 모든 모델은 CPU에서 평가
- 배치 크기: 배치당 100개 문서
- 공정한 비교를 위해 정규화가 활성화된 모델 사용
- Jina-v2 모델은 초기화 오류로 제외: `JinaBertModel.__init__() got an unexpected keyword argument 'device'`
- 재현성을 위한 랜덤 시드: 42
- KeyBERT 태그 기반 관련 문서 매칭 사용

---

*생성자: `02_src/02_utils/evaluate_embeddings.py`*<br>
*실행 시간: 약 3분*<br>
*플랫폼: Windows*<br>
*날짜: 2025-12-07*<br>
*Python: 3.10*

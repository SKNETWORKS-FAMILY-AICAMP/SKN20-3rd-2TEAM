"""
ì„ë² ë”© ëª¨ë¸ ë¹„êµ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

5ê°œì˜ ì„ë² ë”© ëª¨ë¸ì„ ë¹„êµí•˜ì—¬ ìµœì ì˜ ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤.

í‰ê°€ ëª¨ë¸:
1. sentence-transformers/all-MiniLM-L6-v2
2. sentence-transformers/all-mpnet-base-v2
3. sentence-transformers/msmarco-MiniLM-L-6-v3
4. sentence-transformers/allenai-specter (scientific papers)
5. OpenAI text-embedding-3-small
6. BAAI/bge-m3
7. E5-Mistral / Jina-embeddings (Jina v2, v3)
8. paraphrase-multilingual-mpnet-base-v2

í‰ê°€ ë°©ë²•:
- í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ì— ëŒ€í•œ ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
- Cosine similarity ê¸°ë°˜ Recall@k, MRR ê³„ì‚°
- ê° ì¿¼ë¦¬ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œê°€ ìƒìœ„ì— í¬í•¨ë˜ëŠ”ì§€ í‰ê°€

Version: 1.0
Author: SKN20-3rd-2TEAM
"""

import os
import pickle
import time
import logging
from typing import List, Dict, Tuple
from dataclasses import dataclass

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from langchain_core.documents import Document
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv

# Load environment variables
load_dotenv()


# ==================== ë¡œê¹… ì„¤ì • ====================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ==================== í‰ê°€ìš© ë°ì´í„° í´ë˜ìŠ¤ ====================

@dataclass
class TestQuery:
    """í‰ê°€ìš© í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬"""
    query: str
    relevant_keywords: List[str]  # ê´€ë ¨ í‚¤ì›Œë“œ (metadata.tagsì—ì„œ ë§¤ì¹­)
    relevant_doc_ids: List[str] = None  # íŠ¹ì • ë¬¸ì„œ ID (optional)

    def __repr__(self):
        return f"TestQuery(query='{self.query[:50]}...', keywords={self.relevant_keywords})"


@dataclass
class EvaluationResult:
    """ëª¨ë¸ í‰ê°€ ê²°ê³¼"""
    model_name: str
    recall_at_5: float
    recall_at_10: float
    mrr: float  # Mean Reciprocal Rank
    avg_time: float  # í‰ê·  ê²€ìƒ‰ ì‹œê°„ (ì´ˆ)

    def __repr__(self):
        return (f"EvaluationResult(model='{self.model_name}', "
                f"R@5={self.recall_at_5:.3f}, R@10={self.recall_at_10:.3f}, "
                f"MRR={self.mrr:.3f}, time={self.avg_time:.2f}s)")


# ==================== í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜ ====================

TEST_QUERIES = [
    TestQuery(
        query="ìµœì‹  vision transformer ëª¨ë¸ê³¼ ì´ë¯¸ì§€ ë¶„ë¥˜ ì„±ëŠ¥",
        relevant_keywords=["vision", "transformer", "image"]
    ),
    TestQuery(
        query="ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ fine-tuning ê¸°ë²•",
        relevant_keywords=["llm", "fine-tuning", "training"]
    ),
    TestQuery(
        query="code generationì„ ìœ„í•œ LLM ëª¨ë¸",
        relevant_keywords=["code", "generation", "llm"]
    ),
    TestQuery(
        query="multimodal learningê³¼ vision-language ëª¨ë¸",
        relevant_keywords=["multimodal", "vision", "language"]
    ),
    TestQuery(
        query="reinforcement learning from human feedback",
        relevant_keywords=["reinforcement", "rlhf", "feedback"]
    ),
    TestQuery(
        query="diffusion models for image generation",
        relevant_keywords=["diffusion", "image", "generation"]
    ),
    TestQuery(
        query="efficient transformers and model compression",
        relevant_keywords=["efficient", "transformer", "compression"]
    ),
    TestQuery(
        query="graph neural networks and molecular modeling",
        relevant_keywords=["graph", "neural", "molecular"]
    ),
    TestQuery(
        query="video understanding and temporal modeling",
        relevant_keywords=["video", "temporal", "understanding"]
    ),
    TestQuery(
        query="zero-shot and few-shot learning methods",
        relevant_keywords=["zero-shot", "few-shot", "learning"]
    ),
]

# ==================== ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ====================

def init_models() -> Dict[str, any]:
    """
    8ê°œ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”

    Returns:
        Dict[str, embedding_model]: ëª¨ë¸ëª… -> ì„ë² ë”© ëª¨ë¸ ê°ì²´
    """
    models = {}

    logger.info("[ëª¨ë¸ ì´ˆê¸°í™”] 5ê°œ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹œì‘...")

    # 1. all-MiniLM-L6-v2 (384 dim, ë¹ ë¦„)
    try:
        models["MiniLM-L6"] = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("âœ“ MiniLM-L6-v2 ë¡œë”© ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âœ— MiniLM-L6-v2 ë¡œë”© ì‹¤íŒ¨: {e}")

    # 2. all-mpnet-base-v2 (768 dim, ë†’ì€ í’ˆì§ˆ)
    try:
        models["MPNet"] = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-mpnet-base-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("âœ“ MPNet-base-v2 ë¡œë”© ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âœ— MPNet-base-v2 ë¡œë”© ì‹¤íŒ¨: {e}")

    # 3. msmarco-MiniLM-L-6-v3 (384 dim, ê²€ìƒ‰ ìµœì í™”)
    try:
        models["MsMarco"] = HuggingFaceEmbeddings(
            model_name="sentence-transformers/msmarco-MiniLM-L-6-v3",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("âœ“ MsMarco-MiniLM ë¡œë”© ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âœ— MsMarco-MiniLM ë¡œë”© ì‹¤íŒ¨: {e}")

    # 4. allenai-specter (768 dim, scientific papers íŠ¹í™”)
    try:
        models["SPECTER"] = HuggingFaceEmbeddings(
            model_name="sentence-transformers/allenai-specter",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("âœ“ SPECTER (scientific) ë¡œë”© ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âœ— SPECTER ë¡œë”© ì‹¤íŒ¨: {e}")

    # 5. OpenAI text-embedding-3-small (1536 dim)
    try:
        if os.getenv("OPENAI_API_KEY"):
            models["OpenAI-small"] = OpenAIEmbeddings(
                model="text-embedding-3-small"
            )
            logger.info("âœ“ OpenAI text-embedding-3-small ë¡œë”© ì™„ë£Œ")
        else:
            logger.warning("âœ— OPENAI_API_KEY not found, skipping OpenAI model")
    except Exception as e:
        logger.error(f"âœ— OpenAI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")

    # 6. BAAI/bge-m3 (1024 dim, ì¤‘êµ­ì–´ ë° ì˜ì–´ ì§€ì›)
    try:
        models["BGE-M3"] = HuggingFaceEmbeddings(
            model_name="BAAI/bge-m3",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("âœ“ BGE-M3 ë¡œë”© ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âœ— BGE-M3 ë¡œë”© ì‹¤íŒ¨: {e}")

    # 7. E5-Mistral / Jina-embeddings (Jina v2, v3)
    try:
        models["E5-Base"] = HuggingFaceEmbeddings(
            model_name="intfloat/e5-base-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("âœ“ E5-Base ë¡œë”© ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âœ— E5-Base ë¡œë”© ì‹¤íŒ¨: {e}")

    # 8. paraphrase-multilingual-mpnet-base-v2 (768 dim, ë‹¤êµ­ì–´ ì§€ì›)
    try:
        models["Paraphrase-Multi"] = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("âœ“ Paraphrase-Multilingual ë¡œë”© ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âœ— Paraphrase-Multilingual ë¡œë”© ì‹¤íŒ¨: {e}")

    logger.info(f"[ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ] {len(models)}ê°œ ëª¨ë¸ ì¤€ë¹„ë¨")
    return models


# ==================== í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚° ====================

def calculate_recall_at_k(
    relevant_indices: List[int],
    retrieved_indices: List[int],
    k: int
) -> float:
    """
    Recall@k ê³„ì‚°

    Args:
        relevant_indices: ê´€ë ¨ ë¬¸ì„œ ì¸ë±ìŠ¤ ëª©ë¡
        retrieved_indices: ê²€ìƒ‰ëœ ë¬¸ì„œ ì¸ë±ìŠ¤ ëª©ë¡ (ìƒìœ„ kê°œ)
        k: ìƒìœ„ kê°œ

    Returns:
        float: Recall@k ì ìˆ˜
    """
    if not relevant_indices:
        return 0.0

    retrieved_k = set(retrieved_indices[:k])
    relevant_set = set(relevant_indices)

    hits = len(retrieved_k & relevant_set)
    recall = hits / len(relevant_set)

    return recall


def calculate_mrr(
    relevant_indices: List[int],
    retrieved_indices: List[int]
) -> float:
    """
    Mean Reciprocal Rank ê³„ì‚°

    Args:
        relevant_indices: ê´€ë ¨ ë¬¸ì„œ ì¸ë±ìŠ¤ ëª©ë¡
        retrieved_indices: ê²€ìƒ‰ëœ ë¬¸ì„œ ì¸ë±ìŠ¤ ëª©ë¡

    Returns:
        float: MRR ì ìˆ˜
    """
    relevant_set = set(relevant_indices)

    for rank, idx in enumerate(retrieved_indices, 1):
        if idx in relevant_set:
            return 1.0 / rank

    return 0.0


# ==================== ê²€ìƒ‰ ë° í‰ê°€ ====================

def find_relevant_docs(
    chunks: List[Document],
    test_query: TestQuery
) -> List[int]:
    """
    í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œ ì¸ë±ìŠ¤ ì°¾ê¸°

    Args:
        chunks: ì „ì²´ ë¬¸ì„œ ì²­í¬
        test_query: í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬

    Returns:
        List[int]: ê´€ë ¨ ë¬¸ì„œ ì¸ë±ìŠ¤ ëª©ë¡
    """
    relevant_indices = []

    for idx, doc in enumerate(chunks):
        tags = doc.metadata.get('tags', [])

        # ê´€ë ¨ í‚¤ì›Œë“œê°€ tagsì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if any(keyword.lower() in [tag.lower() for tag in tags]
               for keyword in test_query.relevant_keywords):
            relevant_indices.append(idx)

    return relevant_indices


def retrieve_top_k(
    query_embedding: np.ndarray,
    doc_embeddings: np.ndarray,
    k: int = 10
) -> List[int]:
    """
    Cosine similarity ê¸°ë°˜ ìƒìœ„ kê°œ ë¬¸ì„œ ì¸ë±ìŠ¤ ê²€ìƒ‰

    Args:
        query_embedding: ì¿¼ë¦¬ ì„ë² ë”© (1, dim)
        doc_embeddings: ë¬¸ì„œ ì„ë² ë”© (n, dim)
        k: ìƒìœ„ kê°œ

    Returns:
        List[int]: ìƒìœ„ kê°œ ë¬¸ì„œ ì¸ë±ìŠ¤
    """
    # Cosine similarity ê³„ì‚°
    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]

    # ìƒìœ„ kê°œ ì¸ë±ìŠ¤
    top_k_indices = np.argsort(similarities)[::-1][:k]

    return top_k_indices.tolist()


def evaluate_model(
    model_name: str,
    embedding_model: any,
    chunks: List[Document],
    test_queries: List[TestQuery],
    top_k: int = 10
) -> EvaluationResult:
    """
    ë‹¨ì¼ ëª¨ë¸ í‰ê°€

    Args:
        model_name: ëª¨ë¸ëª…
        embedding_model: ì„ë² ë”© ëª¨ë¸
        chunks: ì „ì²´ ë¬¸ì„œ ì²­í¬
        test_queries: í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ëª©ë¡
        top_k: ìƒìœ„ kê°œ ê²€ìƒ‰

    Returns:
        EvaluationResult: í‰ê°€ ê²°ê³¼
    """
    logger.info(f"\n[í‰ê°€ ì‹œì‘] {model_name}")

    # 1. ëª¨ë“  ë¬¸ì„œ ì„ë² ë”© ìƒì„±
    logger.info(f"  - ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì¤‘... ({len(chunks)}ê°œ)")
    start_time = time.time()

    try:
        # ë°°ì¹˜ë¡œ ì„ë² ë”© (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        batch_size = 100
        all_embeddings = []

        for i in range(0, len(chunks), batch_size):
            batch_docs = chunks[i:i+batch_size]
            batch_texts = [doc.page_content for doc in batch_docs]

            if hasattr(embedding_model, 'embed_documents'):
                batch_embeddings = embedding_model.embed_documents(batch_texts)
            else:
                # OpenAIì˜ ê²½ìš°
                batch_embeddings = [embedding_model.embed_query(text) for text in batch_texts]

            all_embeddings.extend(batch_embeddings)

            if (i // batch_size + 1) % 10 == 0:
                logger.info(f"    ì§„í–‰: {i+len(batch_docs)}/{len(chunks)}")

        doc_embeddings = np.array(all_embeddings)
        embedding_time = time.time() - start_time
        logger.info(f"  - ì„ë² ë”© ì™„ë£Œ ({embedding_time:.2f}ì´ˆ)")

    except Exception as e:
        logger.error(f"  âœ— ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return EvaluationResult(model_name, 0.0, 0.0, 0.0, 0.0)

    # 2. ê° í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ í‰ê°€
    recall_5_scores = []
    recall_10_scores = []
    mrr_scores = []
    query_times = []

    for query_idx, test_query in enumerate(test_queries, 1):
        logger.info(f"  - ì¿¼ë¦¬ {query_idx}/{len(test_queries)}: '{test_query.query[:50]}...'")

        # ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
        relevant_indices = find_relevant_docs(chunks, test_query)

        if not relevant_indices:
            logger.warning(f"    ê²½ê³ : ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ")
            continue

        logger.info(f"    ê´€ë ¨ ë¬¸ì„œ: {len(relevant_indices)}ê°œ")

        # ì¿¼ë¦¬ ì„ë² ë”© ë° ê²€ìƒ‰
        try:
            start_time = time.time()
            query_embedding = np.array([embedding_model.embed_query(test_query.query)])
            retrieved_indices = retrieve_top_k(query_embedding, doc_embeddings, k=top_k)
            query_time = time.time() - start_time
            query_times.append(query_time)

            # ë©”íŠ¸ë¦­ ê³„ì‚°
            recall_5 = calculate_recall_at_k(relevant_indices, retrieved_indices, k=5)
            recall_10 = calculate_recall_at_k(relevant_indices, retrieved_indices, k=10)
            mrr = calculate_mrr(relevant_indices, retrieved_indices)

            recall_5_scores.append(recall_5)
            recall_10_scores.append(recall_10)
            mrr_scores.append(mrr)

            logger.info(f"    R@5={recall_5:.3f}, R@10={recall_10:.3f}, MRR={mrr:.3f}")

        except Exception as e:
            logger.error(f"    âœ— ì¿¼ë¦¬ í‰ê°€ ì‹¤íŒ¨: {e}")
            continue

    # 3. í‰ê·  ê³„ì‚°
    avg_recall_5 = np.mean(recall_5_scores) if recall_5_scores else 0.0
    avg_recall_10 = np.mean(recall_10_scores) if recall_10_scores else 0.0
    avg_mrr = np.mean(mrr_scores) if mrr_scores else 0.0
    avg_time = np.mean(query_times) if query_times else 0.0

    result = EvaluationResult(
        model_name=model_name,
        recall_at_5=avg_recall_5,
        recall_at_10=avg_recall_10,
        mrr=avg_mrr,
        avg_time=avg_time
    )

    logger.info(f"[í‰ê°€ ì™„ë£Œ] {result}")
    return result


# ==================== ë©”ì¸ ì‹¤í–‰ ====================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("=" * 80)
    logger.info("ì„ë² ë”© ëª¨ë¸ ë¹„êµ í‰ê°€ ì‹œì‘")
    logger.info("=" * 80)

    # 1. ì²­í¬ ë°ì´í„° ë¡œë“œ
    chunks_path = "01_data/chunks/chunks_all.pkl"
    logger.info(f"\n[ë°ì´í„° ë¡œë“œ] {chunks_path}")

    with open(chunks_path, 'rb') as f:
        chunks = pickle.load(f)

    logger.info(f"  - ì´ ì²­í¬ ìˆ˜: {len(chunks)}")

    # ìƒ˜í”Œë§ (ì „ì²´ ë°ì´í„°ëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)
    # ì „ì²´ í‰ê°€ë¥¼ ì›í•˜ë©´ ì´ ë¶€ë¶„ ì œê±°
    if len(chunks) > 2000:
        logger.warning(f"  - í‰ê°€ ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ 2000ê°œ ìƒ˜í”Œë§")
        np.random.seed(42)
        sample_indices = np.random.choice(len(chunks), 2000, replace=False)
        chunks = [chunks[i] for i in sample_indices]

    # 2. ëª¨ë¸ ì´ˆê¸°í™”
    models = init_models()

    if not models:
        logger.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        return

    # 3. ê° ëª¨ë¸ í‰ê°€
    results = []

    for model_name, embedding_model in models.items():
        try:
            result = evaluate_model(
                model_name=model_name,
                embedding_model=embedding_model,
                chunks=chunks,
                test_queries=TEST_QUERIES,
                top_k=10
            )
            results.append(result)
        except Exception as e:
            logger.error(f"ëª¨ë¸ {model_name} í‰ê°€ ì‹¤íŒ¨: {e}")

    # 4. ê²°ê³¼ ì¶œë ¥
    logger.info("\n" + "=" * 80)
    logger.info("ìµœì¢… í‰ê°€ ê²°ê³¼")
    logger.info("=" * 80)

    # ì •ë ¬ (Recall@10 ê¸°ì¤€)
    results.sort(key=lambda x: x.recall_at_10, reverse=True)

    print("\n{:<20} {:>10} {:>10} {:>10} {:>12}".format(
        "Model", "R@5", "R@10", "MRR", "Avg Time(s)"
    ))
    print("-" * 65)

    for result in results:
        print("{:<20} {:>10.3f} {:>10.3f} {:>10.3f} {:>12.2f}".format(
            result.model_name,
            result.recall_at_5,
            result.recall_at_10,
            result.mrr,
            result.avg_time
        ))

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
    if results:
        best_model = results[0]
        logger.info(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model.model_name}")
        logger.info(f"   - Recall@10: {best_model.recall_at_10:.3f}")
        logger.info(f"   - MRR: {best_model.mrr:.3f}")
        logger.info(f"   - í‰ê·  ê²€ìƒ‰ ì‹œê°„: {best_model.avg_time:.2f}ì´ˆ")


if __name__ == "__main__":
    main()

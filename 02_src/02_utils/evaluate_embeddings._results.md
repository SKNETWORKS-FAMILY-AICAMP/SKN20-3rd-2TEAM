# 임베딩 모델 평가 결과

## 개요

이 문서는 HuggingFace DailyPapers RAG 시스템을 위한 7가지 임베딩 모델의 평가 결과를 담고 있습니다.

**평가 날짜:** 2025-12-05
**전체 청크 수:** 18,299개 (평가를 위해 2,000개 샘플링)
**테스트 쿼리:** 10개

## 평가 지표

- **Recall@5 (R@5):** 상위 5개 결과에서 관련 문서를 찾은 비율
- **Recall@10 (R@10):** 상위 10개 결과에서 관련 문서를 찾은 비율
- **MRR (Mean Reciprocal Rank):** 첫 번째 관련 문서의 순위 역수 평균
- **Avg Time:** 평균 쿼리 시간 (초)

## 테스트 쿼리

1. 최신 vision transformer 모델과 이미지 분류 성능
2. 대규모 언어 모델의 fine-tuning 기법
3. code generation을 위한 LLM 모델
4. multimodal learning과 vision-language 모델
5. reinforcement learning from human feedback
6. diffusion models for image generation
7. efficient transformers and model compression
8. graph neural networks and molecular modeling
9. video understanding and temporal modeling
10. zero-shot and few-shot learning methods

## 결과 요약

| 순위 | 모델 | R@5 | R@10 | MRR | 평균 시간 (초) |
|------|-------|-----|------|-----|-----------------|
| 🥇 1 | **OpenAI-small** | 0.011 | **0.056** | 0.339 | 0.38 |
| 2 | SPECTER | 0.005 | **0.050** | 0.208 | 0.08 |
| 3 | MiniLM-L6 | **0.025** | **0.050** | 0.404 | **0.02** |
| 4 | MPNet | **0.029** | 0.035 | **0.445** | 0.08 |
| 5 | Paraphrase-Multi | 0.010 | 0.019 | **0.492** | 0.08 |
| 6 | BGE-M3 | 0.003 | 0.012 | 0.321 | 0.27 |
| 7 | MsMarco | 0.003 | 0.008 | 0.303 | **0.02** |

*참고: Jina-v2 모델은 초기화 오류로 인해 로드 실패*

## 상세 모델 분석

### 1. 우승자: OpenAI text-embedding-3-small

- **모델:** `text-embedding-3-small`
- **차원:** 1536
- **최고 지표:** Recall@10 (0.056)
- **장점:**
  - 가장 높은 Recall@10 성능
  - 검색 정확도와 MRR의 균형이 좋음
  - OpenAI의 상용급 품질
- **단점:**
  - 가장 느린 추론 시간 (쿼리당 0.38초)
  - API 호출이 필요하고 비용 발생
  - 높은 차원으로 인해 더 많은 스토리지 필요

**권장 사항:** API 비용과 지연 시간이 허용된다면 프로덕션에 가장 적합함

---

### 2. SPECTER (과학 논문 특화)

- **모델:** `sentence-transformers/allenai-specter`
- **차원:** 768
- **특화 분야:** 과학 논문
- **성능:**
  - R@5: 0.005
  - R@10: 0.050
  - MRR: 0.208
- **장점:**
  - Recall@10에서 공동 2위
  - 과학/학술 콘텐츠에 최적화
  - 빠른 추론 (0.08초)
- **단점:**
  - 낮은 MRR은 관련 문서가 낮은 순위에 나타남을 의미
  - 낮은 Recall@5 성능

**권장 사항:** 과학 논문에는 좋지만 이 데이터셋에는 최적이 아님.

---

### 3. MiniLM-L6

- **모델:** `sentence-transformers/all-MiniLM-L6-v2`
- **차원:** 384
- **성능:**
  - R@5: 0.025 (로컬 모델 중 최고)
  - R@10: 0.050 (공동 2위)
  - MRR: 0.404
- **장점:**
  - **가장 빠른 추론 시간** (0.02초)
  - 로컬 모델 중 최고의 Recall@5 성능
  - 가장 작은 모델 크기 (384 차원)
  - 좋은 MRR 점수
  - API 비용 없음
- **단점:**
  - OpenAI보다 낮은 Recall@10

**권장 사항:** 로컬 배포에 탁월한 선택. 최고의 속도 대비 성능 비율.

---

### 4. MPNet

- **모델:** `sentence-transformers/all-mpnet-base-v2`
- **차원:** 768
- **성능:**
  - R@5: 0.029 (로컬 모델 중 최고)
  - R@10: 0.035
  - MRR: 0.445 (로컬 모델 중 최고)
- **장점:**
  - **로컬 모델 중 가장 높은 MRR 점수** (0.445)
  - 모든 모델 중 최고의 Recall@5
  - 고품질 임베딩
- **단점:**
  - 예상보다 낮은 Recall@10
  - 경량 모델보다 느림 (MiniLM보다 4배 느림)

**권장 사항:** 순위 품질(MRR)이 가장 좋은 로컬 모델. 첫 번째 결과 품질이 가장 중요할 때 선택.

---

### 5. Paraphrase-Multilingual

- **모델:** `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
- **차원:** 768
- **성능:**
  - R@5: 0.010
  - R@10: 0.019
  - MRR: **0.492 (전체 최고)**
- **장점:**
  - **모든 모델 중 가장 높은 MRR**
  - 다국어 지원
  - 관련 문서를 찾으면 매우 높은 순위에 배치
- **단점:**
  - 전반적으로 낮은 재현율 점수
  - 영어 전용 과학 콘텐츠에 최적화되지 않을 수 있음

**권장 사항:** 다국어 지원이 필요한 경우 고려하되, 영어 전용 논문에는 최적이 아님.

---

### 6. BGE-M3

- **모델:** `BAAI/bge-m3`
- **차원:** 1024
- **성능:**
  - R@5: 0.003
  - R@10: 0.012
  - MRR: 0.321
- **장점:**
  - 중국어와 영어 지원
  - 일반적으로 좋은 성능을 보이는 대형 모델
- **단점:**
  - **가장 느린 로컬 모델** (0.27초)
  - 이 데이터셋에서 낮은 성능
  - 영어 전용 콘텐츠에는 과한 사양

**권장 사항:** 중국어 지원이 필요하지 않다면 이 사용 사례에 권장하지 않음.

---

### 7. MsMarco-MiniLM

- **모델:** `sentence-transformers/msmarco-MiniLM-L-6-v3`
- **차원:** 384
- **성능:**
  - R@5: 0.003
  - R@10: 0.008
  - MRR: 0.303
- **장점:**
  - 빠른 추론 (0.02초)
  - 패시지 검색에 최적화
- **단점:**
  - 전반적으로 가장 낮은 성능
  - MS MARCO 데이터셋(질의응답)으로 학습되어 과학 논문에 맞지 않을 수 있음

**권장 사항:** 이 사용 사례에 권장하지 않음.

---

## 주요 발견사항

1. **OpenAI text-embedding-3-small**이 최고의 Recall@10을 달성했지만 지연 시간과 비용이 높음
2. **MiniLM-L6**는 로컬 배포를 위한 최고의 속도 대비 성능 비율을 제공
3. **MPNet**은 로컬 모델 중 가장 높은 MRR을 가지며, 첫 번째 결과 품질이 중요할 때 최고
4. **Paraphrase-Multilingual**은 낮은 재현율에도 불구하고 놀랍게도 가장 높은 전체 MRR을 보임
5. 특정 도메인에 최적화된 모델(과학 논문용 SPECTER, QA용 MsMarco)이 이 데이터셋에서 예상만큼 좋은 성능을 보이지 않음

## 성능 대 속도 비교

```
속도 (쿼리 시간)
MiniLM-L6:   0.02초  ████
MsMarco:     0.02초  ████
MPNet:       0.08초  ████████████████
SPECTER:     0.08초  ████████████████
BGE-M3:      0.27초  ████████████████████████████████████████████████
OpenAI:      0.38초  ████████████████████████████████████████████████████████████████

Recall@10 성능
OpenAI:      0.056  ████████████████████████████
SPECTER:     0.050  █████████████████████████
MiniLM-L6:   0.050  █████████████████████████
MPNet:       0.035  ██████████████████
Paraphrase:  0.019  ██████████
BGE-M3:      0.012  ██████
MsMarco:     0.008  ████
```

## 사용 사례별 권장사항

### 프로덕션 RAG 시스템 (비용 허용 가능)
**권장:** `OpenAI text-embedding-3-small`
- 최고의 검색 성능
- 프로덕션 품질을 위해 API 비용을 지불할 가치 있음
- **비용:** 100만 토큰당 약 $0.02

### 로컬 배포 (속도 우선)
**권장:** `MiniLM-L6`
- 가장 빠른 추론 (0.02초)
- 성능과 효율성의 좋은 균형
- 가장 작은 모델 풋프린트 (384 차원)
- **OpenAI보다 19배 빠름**

### 로컬 배포 (품질 우선)
**권장:** `MPNet`
- 로컬 모델 중 최고의 MRR (0.445)
- 가장 높은 Recall@5 (0.029)
- 더 높은 품질의 임베딩
- 첫 번째 결과가 가장 중요할 때 적합

### 예산 제약 + 품질
**권장:** `MiniLM-L6` 또는 `MPNet`
- 둘 다 API 비용 없이 좋은 성능 제공
- 속도는 MiniLM-L6, 품질은 MPNet 선택

### 다국어 지원
**권장:** `Paraphrase-Multilingual`
- 전체 최고 MRR (0.492)
- 50개 이상의 언어 지원
- 교차 언어 검색에 적합

## 비용 분석

### 무료 모델 (HuggingFace)
- **MiniLM-L6, MPNet, MsMarco, SPECTER, BGE-M3, Paraphrase-Multi:** $0
- 한 번 다운로드, 무제한 사용
- 다운로드 후 인터넷 불필요

### 유료 모델 (OpenAI)
- **text-embedding-3-small:** 100만 토큰당 $0.02
- 18,299개 청크 (~450만 토큰): **~$0.09**
- 월간 재인덱싱 비용 누적
- 네트워크 지연 + API 의존성

## 기술 노트

- 전체 18,299개 중 무작위로 샘플링한 2,000개 청크로 평가 수행
- 모든 모델은 CPU에서 평가
- 배치 크기: 배치당 100개 문서
- 공정한 비교를 위해 정규화가 활성화된 모델 사용
- Jina-v2 모델은 초기화 오류로 제외: `JinaBertModel.__init__() got an unexpected keyword argument 'device'`
- 재현성을 위한 랜덤 시드: 42

## 결과 재현

```bash
# 평가 스크립트 실행
cd C:\.workspace\SKN20-3rd-2TEAM
python 02_src\02_utils\evaluate_embeddings.py

# 전체 데이터셋(18,299개 청크)으로 평가하려면 샘플링 코드 제거:
# evaluate_embeddings.py의 468-472번째 줄을 주석 처리
```

---

*생성자: `02_src/02_utils/evaluate_embeddings.py`*
*실행 시간: 약 9분*
*플랫폼: Windows*
*날짜: 2025-12-05*
